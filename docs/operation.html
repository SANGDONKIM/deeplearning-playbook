<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 텐서 (tensor) 연산 | 딥러닝 공략집 with R</title>
  <meta name="description" content="딥러닝 라이브러리 Rtorch를 사용하여 딥러닝의 끝판왕을 정복해보자. 본격 R 딥러닝 공략집" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 텐서 (tensor) 연산 | 딥러닝 공략집 with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="딥러닝 라이브러리 Rtorch를 사용하여 딥러닝의 끝판왕을 정복해보자. 본격 R 딥러닝 공략집" />
  <meta name="github-repo" content="statisticsplaybook/r-torch-playbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 텐서 (tensor) 연산 | 딥러닝 공략집 with R" />
  
  <meta name="twitter:description" content="딥러닝 라이브러리 Rtorch를 사용하여 딥러닝의 끝판왕을 정복해보자. 본격 R 딥러닝 공략집" />
  

<meta name="author" content="슬기로운통계생활" />


<meta name="date" content="2021-02-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.6.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">딥러닝 공략집 with Rtorch</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 들어가며</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#설치하기"><i class="fa fa-check"></i><b>1.1</b> 설치하기</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> 딥러닝 첫걸음, 텐서 (tensor) 만들기</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#torch와의-첫만남"><i class="fa fa-check"></i><b>2.1</b> <code>torch</code>와의 첫만남</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#텐서-tensor-만들기"><i class="fa fa-check"></i><b>2.2</b> 텐서 (tensor) 만들기</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#빈-텐서-만들기"><i class="fa fa-check"></i><b>2.2.1</b> 빈 텐서 만들기</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#랜덤-텐서"><i class="fa fa-check"></i><b>2.2.2</b> 랜덤 텐서</a></li>
<li class="chapter" data-level="2.2.3" data-path="intro.html"><a href="intro.html#단위-텐서"><i class="fa fa-check"></i><b>2.2.3</b> 단위 텐서</a></li>
<li class="chapter" data-level="2.2.4" data-path="intro.html"><a href="intro.html#영0-텐서"><i class="fa fa-check"></i><b>2.2.4</b> 영(0) 텐서</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#고급기술-영리하게-만들기"><i class="fa fa-check"></i><b>2.3</b> 고급기술: 영리하게 만들기</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#텐서-직접선언"><i class="fa fa-check"></i><b>2.3.1</b> 텐서 직접선언</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#연산자-사용"><i class="fa fa-check"></i><b>2.3.2</b> <code>:</code> 연산자 사용</a></li>
<li class="chapter" data-level="2.3.3" data-path="intro.html"><a href="intro.html#seq-함수-사용"><i class="fa fa-check"></i><b>2.3.3</b> <code>seq()</code> 함수 사용</a></li>
<li class="chapter" data-level="2.3.4" data-path="intro.html"><a href="intro.html#연산자-사용-1"><i class="fa fa-check"></i><b>2.3.4</b> <code>%&gt;%</code> 연산자 사용</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#텐서와-행렬은-같을까"><i class="fa fa-check"></i><b>2.4</b> 텐서와 행렬은 같을까?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>3</b> 텐서 (tensor) 연산</a>
<ul>
<li class="chapter" data-level="3.1" data-path="operation.html"><a href="operation.html#토치-torch-불러오기-및-준비물-준비"><i class="fa fa-check"></i><b>3.1</b> 토치 (torch) 불러오기 및 준비물 준비</a></li>
<li class="chapter" data-level="3.2" data-path="operation.html"><a href="operation.html#텐서의-연산"><i class="fa fa-check"></i><b>3.2</b> 텐서의 연산</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="operation.html"><a href="operation.html#형type-변환"><i class="fa fa-check"></i><b>3.2.1</b> 형(type) 변환</a></li>
<li class="chapter" data-level="3.2.2" data-path="operation.html"><a href="operation.html#모양-변환"><i class="fa fa-check"></i><b>3.2.2</b> 모양 변환</a></li>
<li class="chapter" data-level="3.2.3" data-path="operation.html"><a href="operation.html#덧셈과-뺄셈"><i class="fa fa-check"></i><b>3.2.3</b> 덧셈과 뺄셈</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/statisticsplaybook/r-torch-playbook" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">딥러닝 공략집 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="operation" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> 텐서 (tensor) 연산</h1>
<p>지난 챕터에서 우리는 텐서가 행렬의 연산에 적용되는 <code>%*%</code>과 호환이 되지 않는 다는 것을 알게되었다. 이번 챕터에서는 텐서들의 연산에 대하여 알아보도록 하자.</p>
<div id="토치-torch-불러오기-및-준비물-준비" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> 토치 (torch) 불러오기 및 준비물 준비</h2>
<p>토치 (torch) 를 불러오고, 이번 챕터에 사용될 텐서 A, B, 그리고 C를 준비하자. 지난 챕터에서 배운 난수를 이용한 텐서도 만들 예정이니 난수를 고정한다.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="operation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb1-2"><a href="operation.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="operation.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 난수 생성 시드 고정 </span></span>
<span id="cb1-4"><a href="operation.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(<span class="dv">2021</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="operation.html#cb2-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb2-2"><a href="operation.html#cb2-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">torch_rand</span>(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb2-3"><a href="operation.html#cb2-3" aria-hidden="true" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">torch_rand</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb2-4"><a href="operation.html#cb2-4" aria-hidden="true" tabindex="-1"></a>A; B; C</span></code></pre></div>
<pre><code>## torch_tensor
##  1
##  2
##  3
##  4
##  5
##  6
## [ CPULongType{6} ]</code></pre>
<pre><code>## torch_tensor
##  0.5134  0.7426  0.7159
##  0.5705  0.1653  0.0443
## [ CPUFloatType{2,3} ]</code></pre>
<pre><code>## torch_tensor
## (1,.,.) = 
##   0.9628  0.2943
##   0.0992  0.8096
##   0.0169  0.8222
## 
## (2,.,.) = 
##   0.1242  0.7489
##   0.3608  0.5131
##   0.2959  0.7834
## [ CPUFloatType{2,3,2} ]</code></pre>
<p>만들어진 세 개의 텐서 결과를 살펴보면 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>텐서 A: 정수들로 구성이 되어있고, 6개의 원소들이 벡터를 이루고 있다.</li>
<li>텐서 B: 실수들로 구성이 되어있고, 똑같이 6개의 원소들이 있지만, 모양이 4행 3열인 2차원 행렬의 모양을 하고 있다.</li>
<li>텐서 C: 실수들로 구성이 되어있고, 총 원소 갯수는 12개지만, 모양은 3행 2열의 행렬이 두개가 쌓여진 꼴의 3차원 배열 (array) 이다.</li>
</ol>
</div>
<div id="텐서의-연산" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> 텐서의 연산</h2>
<div id="형type-변환" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> 형(type) 변환</h3>
<p>먼저 주목해야 할 것은 바로 텐서 A와 B의 자료형이 다르다는 것이다. 이게 무슨뜻이냐면 A에는 정수만이 담길 수 있고, B에는 실수만이 담길 수 있도록 설계가 되어있다는 것이다. 앞에서 확인한 자료형을 좀 더 명확하게 확인하기 위해서는 <code>type()</code> 사용한다.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="operation.html#cb6-1" aria-hidden="true" tabindex="-1"></a>A<span class="sc">$</span>dtype</span></code></pre></div>
<pre><code>## torch_Long</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="operation.html#cb8-1" aria-hidden="true" tabindex="-1"></a>B<span class="sc">$</span>dtype</span></code></pre></div>
<pre><code>## torch_Float</code></pre>
<p>텐서 A를 실수형 텐서로 바꿔보자. 텐서의 형을 변환할 때에는 A텐서 안에 속성으로 들어가있는 to() 함수를 사용 (좀 더 어려운 관점에서는 OOP의 method를 사용) 해서 바꿔줄 수 있다.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="operation.html#cb10-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> A<span class="sc">$</span><span class="fu">to</span>(<span class="at">dtype =</span> <span class="fu">torch_double</span>())</span>
<span id="cb10-2"><a href="operation.html#cb10-2" aria-hidden="true" tabindex="-1"></a>A</span></code></pre></div>
<pre><code>## torch_tensor
##  1
##  2
##  3
##  4
##  5
##  6
## [ CPUDoubleType{6} ]</code></pre>
<p>torch에는 정말 많은 자료형이 있는데, 그 목록은 <a href="https://torch.mlverse.org/docs/reference/torch_dtype.html">다음</a>을 참고하자.</p>
</div>
<div id="모양-변환" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> 모양 변환</h3>
<p>앞에서 텐서 A를 B와 같은 실수를 담을 수 있는 형으로 바꾸었다. 그렇다면 이 두 개를 더할 수 있을까? 답은 “아니올시다.” 이다. 왜냐하면 모양이 다르기 때문이다.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="operation.html#cb12-1" aria-hidden="true" tabindex="-1"></a>A <span class="sc">+</span> B</span></code></pre></div>
<pre><code>## Error in (function (self, other, alpha) : The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1
## Exception raised from infer_size at ../aten/src/ATen/ExpandUtils.cpp:24 (most recent call first):
## frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7fbe5be62b89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so)
## frame #1: at::infer_size(c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;) + 0x552 (0x7fbe4b9b1382 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #2: at::TensorIterator::compute_shape(at::TensorIteratorConfig const&amp;) + 0xde (0x7fbe4beb3c2e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #3: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x64 (0x7fbe4beb61e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #4: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7fbe4beb699d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #5: at::TensorIterator::binary_op(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 0x130 (0x7fbe4beb6b30 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #6: at::native::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x53 (0x7fbe4bb69bc3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #7: &lt;unknown function&gt; + 0x13311bd (0x7fbe4c1d01bd in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #8: &lt;unknown function&gt; + 0xaf2045 (0x7fbe4b991045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #9: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7fbe4c37b81f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #10: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7fbe4c271fd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #11: &lt;unknown function&gt; + 0x2a0f2bb (0x7fbe4d8ae2bb in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #12: &lt;unknown function&gt; + 0xaf2045 (0x7fbe4b991045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #13: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7fbe4c37b81f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #14: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7fbe4c271fd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so)
## frame #15: _lantern_add_tensor_tensor_scalar + 0x64 (0x7fbe5c1e40e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so)
## frame #16: cpp_torch_namespace_add_self_Tensor_other_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchScalar, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchScalar&gt;(XPtrTorchScalar*)), false&gt;) + 0x48 (0x7fbe5cb29fe8 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so)
## frame #17: _torch_cpp_torch_namespace_add_self_Tensor_other_Tensor + 0x9c (0x7fbe5c8c200c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so)
## frame #18: &lt;unknown function&gt; + 0xf9310 (0x7fbe6fbb7310 in /usr/lib/R/lib/libR.so)
## frame #19: &lt;unknown function&gt; + 0xf9826 (0x7fbe6fbb7826 in /usr/lib/R/lib/libR.so)
## frame #20: &lt;unknown function&gt; + 0x137106 (0x7fbe6fbf5106 in /usr/lib/R/lib/libR.so)
## frame #21: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #22: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #23: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #24: Rf_eval + 0x353 (0x7fbe6fc018c3 in /usr/lib/R/lib/libR.so)
## frame #25: &lt;unknown function&gt; + 0xc650d (0x7fbe6fb8450d in /usr/lib/R/lib/libR.so)
## frame #26: &lt;unknown function&gt; + 0x137106 (0x7fbe6fbf5106 in /usr/lib/R/lib/libR.so)
## frame #27: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #28: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #29: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #30: &lt;unknown function&gt; + 0x13a989 (0x7fbe6fbf8989 in /usr/lib/R/lib/libR.so)
## frame #31: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #32: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #33: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #34: &lt;unknown function&gt; + 0x13a989 (0x7fbe6fbf8989 in /usr/lib/R/lib/libR.so)
## frame #35: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #36: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #37: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #38: &lt;unknown function&gt; + 0x13a989 (0x7fbe6fbf8989 in /usr/lib/R/lib/libR.so)
## frame #39: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #40: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #41: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #42: &lt;unknown function&gt; + 0x13a989 (0x7fbe6fbf8989 in /usr/lib/R/lib/libR.so)
## frame #43: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #44: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #45: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #46: &lt;unknown function&gt; + 0x12d83b (0x7fbe6fbeb83b in /usr/lib/R/lib/libR.so)
## frame #47: &lt;unknown function&gt; + 0x9021b (0x7fbe6fb4e21b in /usr/lib/R/lib/libR.so)
## frame #48: Rf_eval + 0x706 (0x7fbe6fc01c76 in /usr/lib/R/lib/libR.so)
## frame #49: &lt;unknown function&gt; + 0x149782 (0x7fbe6fc07782 in /usr/lib/R/lib/libR.so)
## frame #50: &lt;unknown function&gt; + 0x137106 (0x7fbe6fbf5106 in /usr/lib/R/lib/libR.so)
## frame #51: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #52: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #53: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)
## frame #54: &lt;unknown function&gt; + 0x13a989 (0x7fbe6fbf8989 in /usr/lib/R/lib/libR.so)
## frame #55: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #56: &lt;unknown function&gt; + 0x1440ac (0x7fbe6fc020ac in /usr/lib/R/lib/libR.so)
## frame #57: Rf_eval + 0x454 (0x7fbe6fc019c4 in /usr/lib/R/lib/libR.so)
## frame #58: &lt;unknown function&gt; + 0x14a22c (0x7fbe6fc0822c in /usr/lib/R/lib/libR.so)
## frame #59: &lt;unknown function&gt; + 0x1871fd (0x7fbe6fc451fd in /usr/lib/R/lib/libR.so)
## frame #60: &lt;unknown function&gt; + 0x1353c4 (0x7fbe6fbf33c4 in /usr/lib/R/lib/libR.so)
## frame #61: Rf_eval + 0x180 (0x7fbe6fc016f0 in /usr/lib/R/lib/libR.so)
## frame #62: &lt;unknown function&gt; + 0x14550f (0x7fbe6fc0350f in /usr/lib/R/lib/libR.so)
## frame #63: Rf_applyClosure + 0x1c7 (0x7fbe6fc042d7 in /usr/lib/R/lib/libR.so)</code></pre>
<p>모양이 다른 텐서를 더하려고 하면 R은 위에서 보듯 너무나 많은 에러를 쏟아낸다. 모양이 다른 두 텐서를 더하기 위해서는 모양을 같게 맞춰줘야 한다. A의 모양을 B의 모양과 같이 바꿔보도록 하자. 모양을 바꿀때는 <code>view()</code> 함수를 사용하고, 안에 모양의 형태를 벡터 형식으로 짚어 넣는다는 것을 기억하자.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="operation.html#cb14-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> A<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb14-2"><a href="operation.html#cb14-2" aria-hidden="true" tabindex="-1"></a>A</span></code></pre></div>
<pre><code>## torch_tensor
##  1  2  3
##  4  5  6
## [ CPUDoubleType{2,3} ]</code></pre>
</div>
<div id="덧셈과-뺄셈" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> 덧셈과 뺄셈</h3>
<p>앞에서 형(type)과 모양(shape)까지 맞춰놨으니, 텐서끼리의 덧셈을 할 수 있다.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="operation.html#cb16-1" aria-hidden="true" tabindex="-1"></a>A <span class="sc">+</span> B</span></code></pre></div>
<pre><code>## torch_tensor
##  1.5134  2.7426  3.7159
##  4.5705  5.1653  6.0443
## [ CPUDoubleType{2,3} ]</code></pre>
<p>사실, 텐서끼리의 연산은 모양만 맞으면 가능하다. 즉, 다음의 연산이 성립한다.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="operation.html#cb18-1" aria-hidden="true" tabindex="-1"></a>A_ <span class="ot">&lt;-</span> A<span class="sc">$</span><span class="fu">to</span>(<span class="at">dtype =</span> <span class="fu">torch_long</span>())</span>
<span id="cb18-2"><a href="operation.html#cb18-2" aria-hidden="true" tabindex="-1"></a>A_ <span class="sc">+</span> B</span></code></pre></div>
<pre><code>## torch_tensor
##  1.5134  2.7426  3.7159
##  4.5705  5.1653  6.0443
## [ CPUFloatType{2,3} ]</code></pre>
<p>결과에서 알 수 있듯, 정수를 담을 수 있는 텐서와 실수를 담을 수 있는 텐서를 더하면, 결과는 실수를 담을 수 있는 텐서로 반환이 된다. 하지만, 필자는 이러한 코딩은 피해야 한다고 생각한다. 즉, 모든 연산을 할 경우, 명시적으로 형변환을 한 후 연산을 할 것을 권한다. 왜냐하면, 언제나 우리는 코드를 다른 사람이 보았을 때, 이해하기 쉽도록 짜는 것을 추구해야 한다. (코드는 하나의 자신의 생각을 적은 글이다.)</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statisticsplaybook/r-torch-playbook/edit/master/02-tensor-calculation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
