[["operation.html", "Chapter 3 텐서 (tensor) 연산 3.1 토치 (torch) 불러오기 및 준비물 준비 3.2 텐서의 연산", " Chapter 3 텐서 (tensor) 연산 지난 챕터에서 우리는 텐서가 행렬의 연산에 적용되는 %*%과 호환이 되지 않는 다는 것을 알게되었다. 이번 챕터에서는 텐서들의 연산에 대하여 알아보도록 하자. 3.1 토치 (torch) 불러오기 및 준비물 준비 토치 (torch) 를 불러오고, 이번 챕터에 사용될 텐서 A, B, 그리고 C를 준비하자. 지난 챕터에서 배운 난수를 이용한 텐서도 만들 예정이니 난수를 고정한다. library(torch) # 난수 생성 시드 고정 torch_manual_seed(2021) A &lt;- torch_tensor(1:6) B &lt;- torch_rand(2, 3) C &lt;- torch_rand(2, 3, 2) A; B; C ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## [ CPULongType{6} ] ## torch_tensor ## 0.5134 0.7426 0.7159 ## 0.5705 0.1653 0.0443 ## [ CPUFloatType{2,3} ] ## torch_tensor ## (1,.,.) = ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## ## (2,.,.) = ## 0.1242 0.7489 ## 0.3608 0.5131 ## 0.2959 0.7834 ## [ CPUFloatType{2,3,2} ] 만들어진 세 개의 텐서 결과를 살펴보면 다음과 같다. 텐서 A: 정수들로 구성이 되어있고, 6개의 원소들이 벡터를 이루고 있다. 텐서 B: 실수들로 구성이 되어있고, 똑같이 6개의 원소들이 있지만, 모양이 4행 3열인 2차원 행렬의 모양을 하고 있다. 텐서 C: 실수들로 구성이 되어있고, 총 원소 갯수는 12개지만, 모양은 3행 2열의 행렬이 두개가 쌓여진 꼴의 3차원 배열 (array) 이다. 3.2 텐서의 연산 3.2.1 형(type) 변환 먼저 주목해야 할 것은 바로 텐서 A와 B의 자료형이 다르다는 것이다. 이게 무슨뜻이냐면 A에는 정수만이 담길 수 있고, B에는 실수만이 담길 수 있도록 설계가 되어있다는 것이다. 앞에서 확인한 자료형을 좀 더 명확하게 확인하기 위해서는 type() 사용한다. A$dtype ## torch_Long B$dtype ## torch_Float 텐서 A를 실수형 텐서로 바꿔보자. 텐서의 형을 변환할 때에는 A텐서 안에 속성으로 들어가있는 to() 함수를 사용 (좀 더 어려운 관점에서는 OOP의 method를 사용) 해서 바꿔줄 수 있다. A &lt;- A$to(dtype = torch_double()) A ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## [ CPUDoubleType{6} ] torch에는 정말 많은 자료형이 있는데, 그 목록은 다음을 참고하자. 3.2.2 모양 변환 앞에서 텐서 A를 B와 같은 실수를 담을 수 있는 형으로 바꾸었다. 그렇다면 이 두 개를 더할 수 있을까? 답은 “아니올시다.” 이다. 왜냐하면 모양이 다르기 때문이다. A + B ## Error in (function (self, other, alpha) : The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1 ## Exception raised from infer_size at ../aten/src/ATen/ExpandUtils.cpp:24 (most recent call first): ## frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7f086041eb89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so) ## frame #1: at::infer_size(c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;) + 0x552 (0x7f084ff6d382 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #2: at::TensorIterator::compute_shape(at::TensorIteratorConfig const&amp;) + 0xde (0x7f085046fc2e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #3: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x64 (0x7f08504721e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #4: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7f085047299d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #5: at::TensorIterator::binary_op(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 0x130 (0x7f0850472b30 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #6: at::native::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x53 (0x7f0850125bc3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #7: &lt;unknown function&gt; + 0x13311bd (0x7f085078c1bd in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #8: &lt;unknown function&gt; + 0xaf2045 (0x7f084ff4d045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #9: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f085093781f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #10: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f085082dfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #11: &lt;unknown function&gt; + 0x2a0f2bb (0x7f0851e6a2bb in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #12: &lt;unknown function&gt; + 0xaf2045 (0x7f084ff4d045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #13: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f085093781f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #14: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f085082dfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #15: _lantern_add_tensor_tensor_scalar + 0x64 (0x7f08607a00e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so) ## frame #16: cpp_torch_namespace_add_self_Tensor_other_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchScalar, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchScalar&gt;(XPtrTorchScalar*)), false&gt;) + 0x48 (0x7f08610e5fe8 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #17: _torch_cpp_torch_namespace_add_self_Tensor_other_Tensor + 0x9c (0x7f0860e7e00c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #18: &lt;unknown function&gt; + 0xf9310 (0x7f0874173310 in /usr/lib/R/lib/libR.so) ## frame #19: &lt;unknown function&gt; + 0xf9826 (0x7f0874173826 in /usr/lib/R/lib/libR.so) ## frame #20: &lt;unknown function&gt; + 0x137106 (0x7f08741b1106 in /usr/lib/R/lib/libR.so) ## frame #21: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #22: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #23: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #24: Rf_eval + 0x353 (0x7f08741bd8c3 in /usr/lib/R/lib/libR.so) ## frame #25: &lt;unknown function&gt; + 0xc650d (0x7f087414050d in /usr/lib/R/lib/libR.so) ## frame #26: &lt;unknown function&gt; + 0x137106 (0x7f08741b1106 in /usr/lib/R/lib/libR.so) ## frame #27: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #28: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #29: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #30: &lt;unknown function&gt; + 0x13a989 (0x7f08741b4989 in /usr/lib/R/lib/libR.so) ## frame #31: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #32: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #33: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #34: &lt;unknown function&gt; + 0x13a989 (0x7f08741b4989 in /usr/lib/R/lib/libR.so) ## frame #35: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #36: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #37: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #38: &lt;unknown function&gt; + 0x13a989 (0x7f08741b4989 in /usr/lib/R/lib/libR.so) ## frame #39: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #40: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #41: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #42: &lt;unknown function&gt; + 0x13a989 (0x7f08741b4989 in /usr/lib/R/lib/libR.so) ## frame #43: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #44: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #45: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #46: &lt;unknown function&gt; + 0x12d83b (0x7f08741a783b in /usr/lib/R/lib/libR.so) ## frame #47: &lt;unknown function&gt; + 0x9021b (0x7f087410a21b in /usr/lib/R/lib/libR.so) ## frame #48: Rf_eval + 0x706 (0x7f08741bdc76 in /usr/lib/R/lib/libR.so) ## frame #49: &lt;unknown function&gt; + 0x149782 (0x7f08741c3782 in /usr/lib/R/lib/libR.so) ## frame #50: &lt;unknown function&gt; + 0x137106 (0x7f08741b1106 in /usr/lib/R/lib/libR.so) ## frame #51: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #52: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #53: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) ## frame #54: &lt;unknown function&gt; + 0x13a989 (0x7f08741b4989 in /usr/lib/R/lib/libR.so) ## frame #55: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #56: &lt;unknown function&gt; + 0x1440ac (0x7f08741be0ac in /usr/lib/R/lib/libR.so) ## frame #57: Rf_eval + 0x454 (0x7f08741bd9c4 in /usr/lib/R/lib/libR.so) ## frame #58: &lt;unknown function&gt; + 0x14a22c (0x7f08741c422c in /usr/lib/R/lib/libR.so) ## frame #59: &lt;unknown function&gt; + 0x1871fd (0x7f08742011fd in /usr/lib/R/lib/libR.so) ## frame #60: &lt;unknown function&gt; + 0x1353c4 (0x7f08741af3c4 in /usr/lib/R/lib/libR.so) ## frame #61: Rf_eval + 0x180 (0x7f08741bd6f0 in /usr/lib/R/lib/libR.so) ## frame #62: &lt;unknown function&gt; + 0x14550f (0x7f08741bf50f in /usr/lib/R/lib/libR.so) ## frame #63: Rf_applyClosure + 0x1c7 (0x7f08741c02d7 in /usr/lib/R/lib/libR.so) 모양이 다른 텐서를 더하려고 하면 R은 위에서 보듯 너무나 많은 에러를 쏟아낸다. 모양이 다른 두 텐서를 더하기 위해서는 모양을 같게 맞춰줘야 한다. A의 모양을 B의 모양과 같이 바꿔보도록 하자. 모양을 바꿀때는 view() 함수를 사용하고, 안에 모양의 형태를 벡터 형식으로 짚어 넣는다는 것을 기억하자. A &lt;- A$view(c(2, 3)) A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] 3.2.3 덧셈과 뺄셈 앞에서 형(type)과 모양(shape)까지 맞춰놨으니, 텐서끼리의 덧셈과 뺄셈을 할 수 있다. A + B ## torch_tensor ## 1.5134 2.7426 3.7159 ## 4.5705 5.1653 6.0443 ## [ CPUDoubleType{2,3} ] A - B ## torch_tensor ## 0.4866 1.2574 2.2841 ## 3.4295 4.8347 5.9557 ## [ CPUDoubleType{2,3} ] 사실, 텐서끼리의 연산은 모양만 맞으면 가능하다. 즉, 다음의 연산이 성립한다. A_ &lt;- A$to(dtype = torch_long()) A_ + B ## torch_tensor ## 1.5134 2.7426 3.7159 ## 4.5705 5.1653 6.0443 ## [ CPUFloatType{2,3} ] 결과에서 알 수 있듯, 정수를 담을 수 있는 텐서와 실수를 담을 수 있는 텐서를 더하면, 결과는 실수를 담을 수 있는 텐서로 반환이 된다. 하지만, 필자는 이러한 코딩은 피해야 한다고 생각한다. 즉, 모든 연산을 할 경우, 명시적으로 형변환을 한 후 연산을 할 것을 권한다. 왜냐하면, 언제나 우리는 코드를 다른 사람이 보았을 때, 이해하기 쉽도록 짜는 것을 추구해야 한다. (코드는 하나의 자신의 생각을 적은 글이다.) 3.2.4 상수와의 연산 R에서와 마찬가지로, 텐서와 상수와의 사칙연산은 각 원소에 적용되는 것을 확인하자. A + 2 ## torch_tensor ## 3 4 5 ## 6 7 8 ## [ CPUDoubleType{2,3} ] B^2 ## torch_tensor ## 0.2636 0.5514 0.5125 ## 0.3254 0.0273 0.0020 ## [ CPUFloatType{2,3} ] A %/% 3 ## torch_tensor ## 0 0 1 ## 1 1 2 ## [ CPUDoubleType{2,3} ] A %% 3 ## torch_tensor ## 1 2 0 ## 1 2 0 ## [ CPUDoubleType{2,3} ] 3.2.5 제곱근과 로그 제곱근(square root)나 로그(log) 함수 역시 각 원소별 적용이 가능하다. A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] torch_sqrt(A) ## torch_tensor ## 1.0000 1.4142 1.7321 ## 2.0000 2.2361 2.4495 ## [ CPUDoubleType{2,3} ] 위의 연산이 에러가 나는 이유는 A가 정수를 담는 텐서였는데, 연산을 수행한 후에 실수가 담겨져서 나오는 에러이다. R과는 사뭇다른 예민한 아이 torch를 위해 형을 바꿔준 후에 연산을 실행하도록 하자. torch_sqrt(A$to(dtype = torch_double())) ## torch_tensor ## 1.0000 1.4142 1.7321 ## 2.0000 2.2361 2.4495 ## [ CPUDoubleType{2,3} ] torch_log(B) ## torch_tensor ## -0.6667 -0.2977 -0.3342 ## -0.5613 -1.8002 -3.1166 ## [ CPUFloatType{2,3} ] 3.2.6 텐서의 곱셈 텐서의 곱셈 역시 모양이 맞아야 하므로, 3행 2열이 두개가 붙어있는 C에서 앞에 한장을 떼어내도록 하자. B ## torch_tensor ## 0.5134 0.7426 0.7159 ## 0.5705 0.1653 0.0443 ## [ CPUFloatType{2,3} ] D &lt;- C[1,,] D ## torch_tensor ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## [ CPUFloatType{3,2} ] 텐서의 곱셈은 torch_matmul() 함수를 사용한다. # 파이프 사용해도 무방하다. # B %&gt;% torch_matmul(D) torch_matmul(B, D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] 토치의 텐서 곱셈은 다음과 같은 방법들도 있으니 알아두자. torch_mm(B, D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] B$mm(D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] B$matmul(D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] 3.2.7 텐서의 전치(transpose) 전치(transpose)는 주어진 텐서를 뒤집는 것인데, 다음의 문법 구조를 가지고 있다. torch_transpose(input, dim0, dim1) dim0, dim1는 바꿀 차원을 의미한다. ‘바꿀 차원은 두 개 밖에 없지 않나?’ 라고 생각할 수 있다. 2 차원 텐서의 경우에는 그렇다. 우리가 행렬을 전치하는 경우에는 transpose를 취하는 대상이 2차원이므로 지정해주는 차원이 정해져있다. 하지만, 텐서의 차원이 3차원 이상이 되면 전치를 해주는 차원을 지정해줘야한다. A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] 위의 텐서 A의 차원은 행과 열, 즉, 2개이다. 다음의 코드들은 A 텐서의 첫번째 차원과 두번째 차원을 뒤집는 효과를 가져온다. 즉, 전치 텐서가 된다. torch_transpose(A, 1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] A$transpose(1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] A %&gt;% torch_transpose(1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] 3차원의 텐서를 살펴보자. C ## torch_tensor ## (1,.,.) = ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## ## (2,.,.) = ## 0.1242 0.7489 ## 0.3608 0.5131 ## 0.2959 0.7834 ## [ CPUFloatType{2,3,2} ] 텐서 C는 위와 같이 2차원 텐서가 두 개 포개져 있다고 생각하면 된다. 텐서의 결과물을 잘 살펴보면, 제일 앞에 위치한 1, 2가 나타내는 것이 우리가 흔히 생각하는 행렬들의 색인(index) 역할을 한다는 것을 알 수 있다. torch_transpose(C, 2, 3) ## torch_tensor ## (1,.,.) = ## 0.9628 0.0992 0.0169 ## 0.2943 0.8096 0.8222 ## ## (2,.,.) = ## 0.1242 0.3608 0.2959 ## 0.7489 0.5131 0.7834 ## [ CPUFloatType{2,2,3} ] 이 부분에서 R에서 기본적으로 제공하는 array의 문법과 차이가 발생하는데, 다음의 코드를 살펴보자. 먼저 R에서 2행 3열의 행렬을 두 개 포개어 놓은 3차원 배열을 만드는 코드이다. array(1:12, c(2, 3, 2)) ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 9 11 ## [2,] 8 10 12 필자는 참고로 matrix()를 만들때에도 byrow 옵션을 써서 만드는 것을 좋아하는데, array()에서 byrow 옵션 효과를 적용하려면 aperm() 함수를 사용해야 한다. 따라서, 좀 더 직관적으로 쓰기위해서 다음의 함수를 사용하자. array_3d_byrow &lt;- function(num_vec, nrow, ncol, ndeath){ aperm(array(num_vec, c(ncol, nrow, ndeath)), c(2, 1, 3)) } E &lt;- array_3d_byrow(1:12, 2, 3, 2) E ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 8 9 ## [2,] 10 11 12 이러한 코드를 앞서 배웠던 torch_tensor() 함수에 넣어보자. E %&gt;% torch_tensor() ## torch_tensor ## (1,.,.) = ## 1 7 ## 2 8 ## 3 9 ## ## (2,.,.) = ## 4 10 ## 5 11 ## 6 12 ## [ CPULongType{2,3,2} ] 결과를 살펴보면, 우리가 예상했던 2행 3열의 텐서가 두개 겹쳐있는 텐서의 모양이 나오지 않는다는 것을 알 수 있다. 이유는 torch에서 정의된 3차원 텐서의 경우, 첫번째 차원이 텐서가 얼마나 겹쳐있는지를 나타내는 깊이(depth)를 나타내기 때문이다. 문제를 해결하기 위해서는 aperm() 사용해서 차원을 바꿔주면 된다. E %&gt;% aperm(c(3, 1, 2)) %&gt;% # 3 번째 차원을 맨 앞으로, 나머지는 그대로 torch_tensor() ## torch_tensor ## (1,.,.) = ## 1 2 3 ## 4 5 6 ## ## (2,.,.) = ## 7 8 9 ## 10 11 12 ## [ CPULongType{2,2,3} ] 위의 경우를 좀더 직관적인 함수명으로 바꿔서 사용하도록 하자. 😂 array_to_torch &lt;- function(mat, n_dim = 3){ torch_tensor(aperm(mat, c(n_dim:3, 1, 2))) } E &lt;- array_to_torch(E) E ## torch_tensor ## (1,.,.) = ## 1 2 3 ## 4 5 6 ## ## (2,.,.) = ## 7 8 9 ## 10 11 12 ## [ CPULongType{2,2,3} ] "]]
