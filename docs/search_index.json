[["index.html", "딥러닝 공략집 with R 들어가며 설치하기 기본 패키지", " 딥러닝 공략집 with R 슬기로운통계생활 2021-02-10 들어가며 Figure 0.1: deep-learning playbook 이제까지 R에서의 딥러닝은 Python의 라이브러리들을 reticulate 패키지를 이용하여 빌려온 형태였지만, torch for R 패키지는 C 라이브러리를 Torch를 기반으로 R을 wrapper 언어로서 사용하여 패키지를 만들었다. 즉, Torch + Python = PyTorch, Torch + R = Rtorch가 되는 셈이다. 설치하기 설치 역시 간단한다. 여느 R패키지와 같이 install.packages() 함수를 사용하면 된다. 서브 라이브러리인 torchaudio와 torchvision이 있으나, 책의 뒷부분에서 다루기로 한다. install.packages(&quot;torch&quot;) # 혹은 개발버전을 다운 받고 싶다면 # devtools::install_github(&quot;mlverse/torch&quot;) 기본 패키지 앞으로의 내용에 있어서 다음의 두 패키지는 기본으로 불러와서 사용하는 것을 약속으로 한다. library(tidyverse) library(torch) "],["intro.html", "Chapter 1 딥러닝 첫걸음, 텐서 (tensor) 만들기 1.1 torch와의 첫만남 1.2 텐서 (tensor) 만들기 1.3 고급기술: 영리하게 만들기 1.4 텐서와 행렬은 같을까?", " Chapter 1 딥러닝 첫걸음, 텐서 (tensor) 만들기 1.1 torch와의 첫만남 torch패키지를 설치했으니, 한번 만나봐야한다. 다음의 명령어를 통하여 torch를 불러보자. library(torch) 1.2 텐서 (tensor) 만들기 텐서가 무엇이냐! 무언가 대단한 것처럼 보이나, 결국 우리가 R을 배웠을때 사용했던 matrix의 개념을 확장시킨 것이라고 생각하면 된다. 결국 다차원 행렬, 혹은 Array인 것이다. 우리가 많이 쓰는 행렬도 Array에 속하지만, 보통 Array라는 용어는 3차원 이상의 행렬을 암시한다. 이름부터 멋있는 딥러닝인데 다른 용어들이 Array같이 다른 패키지에서 사용되는 것들이랑 동일하면 격이 떨어지므로, 텐서 (tensor) 라고 붙였다. 토치 설명서에 따르면 텐서는 R의 Array와 비슷하나, GPU 계산에도 쓸 수 있다고 나와있다. (응, 그냥 Array.) 또한, 프로그래밍 언어에서 어떤 변수를 만들때, 만든다고 하지않고, “선언한다\" 라고 한다. 따라서 앞으로 만든다는 말 대신”선언\"이라는 용어를 사용하겠다. 1.2.1 빈 텐서 만들기 속이 빈 5행 3열의 텐서은 다음과 같이 선언한다. 주의할 점은 우리가 이번에 만들 빈 (empty) 텐서 과 뒤에서 만들어 볼 0 텐서는 다르다; 빈 텐서은 0과 근접한 쓰레기값이 들어있는 반면에, 0 텐서에는 정말 0이 들어있다. x &lt;- torch_empty(5, 3) # 텐서 x값 확인 x ## torch_tensor ## 0 0 0 ## 0 0 0 ## 0 0 0 ## 0 0 0 ## 0 0 0 ## [ CPUFloatType{5,3} ] # 텐서 x의 크기 확인 dim(x) ## [1] 5 3 정말 5행 3열의 텐서가 만들어졌다. 이건 마치 우리가 R을 처음 시작하고 텐서을 만드는 것과 아주 유사해서, 실제 R을 만져본 사람이라면 뒤로 빨리 넘기고 싶어하는 욕구가 솓구칠 것이다. 결과값을 잘 살펴보자. CPUFloatType에서 우리는 현재 만든 rand_tensor는 CPU에서 접근이 가능하며, 실수 (float) 타입이라는 것을 이야기해준다. 1.2.2 랜덤 텐서 텐서의 각 자리에 0에서 1사이의 난수로 채워서 만드는 방법이다. torch_rand() 함수를 사용한다. rand_tensor &lt;- torch_rand(5, 3) rand_tensor ## torch_tensor ## 0.2117 0.7335 0.4033 ## 0.3414 0.3143 0.2592 ## 0.0112 0.9920 0.9388 ## 0.2523 0.2627 0.2483 ## 0.6070 0.0639 0.7073 ## [ CPUFloatType{5,3} ] 참고로 이렇게 만들어진 텐서에는 R에서 텐서과 어레이(array)에 접근할 때사용한 모든 문법들을 사용해서 접근할 수 있다. rand_tensor[,2] ## torch_tensor ## 0.7335 ## 0.3143 ## 0.9920 ## 0.2627 ## 0.0639 ## [ CPUFloatType{5} ] rand_tensor[1:3,] ## torch_tensor ## 0.2117 0.7335 0.4033 ## 0.3414 0.3143 0.2592 ## 0.0112 0.9920 0.9388 ## [ CPUFloatType{3,3} ] rand_tensor[3:4,c(1, 3)] ## torch_tensor ## 0.0112 0.9388 ## 0.2523 0.2483 ## [ CPUFloatType{2,2} ] 위의 예제에서 벌써부터 일부 R유저들은 감격의 눈물을 흘릴 수 있다. 그렇다, Rtorch에서 텐서의 첫번째 위치는 1부터 시작한다. 이 너무나도 당연한 진리는 파이썬에서는 통하지 않는다. 1.2.3 단위 텐서 4행 4열의 단위 텐서 (identity matrix)를 선언하는 방법은 다음과 같다. x &lt;- torch_eye(4) x ## torch_tensor ## 1 0 0 0 ## 0 1 0 0 ## 0 0 1 0 ## 0 0 0 1 ## [ CPUFloatType{4,4} ] 1.2.4 영(0) 텐서 텐서의 요소들이 모두 0으로 채워진 3행 5열의 텐서을 선언하는 것은 다음과 같이 torch_zeros() 함수를 사용한다. x &lt;- torch_zeros(3, 5) x ## torch_tensor ## 0 0 0 0 0 ## 0 0 0 0 0 ## 0 0 0 0 0 ## [ CPUFloatType{3,5} ] 1.3 고급기술: 영리하게 만들기 지금까지는 미리 정해진 값들, 난수나, 0과 1을 채워넣는 법을 배웠다. 하지만, 많은 경우 우리가 직접 정의한 텐서들을 다루게 될 것이다. 이번 섹션에서는 좀 더 영리하게 선언해보는 방법을 배워보자. 1.3.1 텐서 직접선언 가장 핵심적인 내용은 R에서 벡터와 행렬을 정의한 후 torch_tensor() 함수에 넣어주면, 그대로 가져다가 텐서로 바꿔준다는 사실이다. 다음의 예제는 2행 2열의 행렬을 정의한 후, 정의된 행렬을 사용하여 텐서를 만드는 코드이다. y &lt;- torch_tensor(matrix(c(1, 2, 3, 4, 5, 6), ncol = 2)) y ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUFloatType{3,2} ] 1.3.2 : 연산자 사용 위의 코드가 잘 작동한다는 사실을 알게 되면, 우리가 너무나 익숙한 R의 기본 함수들을 사용하여 텐서를 자유롭게 만들 수 있을 것이다. 앞선 예제는 : 연산자를 통하여 다음과 같이 축약 할 수 있다. y &lt;- torch_tensor(matrix(1:6, ncol = 2)) y ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPULongType{3,2} ] 1.3.3 seq() 함수 사용 seq() 함수는 좀 더 유연한 벡터를 만들 수 있도록 해주므로, 텐서를 만들때 유용하게 사용될 것이다. y &lt;- torch_tensor(matrix(seq(0.1, 1, by = 0.1), ncol = 2)) y ## torch_tensor ## 0.1000 0.6000 ## 0.2000 0.7000 ## 0.3000 0.8000 ## 0.4000 0.9000 ## 0.5000 1.0000 ## [ CPUFloatType{5,2} ] 위의 코드는 seq() 함수를 사용해서 벡터를 만들고, 2열을 갖는 행렬을 만든 후, 텐서로 변환을 시켰다. 단, by 옵션의 경우, 결과값이 홀수인지 짝수인지 체크해줘야 하므로, 특정 범위에서의 일정 간격 숫자를 뽑아 행렬로 만들땐 length.out 옵션이 편하다. y &lt;- torch_tensor(matrix(seq(0, 1, length.out = 10), ncol = 2)) y ## torch_tensor ## 0.0000 0.5556 ## 0.1111 0.6667 ## 0.2222 0.7778 ## 0.3333 0.8889 ## 0.4444 1.0000 ## [ CPUFloatType{5,2} ] 둘 다 0과 1사이의 벡터를 만들었지만, 결과는 다르다는 것에 주의하자. 텐서를 만드는 방법에 대한 핵심은 결국, 자신이 편한 방법으로 만들고 싶은 텐서와 대응되는 R 개체를 만들고, torch_tensor()에 입력 시켜주면 되는 것이다. 1.3.4 %&gt;% 연산자 사용 가끔 R에서 아주 많이 쓰이는 %&gt;% 파이프 연산자를 다른 라이브러리를 사용할 경우 적용할 생각을 못하는 경우가 있다. 왼쪽의 결과 값을 오른쪽의 입력값으로 넘겨주는 파이프 연산자 역시 torch 패키지에서 사용 가능하므로, 텐서 만드는 방법은 그야말로 무궁무진하다. library(magrittr) y2 &lt;- torch_tensor(1:5 %&gt;% diag()) y2 ## torch_tensor ## 1 0 0 0 0 ## 0 2 0 0 0 ## 0 0 3 0 0 ## 0 0 0 4 0 ## 0 0 0 0 5 ## [ CPULongType{5,5} ] 1.4 텐서와 행렬은 같을까? 앞에서 설명한 것처럼 텐서는 행렬의 개념을 확장시킨 것에 지나지 않겠지만, 그렇다고 같은 취급을 해서도 안된다. 그도 그럴것이 R에서 torch의 텐서와 행렬은 같지 않다. 이러한 사실은 다음과 같이 위에서 만든 텐서 x에 R의 기본 연산자인 행렬곱을 적용해보면 알 수 있다. x &lt;- torch_zeros(3, 5) x %*% t(x) ## Error in t.default(x): argument is not a matrix 위의 argument is not a matrix 에러에서 우리는 정말 텐서와 행렬은 다르게 취급된다는 것을 알 수 있다. 즉, R환경에서 텐서와 행렬은 근본이 다른 개체(object)라는 것을 알 수 있다. 그렇다면 ‘텐서끼리의 계산은 어떻게 할까?’ 자연스러운 의문이 든다. 다음 장에서는 텐서의 연산에 대하여 배워보자. "],["operation.html", "Chapter 2 텐서 (tensor) 연산 2.1 토치 (torch) 불러오기 및 준비물 준비 2.2 텐서의 연산", " Chapter 2 텐서 (tensor) 연산 지난 챕터에서 우리는 텐서가 행렬의 연산에 적용되는 %*%과 호환이 되지 않는 다는 것을 알게되었다. 이번 챕터에서는 텐서들의 연산에 대하여 알아보도록 하자. 2.1 토치 (torch) 불러오기 및 준비물 준비 토치 (torch) 를 불러오고, 이번 챕터에 사용될 텐서 A, B, 그리고 C를 준비하자. 지난 챕터에서 배운 난수를 이용한 텐서도 만들 예정이니 난수를 고정한다. library(torch) # 난수 생성 시드 고정 torch_manual_seed(2021) A &lt;- torch_tensor(1:6) B &lt;- torch_rand(2, 3) C &lt;- torch_rand(2, 3, 2) A; B; C ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## [ CPULongType{6} ] ## torch_tensor ## 0.5134 0.7426 0.7159 ## 0.5705 0.1653 0.0443 ## [ CPUFloatType{2,3} ] ## torch_tensor ## (1,.,.) = ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## ## (2,.,.) = ## 0.1242 0.7489 ## 0.3608 0.5131 ## 0.2959 0.7834 ## [ CPUFloatType{2,3,2} ] 만들어진 세 개의 텐서 결과를 살펴보면 다음과 같다. 텐서 A: 정수들로 구성이 되어있고, 6개의 원소들이 벡터를 이루고 있다. 텐서 B: 실수들로 구성이 되어있고, 똑같이 6개의 원소들이 있지만, 모양이 4행 3열인 2차원 행렬의 모양을 하고 있다. 텐서 C: 실수들로 구성이 되어있고, 총 원소 갯수는 12개지만, 모양은 3행 2열의 행렬이 두개가 쌓여진 꼴의 3차원 배열 (array) 이다. 2.2 텐서의 연산 2.2.1 형(type) 변환 먼저 주목해야 할 것은 바로 텐서 A와 B의 자료형이 다르다는 것이다. 이게 무슨뜻이냐면 A에는 정수만이 담길 수 있고, B에는 실수만이 담길 수 있도록 설계가 되어있다는 것이다. 앞에서 확인한 자료형을 좀 더 명확하게 확인하기 위해서는 type() 사용한다. A$dtype ## torch_Long B$dtype ## torch_Float 텐서 A를 실수형 텐서로 바꿔보자. 텐서의 형을 변환할 때에는 A텐서 안에 속성으로 들어가있는 to() 함수를 사용 (좀 더 어려운 관점에서는 OOP의 method를 사용) 해서 바꿔줄 수 있다. A &lt;- A$to(dtype = torch_double()) A ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## [ CPUDoubleType{6} ] torch에는 정말 많은 자료형이 있는데, 그 목록은 다음을 참고하자. 2.2.2 모양 변환 앞에서 텐서 A를 B와 같은 실수를 담을 수 있는 형으로 바꾸었다. 그렇다면 이 두 개를 더할 수 있을까? 답은 “아니올시다.” 이다. 왜냐하면 모양이 다르기 때문이다. A + B ## Error in (function (self, other, alpha) : The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1 ## Exception raised from infer_size at ../aten/src/ATen/ExpandUtils.cpp:24 (most recent call first): ## frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7f97b0a9db89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so) ## frame #1: at::infer_size(c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;) + 0x552 (0x7f97a05ec382 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #2: at::TensorIterator::compute_shape(at::TensorIteratorConfig const&amp;) + 0xde (0x7f97a0aeec2e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #3: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x64 (0x7f97a0af11e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #4: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7f97a0af199d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #5: at::TensorIterator::binary_op(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 0x130 (0x7f97a0af1b30 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #6: at::native::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x53 (0x7f97a07a4bc3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #7: &lt;unknown function&gt; + 0x13311bd (0x7f97a0e0b1bd in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #8: &lt;unknown function&gt; + 0xaf2045 (0x7f97a05cc045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #9: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f97a0fb681f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #10: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f97a0eacfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #11: &lt;unknown function&gt; + 0x2a0f2bb (0x7f97a24e92bb in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #12: &lt;unknown function&gt; + 0xaf2045 (0x7f97a05cc045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #13: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f97a0fb681f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #14: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f97a0eacfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #15: _lantern_add_tensor_tensor_scalar + 0x64 (0x7f97b0e1f0e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so) ## frame #16: cpp_torch_namespace_add_self_Tensor_other_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchScalar, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchScalar&gt;(XPtrTorchScalar*)), false&gt;) + 0x48 (0x7f97b1764fe8 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #17: _torch_cpp_torch_namespace_add_self_Tensor_other_Tensor + 0x9c (0x7f97b14fd00c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #18: &lt;unknown function&gt; + 0xf9310 (0x7f97c40e6310 in /usr/lib/R/lib/libR.so) ## frame #19: &lt;unknown function&gt; + 0xf9826 (0x7f97c40e6826 in /usr/lib/R/lib/libR.so) ## frame #20: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #21: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #22: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #23: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #24: Rf_eval + 0x353 (0x7f97c41308c3 in /usr/lib/R/lib/libR.so) ## frame #25: &lt;unknown function&gt; + 0xc650d (0x7f97c40b350d in /usr/lib/R/lib/libR.so) ## frame #26: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #27: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #28: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #29: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #30: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #31: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #32: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #33: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #34: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #35: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #36: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #37: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #38: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #39: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #40: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #41: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #42: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #43: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #44: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #45: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #46: &lt;unknown function&gt; + 0x12d83b (0x7f97c411a83b in /usr/lib/R/lib/libR.so) ## frame #47: &lt;unknown function&gt; + 0x9021b (0x7f97c407d21b in /usr/lib/R/lib/libR.so) ## frame #48: Rf_eval + 0x706 (0x7f97c4130c76 in /usr/lib/R/lib/libR.so) ## frame #49: &lt;unknown function&gt; + 0x149782 (0x7f97c4136782 in /usr/lib/R/lib/libR.so) ## frame #50: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #51: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #52: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #53: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #54: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #55: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #56: &lt;unknown function&gt; + 0x1440ac (0x7f97c41310ac in /usr/lib/R/lib/libR.so) ## frame #57: Rf_eval + 0x454 (0x7f97c41309c4 in /usr/lib/R/lib/libR.so) ## frame #58: &lt;unknown function&gt; + 0x14a22c (0x7f97c413722c in /usr/lib/R/lib/libR.so) ## frame #59: &lt;unknown function&gt; + 0x1871fd (0x7f97c41741fd in /usr/lib/R/lib/libR.so) ## frame #60: &lt;unknown function&gt; + 0x1353c4 (0x7f97c41223c4 in /usr/lib/R/lib/libR.so) ## frame #61: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #62: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #63: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) 모양이 다른 텐서를 더하려고 하면 R은 위에서 보듯 너무나 많은 에러를 쏟아낸다. 모양이 다른 두 텐서를 더하기 위해서는 모양을 같게 맞춰줘야 한다. A의 모양을 B의 모양과 같이 바꿔보도록 하자. 모양을 바꿀때는 view() 함수를 사용하고, 안에 모양의 형태를 벡터 형식으로 짚어 넣는다는 것을 기억하자. A &lt;- A$view(c(2, 3)) A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] 한가지 짚고 넘어가야하는 기능이 있는데, R에서 행렬을 정의할 때, 주어진 원소벡터를 넣고, 가로행과 세로열 중 하나만 입력을 해도 잘 정의가 되는 것을 기억할 것이다. view 함수 역시 비슷한 기능이 있는데, 바로 -1을 이용해서 모양을 변환시키는 방법이다. 앞선 예제에서 2행 3열이 텐서를 1행의 가로 텐서로 변환 시키려면 다음과 같이 view() 함수의 입력값을 조정할 수 있다. A$view(c(1, -1)) ## torch_tensor ## 1 2 3 4 5 6 ## [ CPUDoubleType{1,6} ] 2.2.3 덧셈과 뺄셈 앞에서 형(type)과 모양(shape)까지 맞춰놨으니, 텐서끼리의 덧셈과 뺄셈을 할 수 있다. A + B ## torch_tensor ## 1.5134 2.7426 3.7159 ## 4.5705 5.1653 6.0443 ## [ CPUDoubleType{2,3} ] A - B ## torch_tensor ## 0.4866 1.2574 2.2841 ## 3.4295 4.8347 5.9557 ## [ CPUDoubleType{2,3} ] 사실, 텐서끼리의 연산은 모양만 맞으면 가능하다. 즉, 다음의 연산이 성립한다. A_ &lt;- A$to(dtype = torch_long()) A_ + B ## torch_tensor ## 1.5134 2.7426 3.7159 ## 4.5705 5.1653 6.0443 ## [ CPUFloatType{2,3} ] 결과에서 알 수 있듯, 정수를 담을 수 있는 텐서와 실수를 담을 수 있는 텐서를 더하면, 결과는 실수를 담을 수 있는 텐서로 반환이 된다. 하지만, 필자는 이러한 코딩은 피해야 한다고 생각한다. 즉, 모든 연산을 할 경우, 명시적으로 형변환을 한 후 연산을 할 것을 권한다. 왜냐하면, 언제나 우리는 코드를 다른 사람이 보았을 때, 이해하기 쉽도록 짜는 것을 추구해야 한다. (코드는 하나의 자신의 생각을 적은 글이다.) 2.2.4 상수와의 연산 R에서와 마찬가지로, 텐서와 상수와의 사칙연산은 각 원소에 적용되는 것을 확인하자. A + 2 ## torch_tensor ## 3 4 5 ## 6 7 8 ## [ CPUDoubleType{2,3} ] B^2 ## torch_tensor ## 0.2636 0.5514 0.5125 ## 0.3254 0.0273 0.0020 ## [ CPUFloatType{2,3} ] A %/% 3 ## torch_tensor ## 0 0 1 ## 1 1 2 ## [ CPUDoubleType{2,3} ] A %% 3 ## torch_tensor ## 1 2 0 ## 1 2 0 ## [ CPUDoubleType{2,3} ] 2.2.5 제곱근과 로그 제곱근(square root)나 로그(log) 함수 역시 각 원소별 적용이 가능하다. A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] torch_sqrt(A) ## torch_tensor ## 1.0000 1.4142 1.7321 ## 2.0000 2.2361 2.4495 ## [ CPUDoubleType{2,3} ] 위의 연산이 에러가 나는 이유는 A가 정수를 담는 텐서였는데, 연산을 수행한 후에 실수가 담겨져서 나오는 에러이다. R과는 사뭇다른 예민한 아이 torch를 위해 형을 바꿔준 후에 연산을 실행하도록 하자. torch_sqrt(A$to(dtype = torch_double())) ## torch_tensor ## 1.0000 1.4142 1.7321 ## 2.0000 2.2361 2.4495 ## [ CPUDoubleType{2,3} ] torch_log(B) ## torch_tensor ## -0.6667 -0.2977 -0.3342 ## -0.5613 -1.8002 -3.1166 ## [ CPUFloatType{2,3} ] 2.2.6 텐서의 곱셈 텐서의 곱셈 역시 모양이 맞아야 하므로, 3행 2열이 두개가 붙어있는 C에서 앞에 한장을 떼어내도록 하자. B ## torch_tensor ## 0.5134 0.7426 0.7159 ## 0.5705 0.1653 0.0443 ## [ CPUFloatType{2,3} ] D &lt;- C[1,,] D ## torch_tensor ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## [ CPUFloatType{3,2} ] 텐서의 곱셈은 torch_matmul() 함수를 사용한다. # 파이프 사용해도 무방하다. # B %&gt;% torch_matmul(D) torch_matmul(B, D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] 토치의 텐서 곱셈은 다음과 같은 방법들도 있으니 알아두자. torch_mm(B, D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] B$mm(D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] B$matmul(D) ## torch_tensor ## 0.5800 1.3409 ## 0.5664 0.3381 ## [ CPUFloatType{2,2} ] 2.2.7 텐서의 전치(transpose) 전치(transpose)는 주어진 텐서를 뒤집는 것인데, 다음의 문법 구조를 가지고 있다. torch_transpose(input, dim0, dim1) dim0, dim1는 바꿀 차원을 의미한다. ‘바꿀 차원은 두 개 밖에 없지 않나?’ 라고 생각할 수 있다. 2 차원 텐서의 경우에는 그렇다. 우리가 행렬을 전치하는 경우에는 transpose를 취하는 대상이 2차원이므로 지정해주는 차원이 정해져있다. 하지만, 텐서의 차원이 3차원 이상이 되면 전치를 해주는 차원을 지정해줘야한다. A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] 위의 텐서 A의 차원은 행과 열, 즉, 2개이다. 다음의 코드들은 A 텐서의 첫번째 차원과 두번째 차원을 뒤집는 효과를 가져온다. 즉, 전치 텐서가 된다. torch_transpose(A, 1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] A$transpose(1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] A %&gt;% torch_transpose(1, 2) ## torch_tensor ## 1 4 ## 2 5 ## 3 6 ## [ CPUDoubleType{3,2} ] 3차원의 텐서를 살펴보자. C ## torch_tensor ## (1,.,.) = ## 0.9628 0.2943 ## 0.0992 0.8096 ## 0.0169 0.8222 ## ## (2,.,.) = ## 0.1242 0.7489 ## 0.3608 0.5131 ## 0.2959 0.7834 ## [ CPUFloatType{2,3,2} ] 텐서 C는 위와 같이 2차원 텐서가 두 개 포개져 있다고 생각하면 된다. 텐서의 결과물을 잘 살펴보면, 제일 앞에 위치한 1, 2가 나타내는 것이 우리가 흔히 생각하는 2차원 텐서들의 색인(index) 역할을 한다는 것을 알 수 있다. 앞으로는 편의를 위해서 3차원 텐서의 색인 역할을 하는 차원을 깊이(depth)라고 부르도록 하자. 앞에서 주어진 텐서 C 안의 포개져있는 2차원 텐서들을 전치하기 위해서는 이들을 관할(?)하는 두번째와 세번째 차원을 바꿔줘야 한다. torch_transpose(C, 2, 3) ## torch_tensor ## (1,.,.) = ## 0.9628 0.0992 0.0169 ## 0.2943 0.8096 0.8222 ## ## (2,.,.) = ## 0.1242 0.3608 0.2959 ## 0.7489 0.5131 0.7834 ## [ CPUFloatType{2,2,3} ] 결과를 살펴보면, 잘 바뀌어 있음을 알 수 있다. 2.2.8 R에서의 3차원 배열 앞에서 다룬 torch에서의 3차원 텐서 부분은 R에서 기본적으로 제공하는 array의 문법과 차이가 난다. 다음의 코드를 살펴보자. 먼저 R에서 2행 3열의 행렬을 두 개 포개어 놓은 3차원 배열을 만드는 코드이다. array(1:12, c(2, 3, 2)) ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 9 11 ## [2,] 8 10 12 필자는 참고로 matrix()를 만들때에도 byrow 옵션을 써서 만드는 것을 좋아하는데, array()에서 byrow 옵션 효과를 적용하려면 aperm() 함수를 사용해야 한다. 따라서, 좀 더 직관적으로 쓰기위해서 다음의 함수를 사용하자. array_3d_byrow &lt;- function(num_vec, nrow, ncol, ndeath){ aperm(array(num_vec, c(ncol, nrow, ndeath)), c(2, 1, 3)) } E &lt;- array_3d_byrow(1:12, 2, 3, 2) E ## , , 1 ## ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] 7 8 9 ## [2,] 10 11 12 이러한 코드를 앞서 배웠던 torch_tensor() 함수에 넣어보자. E %&gt;% torch_tensor() ## torch_tensor ## (1,.,.) = ## 1 7 ## 2 8 ## 3 9 ## ## (2,.,.) = ## 4 10 ## 5 11 ## 6 12 ## [ CPULongType{2,3,2} ] 결과를 살펴보면, 우리가 예상했던 2행 3열의 텐서가 두개 겹쳐있는 텐서의 모양이 나오지 않는다는 것을 알 수 있다. 이유는 torch에서 정의된 3차원 텐서의 경우, 첫번째 차원이 텐서가 얼마나 겹쳐있는지를 나타내는 깊이(depth)를 나타내기 때문이다. 문제를 해결하기 위해서는 aperm() 사용해서 차원을 바꿔주면 된다. E %&gt;% aperm(c(3, 1, 2)) %&gt;% # 3 번째 차원을 맨 앞으로, 나머지는 그대로 torch_tensor() ## torch_tensor ## (1,.,.) = ## 1 2 3 ## 4 5 6 ## ## (2,.,.) = ## 7 8 9 ## 10 11 12 ## [ CPULongType{2,2,3} ] 위의 경우를 좀더 직관적인 함수명으로 바꿔서 사용하도록 하자. array_to_torch &lt;- function(mat, n_dim = 3){ torch_tensor(aperm(mat, c(n_dim:3, 1, 2))) } E &lt;- array_to_torch(E) E ## torch_tensor ## (1,.,.) = ## 1 2 3 ## 4 5 6 ## ## (2,.,.) = ## 7 8 9 ## 10 11 12 ## [ CPULongType{2,2,3} ] 2.2.9 다차원 텐서와 1차원 벡터 텐서의 연산 R에서 우리가 아주 애용하는 기능 중 하나가 바로 recycling 개념이다. 즉, 길이 혹은 모양이 맞지 않는 개체(object)들을 연산할 때, 자동으로 길이와 모양을 맞춰서 연산을 해주는 기능인데, torch에서도 이러한 기능을 제공한다. 다음의 코드를 살펴보자. A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] A + torch_tensor(1:3) ## torch_tensor ## 2 4 6 ## 5 7 9 ## [ CPUDoubleType{2,3} ] A ## torch_tensor ## 1 2 3 ## 4 5 6 ## [ CPUDoubleType{2,3} ] A + torch_tensor(matrix(2:3, ncol = 1)) ## torch_tensor ## 3 4 5 ## 7 8 9 ## [ CPUDoubleType{2,3} ] 2.2.10 1차원 텐서 끼리의 연산, 내적과 외적 1차원 텐서끼리의 연산도 2차원 텐서끼리의 연산과 마찬가지라고 생각하면 된다. 내적과 외적 역시 그냥 모양을 맞춰서 곱하면 된다. A_1 &lt;- A$view(c(1, -1)) A_1 ## torch_tensor ## 1 2 3 4 5 6 ## [ CPUDoubleType{1,6} ] A_2 &lt;- A$view(c(-1, 1)) A_2 ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## 5 ## 6 ## [ CPUDoubleType{6,1} ] A_1$mm(A_2) ## torch_tensor ## 91 ## [ CPUDoubleType{1,1} ] A_2$mm(A_1) ## torch_tensor ## 1 2 3 4 5 6 ## 2 4 6 8 10 12 ## 3 6 9 12 15 18 ## 4 8 12 16 20 24 ## 5 10 15 20 25 30 ## 6 12 18 24 30 36 ## [ CPUDoubleType{6,6} ] 한가지 주의할 점은 1차원 텐서끼리의 연산이더라도 꼭 차원을 선언해줘서 열벡터와 행벡터를 분명히 해줘야 한다는 점이다. A_3 &lt;- torch_tensor(1:6) A_1$mm(A_3) ## Error in (function (self, mat2) : mat2 must be a matrix ## Exception raised from mm_cpu at ../aten/src/ATen/native/LinearAlgebra.cpp:399 (most recent call first): ## frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7f97b0a9db89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so) ## frame #1: at::native::mm_cpu(at::Tensor const&amp;, at::Tensor const&amp;) + 0x334 (0x7f97a08ec194 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #2: &lt;unknown function&gt; + 0x133236d (0x7f97a0e0c36d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #3: &lt;unknown function&gt; + 0xaf1c34 (0x7f97a05cbc34 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #4: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;) const + 0x1ce (0x7f97a0fb424e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #5: at::mm(at::Tensor const&amp;, at::Tensor const&amp;) + 0xb7 (0x7f97a0e9a947 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #6: &lt;unknown function&gt; + 0x2a5db24 (0x7f97a2537b24 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #7: &lt;unknown function&gt; + 0xaf1c34 (0x7f97a05cbc34 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #8: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;) const + 0x1ce (0x7f97a0fb424e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #9: at::Tensor::mm(at::Tensor const&amp;) const + 0xb7 (0x7f97a111dd67 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) ## frame #10: _lantern_Tensor_mm_tensor_tensor + 0x4c (0x7f97b0ddb79c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so) ## frame #11: cpp_torch_method_mm_self_Tensor_mat2_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;) + 0x2c (0x7f97b170d4fc in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #12: _torch_cpp_torch_method_mm_self_Tensor_mat2_Tensor + 0x82 (0x7f97b14b2f22 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) ## frame #13: &lt;unknown function&gt; + 0xf932c (0x7f97c40e632c in /usr/lib/R/lib/libR.so) ## frame #14: &lt;unknown function&gt; + 0xf9826 (0x7f97c40e6826 in /usr/lib/R/lib/libR.so) ## frame #15: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #16: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #17: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #18: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #19: Rf_eval + 0x353 (0x7f97c41308c3 in /usr/lib/R/lib/libR.so) ## frame #20: &lt;unknown function&gt; + 0xc650d (0x7f97c40b350d in /usr/lib/R/lib/libR.so) ## frame #21: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #22: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #23: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #24: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #25: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #26: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #27: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #28: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #29: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #30: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #31: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #32: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #33: Rf_eval + 0x353 (0x7f97c41308c3 in /usr/lib/R/lib/libR.so) ## frame #34: &lt;unknown function&gt; + 0x1470a2 (0x7f97c41340a2 in /usr/lib/R/lib/libR.so) ## frame #35: Rf_eval + 0x572 (0x7f97c4130ae2 in /usr/lib/R/lib/libR.so) ## frame #36: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #37: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #38: Rf_eval + 0x353 (0x7f97c41308c3 in /usr/lib/R/lib/libR.so) ## frame #39: &lt;unknown function&gt; + 0x149782 (0x7f97c4136782 in /usr/lib/R/lib/libR.so) ## frame #40: &lt;unknown function&gt; + 0x137106 (0x7f97c4124106 in /usr/lib/R/lib/libR.so) ## frame #41: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #42: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #43: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #44: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #45: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #46: &lt;unknown function&gt; + 0x1440ac (0x7f97c41310ac in /usr/lib/R/lib/libR.so) ## frame #47: Rf_eval + 0x454 (0x7f97c41309c4 in /usr/lib/R/lib/libR.so) ## frame #48: &lt;unknown function&gt; + 0x14a22c (0x7f97c413722c in /usr/lib/R/lib/libR.so) ## frame #49: &lt;unknown function&gt; + 0x1871fd (0x7f97c41741fd in /usr/lib/R/lib/libR.so) ## frame #50: &lt;unknown function&gt; + 0x1353c4 (0x7f97c41223c4 in /usr/lib/R/lib/libR.so) ## frame #51: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #52: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #53: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #54: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #55: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #56: &lt;unknown function&gt; + 0x1440ac (0x7f97c41310ac in /usr/lib/R/lib/libR.so) ## frame #57: &lt;unknown function&gt; + 0x1444e4 (0x7f97c41314e4 in /usr/lib/R/lib/libR.so) ## frame #58: &lt;unknown function&gt; + 0x1377d4 (0x7f97c41247d4 in /usr/lib/R/lib/libR.so) ## frame #59: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) ## frame #60: &lt;unknown function&gt; + 0x14550f (0x7f97c413250f in /usr/lib/R/lib/libR.so) ## frame #61: Rf_applyClosure + 0x1c7 (0x7f97c41332d7 in /usr/lib/R/lib/libR.so) ## frame #62: &lt;unknown function&gt; + 0x13a989 (0x7f97c4127989 in /usr/lib/R/lib/libR.so) ## frame #63: Rf_eval + 0x180 (0x7f97c41306f0 in /usr/lib/R/lib/libR.so) 위의 코드는 연산 에러가 나는데, 이유는 A_3의 모양이 A_1의 모양과 맞지 않기 때문이다. A_1$size() ## [1] 1 6 A_3$size() ## [1] 6 "],["텐서의-이동-cpu-iff-gpu.html", "Chapter 3 텐서의 이동 CPU \\(\\iff\\) GPU 3.1 GPU 사용 가능 체크 3.2 CPU to GPU 3.3 GPU to CPU", " Chapter 3 텐서의 이동 CPU \\(\\iff\\) GPU 딥러닝(deep learning)에서는 네트워크의 구조가 조금만 복잡해져도, 필요한 계산량이 엄청나게 늘어나기 때문에 GPU는 사실 필수적이다. torch 패키지에서는 텐서를 다룰때에 현재 다루는 텐서가 어디에 저장되어있는가에 대한 일종의 태그를 달아놓는다. 다음의 코드를 살펴보자. a &lt;- torch_tensor(1:4) a ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CPULongType{4} ] a는 3이라는 상수가 담겨있는 텐서이다. 이 a를 콘솔에서 돌렸을때에 나오는 결과 [ CPUFloatType{1} ]를 통해서 우리는 a가 현재 CPU의 메모리를 이용하고 있으며, 모양은 {1}인 실수을 담은 텐서라는 것을 알 수 있다. 3.1 GPU 사용 가능 체크 앞서 정의한 텐서 a를 GPU의 메모리로 옮기기 위해서는, 너무나 당연하게 GPU가 현재 시스템에서 접근 가능한지에 대하여 알아보아야한다. GPU 접근성은 cuda_is_available()을 사용한다. cuda_is_available() ## [1] TRUE 3.2 CPU to GPU 이미 정의된 텐서 a를 GPU로 옮기려면 다음과 같이 cuda() 함수를 이용하면 된다. a ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CPULongType{4} ] a$cuda() ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CUDALongType{4} ] gpu &lt;- torch_device(&quot;cuda&quot;) a$to(device = gpu) ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CUDALongType{4} ] 옮길 때에 dtype을 사용하여 다음과 같이 자료형을 바꿔줄 수도 있다. a$to(device = gpu, dtype = torch_double()) ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CUDADoubleType{4} ] 3.3 GPU to CPU GPU 상에 직접 텐서를 만드는 방법은 다음과 같다. b &lt;- torch_tensor(1:4, device=gpu) b ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CUDALongType{4} ] 이전 섹션에서 CPU에서 GPU로 옮기는 방법과 비슷하게 다음의 코드가 작동한다. b$cpu() ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CPULongType{4} ] # to 함수 이용 cpu &lt;- torch_device(&quot;cpu&quot;) a$to(device = cpu) ## torch_tensor ## 1 ## 2 ## 3 ## 4 ## [ CPULongType{4} ] "],["references.html", "References", " References "]]
