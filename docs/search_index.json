[["index.html", "딥러닝 공략집 with R 들어가며 공략집 사용법 설치하기 기본 패키지", " 딥러닝 공략집 with R 슬기로운통계생활 2021-02-19 들어가며 이제까지 R에서의 딥러닝은 Python의 라이브러리들을 reticulate 패키지를 이용하여 빌려온 형태였지만, torch for R 패키지는 C 라이브러리를 Torch를 기반으로 R을 wrapper 언어로서 사용하여 패키지를 만들었다. 즉, Torch + Python = PyTorch, Torch + R = RTorch가 되는 셈이다. 공략집 사용법 현재 웹상에 공개된 딥러닝 공략집에는 hypothesis라는 오픈소스 프로그램을 이용한 중요부분 표시(highlight) 기능과 주석 달기(Annotate) 기능이 구현되어 있다. 중요표시, 주석달기: 읽다가 중요하거나 나중에 따로 보고싶은 기능의 경우, 드래그를 하면 다음과 같은 선택 버튼이 나온다. 형광펜 긋고 싶은 경우 Highlight 선택, 주석을 달고 싶은 경우 Annotate을 선택하자. 하이라이팅 on/off: 가끔은 하이라이팅 해 놓은 것들을 없애고 글 만 읽고싶은 경우가 있을텐데 그 때엔 오른쪽 상단 동그라미에 점이 찍혀있는 버튼를 클릭하면 하이라이팅 된 것이 사라진다. 주석 공개/비공개: 주석은 필자와 다른 독자가 볼 수 있도록 public하게 남길 수도 있고, 자신만 볼 수 있게끔 private으로 설정 할 수 있다. 주석 기능을 이용하여 필자에게 피드백을 줄 수 있다. 오타나 오류 발견시 주석을 달아주시면 필자가 주기적으로 체크해서 고쳐나가도록 하겠다. 알아두기 하이라이팅과 주석들을 나중에 따로 볼 수 있다. 자주 방문하시는 분들은 가입하시고 사용하시면 여러모로 편할 것이다. 설치하기 설치 역시 간단한다. 여느 R패키지와 같이 install.packages() 함수를 사용하면 된다. 서브 라이브러리인 torchaudio와 torchvision이 있으나, 책의 뒷부분에서 다루기로 한다. install.packages(&quot;torch&quot;) # 혹은 개발버전을 다운 받고 싶다면 다음의 코드를 사용한다. # devtools::install_github(&quot;mlverse/torch&quot;) 기본 패키지 앞으로의 내용에 있어서 다음의 두 패키지는 기본으로 불러와서 사용하는 것을 약속으로 한다. library(tidyverse) library(torch) "],["intro.html", "Chapter 1 딥러닝 첫걸음, 텐서 (tensor) 만들기 1.1 torch와의 첫만남 1.2 텐서 (tensor) 만들기 1.3 고급기술: 영리하게 만들기 1.4 텐서와 행렬은 같을까?", " Chapter 1 딥러닝 첫걸음, 텐서 (tensor) 만들기 1.1 torch와의 첫만남 torch패키지를 설치했으니, 한번 만나봐야한다. 다음의 명령어를 통하여 torch를 불러보자. library(torch) 1.2 텐서 (tensor) 만들기 텐서가 무엇이냐! 무언가 대단한 것처럼 보이나, 결국 우리가 R을 배웠을때 사용했던 matrix의 개념을 확장시킨 것이라고 생각하면 된다. 결국 다차원 행렬, 혹은 Array인 것이다. 우리가 많이 쓰는 행렬도 Array에 속하지만, 보통 Array라는 용어는 3차원 이상의 행렬을 암시한다. 이름부터 멋있는 딥러닝인데 다른 용어들이 Array같이 다른 패키지에서 사용되는 것들이랑 동일하면 격이 떨어지므로, 텐서 (tensor) 라고 붙였다. 토치 설명서에 따르면 텐서는 R의 Array와 비슷하나, GPU 계산에도 쓸 수 있다고 나와있다. (응, 그냥 Array.) 또한, 프로그래밍 언어에서 어떤 변수를 만들때, 만든다고 하지않고, “선언한다\" 라고 한다. 따라서 앞으로 만든다는 말 대신”선언\"이라는 용어를 사용하겠다. 1.2.1 빈 텐서 만들기 속이 빈 5행 3열의 텐서은 다음과 같이 선언한다. 주의할 점은 우리가 이번에 만들 빈 (empty) 텐서 과 뒤에서 만들어 볼 0 텐서는 다르다; 빈 텐서은 0과 근접한 쓰레기값이 들어있는 반면에, 0 텐서에는 정말 0이 들어있다. x &lt;- torch_empty(5, 3) # 텐서 x값 확인 x #&gt; torch_tensor #&gt; 0 0 0 #&gt; 0 0 0 #&gt; 0 0 0 #&gt; 0 0 0 #&gt; 0 0 0 #&gt; [ CPUFloatType{5,3} ] # 텐서 x의 크기 확인 dim(x) #&gt; [1] 5 3 정말 5행 3열의 텐서가 만들어졌다. 이건 마치 우리가 R을 처음 시작하고 텐서을 만드는 것과 아주 유사해서, 실제 R을 만져본 사람이라면 뒤로 빨리 넘기고 싶어하는 욕구가 솓구칠 것이다. 결과값을 잘 살펴보자. CPUFloatType에서 우리는 현재 만든 rand_tensor는 CPU에서 접근이 가능하며, 실수 (float) 타입이라는 것을 이야기해준다. 1.2.2 랜덤 텐서 텐서의 각 자리에 0에서 1사이의 난수로 채워서 만드는 방법이다. torch_rand() 함수를 사용한다. rand_tensor &lt;- torch_rand(5, 3) rand_tensor #&gt; torch_tensor #&gt; 0.1406 0.8824 0.5817 #&gt; 0.4629 0.3574 0.5737 #&gt; 0.2139 0.9520 0.9581 #&gt; 0.3552 0.8353 0.6410 #&gt; 0.5302 0.1248 0.1205 #&gt; [ CPUFloatType{5,3} ] 참고로 이렇게 만들어진 텐서에는 R에서 텐서과 어레이(array)에 접근할 때사용한 모든 문법들을 사용해서 접근할 수 있다. rand_tensor[,2] #&gt; torch_tensor #&gt; 0.8824 #&gt; 0.3574 #&gt; 0.9520 #&gt; 0.8353 #&gt; 0.1248 #&gt; [ CPUFloatType{5} ] rand_tensor[1:3,] #&gt; torch_tensor #&gt; 0.1406 0.8824 0.5817 #&gt; 0.4629 0.3574 0.5737 #&gt; 0.2139 0.9520 0.9581 #&gt; [ CPUFloatType{3,3} ] rand_tensor[3:4,c(1, 3)] #&gt; torch_tensor #&gt; 0.2139 0.9581 #&gt; 0.3552 0.6410 #&gt; [ CPUFloatType{2,2} ] 위의 예제에서 벌써부터 일부 R유저들은 감격의 눈물을 흘릴 수 있다. 주의하기 그렇다, Rtorch에서 텐서의 첫번째 위치는 1부터 시작한다. 이 너무나도 당연한 진리는 파이썬에서는 통하지 않는다. 1.2.3 단위 텐서 4행 4열의 단위 텐서 (identity matrix)를 선언하는 방법은 다음과 같다. x &lt;- torch_eye(4) x #&gt; torch_tensor #&gt; 1 0 0 0 #&gt; 0 1 0 0 #&gt; 0 0 1 0 #&gt; 0 0 0 1 #&gt; [ CPUFloatType{4,4} ] 1.2.4 영(0) 텐서 텐서의 요소들이 모두 0으로 채워진 3행 5열의 텐서을 선언하는 것은 다음과 같이 torch_zeros() 함수를 사용한다. x &lt;- torch_zeros(3, 5) x #&gt; torch_tensor #&gt; 0 0 0 0 0 #&gt; 0 0 0 0 0 #&gt; 0 0 0 0 0 #&gt; [ CPUFloatType{3,5} ] 1.3 고급기술: 영리하게 만들기 지금까지는 미리 정해진 값들, 난수나, 0과 1을 채워넣는 법을 배웠다. 하지만, 많은 경우 우리가 직접 정의한 텐서들을 다루게 될 것이다. 이번 섹션에서는 좀 더 영리하게 선언해보는 방법을 배워보자. 1.3.1 텐서 직접선언 가장 핵심적인 내용은 R에서 벡터와 행렬을 정의한 후 torch_tensor() 함수에 넣어주면, 그대로 가져다가 텐서로 바꿔준다는 사실이다. 다음의 예제는 2행 2열의 행렬을 정의한 후, 정의된 행렬을 사용하여 텐서를 만드는 코드이다. y &lt;- torch_tensor(matrix(c(1, 2, 3, 4, 5, 6), ncol = 2)) y #&gt; torch_tensor #&gt; 1 4 #&gt; 2 5 #&gt; 3 6 #&gt; [ CPUFloatType{3,2} ] 1.3.2 : 연산자 사용 위의 코드가 잘 작동한다는 사실을 알게 되면, 우리가 너무나 익숙한 R의 기본 함수들을 사용하여 텐서를 자유롭게 만들 수 있을 것이다. 앞선 예제는 : 연산자를 통하여 다음과 같이 축약 할 수 있다. y &lt;- torch_tensor(matrix(1:6, ncol = 2)) y #&gt; torch_tensor #&gt; 1 4 #&gt; 2 5 #&gt; 3 6 #&gt; [ CPULongType{3,2} ] 1.3.3 seq() 함수 사용 seq() 함수는 좀 더 유연한 벡터를 만들 수 있도록 해주므로, 텐서를 만들때 유용하게 사용될 것이다. y &lt;- torch_tensor(matrix(seq(0.1, 1, by = 0.1), ncol = 2)) y #&gt; torch_tensor #&gt; 0.1000 0.6000 #&gt; 0.2000 0.7000 #&gt; 0.3000 0.8000 #&gt; 0.4000 0.9000 #&gt; 0.5000 1.0000 #&gt; [ CPUFloatType{5,2} ] 위의 코드는 seq() 함수를 사용해서 벡터를 만들고, 2열을 갖는 행렬을 만든 후, 텐서로 변환을 시켰다. 단, by 옵션의 경우, 결과값이 홀수인지 짝수인지 체크해줘야 하므로, 특정 범위에서의 일정 간격 숫자를 뽑아 행렬로 만들땐 length.out 옵션이 편하다. y &lt;- torch_tensor(matrix(seq(0, 1, length.out = 10), ncol = 2)) y #&gt; torch_tensor #&gt; 0.0000 0.5556 #&gt; 0.1111 0.6667 #&gt; 0.2222 0.7778 #&gt; 0.3333 0.8889 #&gt; 0.4444 1.0000 #&gt; [ CPUFloatType{5,2} ] 둘 다 0과 1사이의 벡터를 만들었지만, 결과는 다르다는 것에 주의하자. 알아두기 텐서를 만드는 방법에 대한 핵심은 결국, 자신이 편한 방법으로 만들고 싶은 텐서와 대응되는 R 개체를 만들고, torch_tensor()에 입력 시켜주면 되는 것이다. 1.3.4 %&gt;% 연산자 사용 가끔 R에서 아주 많이 쓰이는 %&gt;% 파이프 연산자를 다른 라이브러리를 사용할 경우 적용할 생각을 못하는 경우가 있다. 왼쪽의 결과 값을 오른쪽의 입력값으로 넘겨주는 파이프 연산자 역시 torch 패키지에서 사용 가능하므로, 텐서 만드는 방법은 그야말로 무궁무진하다. library(magrittr) y2 &lt;- torch_tensor(1:5 %&gt;% diag()) y2 #&gt; torch_tensor #&gt; 1 0 0 0 0 #&gt; 0 2 0 0 0 #&gt; 0 0 3 0 0 #&gt; 0 0 0 4 0 #&gt; 0 0 0 0 5 #&gt; [ CPULongType{5,5} ] 1.4 텐서와 행렬은 같을까? 앞에서 설명한 것처럼 텐서는 행렬의 개념을 확장시킨 것에 지나지 않겠지만, 그렇다고 같은 취급을 해서도 안된다. 그도 그럴것이 R에서 torch의 텐서와 행렬은 같지 않다. 이러한 사실은 다음과 같이 위에서 만든 텐서 x에 R의 기본 연산자인 행렬곱을 적용해보면 알 수 있다. x &lt;- torch_zeros(3, 5) x %*% t(x) #&gt; Error in t.default(x): argument is not a matrix 위의 argument is not a matrix 에러에서 우리는 정말 텐서와 행렬은 다르게 취급된다는 것을 알 수 있다. 그렇다면 ‘텐서끼리의 계산은 어떻게 할까?’ 자연스러운 의문이 든다. 다음 장에서는 텐서의 연산에 대하여 배워보자. 주의하기 R 프로그램 입장에서 torch를 사용해서 정의된 텐서와 base 패키지의 행렬(matrix)은 근본이 다른 객체(object)이다. "],["operation.html", "Chapter 2 텐서 (tensor) 연산 2.1 토치 (torch) 불러오기 및 준비물 준비 2.2 텐서의 연산", " Chapter 2 텐서 (tensor) 연산 지난 챕터에서 우리는 텐서가 행렬의 연산에 적용되는 %*%과 호환이 되지 않는 다는 것을 알게되었다. 이번 챕터에서는 텐서들의 연산에 대하여 알아보도록 하자. 2.1 토치 (torch) 불러오기 및 준비물 준비 토치 (torch) 를 불러오고, 이번 챕터에 사용될 텐서 A, B, 그리고 C를 준비하자. 지난 챕터에서 배운 난수를 이용한 텐서도 만들 예정이니 난수를 고정한다. library(torch) # 난수 생성 시드 고정 torch_manual_seed(2021) A &lt;- torch_tensor(1:6) B &lt;- torch_rand(2, 3) C &lt;- torch_rand(2, 3, 2) A; B; C #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; 5 #&gt; 6 #&gt; [ CPULongType{6} ] #&gt; torch_tensor #&gt; 0.5134 0.7426 0.7159 #&gt; 0.5705 0.1653 0.0443 #&gt; [ CPUFloatType{2,3} ] #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 0.9628 0.2943 #&gt; 0.0992 0.8096 #&gt; 0.0169 0.8222 #&gt; #&gt; (2,.,.) = #&gt; 0.1242 0.7489 #&gt; 0.3608 0.5131 #&gt; 0.2959 0.7834 #&gt; [ CPUFloatType{2,3,2} ] 만들어진 세 개의 텐서 결과를 살펴보면 다음과 같다. 텐서 A: 정수들로 구성이 되어있고, 6개의 원소들이 벡터를 이루고 있다. 텐서 B: 실수들로 구성이 되어있고, 똑같이 6개의 원소들이 있지만, 모양이 4행 3열인 2차원 행렬의 모양을 하고 있다. 텐서 C: 실수들로 구성이 되어있고, 총 원소 갯수는 12개지만, 모양은 3행 2열의 행렬이 두개가 쌓여진 꼴의 3차원 배열 (array) 이다. 2.2 텐서의 연산 2.2.1 형(type) 변환 먼저 주목해야 할 것은 바로 텐서 A와 B의 자료형이 다르다는 것이다. 이게 무슨뜻이냐면 A에는 정수만이 담길 수 있고, B에는 실수만이 담길 수 있도록 설계가 되어있다는 것이다. 앞에서 확인한 자료형을 좀 더 명확하게 확인하기 위해서는 type() 사용한다. A$dtype #&gt; torch_Long B$dtype #&gt; torch_Float 텐서 A를 실수형 텐서로 바꿔보자. 텐서의 형을 변환할 때에는 A텐서 안에 속성으로 들어가있는 to() 함수를 사용 (좀 더 어려운 관점에서는 OOP의 method를 사용) 해서 바꿔줄 수 있다. A &lt;- A$to(dtype = torch_double()) A #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; 5 #&gt; 6 #&gt; [ CPUDoubleType{6} ] torch에는 정말 많은 자료형이 있는데, 그 목록은 다음을 참고하자. 2.2.2 모양 변환 앞에서 텐서 A를 B와 같은 실수를 담을 수 있는 형으로 바꾸었다. 그렇다면 이 두 개를 더할 수 있을까? 답은 “아니올시다.” 이다. 왜냐하면 모양이 다르기 때문이다. A + B #&gt; Error in (function (self, other, alpha) : The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1 #&gt; Exception raised from infer_size at ../aten/src/ATen/ExpandUtils.cpp:24 (most recent call first): #&gt; frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7f692199db89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so) #&gt; frame #1: at::infer_size(c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;) + 0x552 (0x7f69114ec382 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #2: at::TensorIterator::compute_shape(at::TensorIteratorConfig const&amp;) + 0xde (0x7f69119eec2e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #3: at::TensorIterator::build(at::TensorIteratorConfig&amp;) + 0x64 (0x7f69119f11e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #4: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&amp;) + 0xdd (0x7f69119f199d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #5: at::TensorIterator::binary_op(at::Tensor&amp;, at::Tensor const&amp;, at::Tensor const&amp;) + 0x130 (0x7f69119f1b30 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #6: at::native::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x53 (0x7f69116a4bc3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #7: &lt;unknown function&gt; + 0x13311bd (0x7f6911d0b1bd in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #8: &lt;unknown function&gt; + 0xaf2045 (0x7f69114cc045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #9: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f6911eb681f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #10: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f6911dacfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #11: &lt;unknown function&gt; + 0x2a0f2bb (0x7f69133e92bb in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #12: &lt;unknown function&gt; + 0xaf2045 (0x7f69114cc045 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #13: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) const + 0x27f (0x7f6911eb681f in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #14: at::add(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar) + 0x123 (0x7f6911dacfd3 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #15: _lantern_add_tensor_tensor_scalar + 0x64 (0x7f6921d1f0e4 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so) #&gt; frame #16: cpp_torch_namespace_add_self_Tensor_other_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchScalar, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchScalar&gt;(XPtrTorchScalar*)), false&gt;) + 0x48 (0x7f6922664fe8 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) #&gt; frame #17: _torch_cpp_torch_namespace_add_self_Tensor_other_Tensor + 0x9c (0x7f69223fd00c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) #&gt; frame #18: &lt;unknown function&gt; + 0xf9310 (0x7f6938018310 in /usr/lib/R/lib/libR.so) #&gt; frame #19: &lt;unknown function&gt; + 0xf9826 (0x7f6938018826 in /usr/lib/R/lib/libR.so) #&gt; frame #20: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #21: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #22: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #23: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #24: Rf_eval + 0x353 (0x7f69380628c3 in /usr/lib/R/lib/libR.so) #&gt; frame #25: &lt;unknown function&gt; + 0xc650d (0x7f6937fe550d in /usr/lib/R/lib/libR.so) #&gt; frame #26: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #27: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #28: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #29: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #30: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #31: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #32: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #33: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #34: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #35: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #36: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #37: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #38: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #39: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #40: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #41: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #42: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #43: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #44: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #45: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #46: &lt;unknown function&gt; + 0x12d83b (0x7f693804c83b in /usr/lib/R/lib/libR.so) #&gt; frame #47: &lt;unknown function&gt; + 0x9021b (0x7f6937faf21b in /usr/lib/R/lib/libR.so) #&gt; frame #48: Rf_eval + 0x706 (0x7f6938062c76 in /usr/lib/R/lib/libR.so) #&gt; frame #49: &lt;unknown function&gt; + 0x149782 (0x7f6938068782 in /usr/lib/R/lib/libR.so) #&gt; frame #50: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #51: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #52: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #53: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #54: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #55: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #56: &lt;unknown function&gt; + 0x1440ac (0x7f69380630ac in /usr/lib/R/lib/libR.so) #&gt; frame #57: Rf_eval + 0x454 (0x7f69380629c4 in /usr/lib/R/lib/libR.so) #&gt; frame #58: &lt;unknown function&gt; + 0x14a22c (0x7f693806922c in /usr/lib/R/lib/libR.so) #&gt; frame #59: &lt;unknown function&gt; + 0x1871fd (0x7f69380a61fd in /usr/lib/R/lib/libR.so) #&gt; frame #60: &lt;unknown function&gt; + 0x1353c4 (0x7f69380543c4 in /usr/lib/R/lib/libR.so) #&gt; frame #61: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #62: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #63: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) 모양이 다른 텐서를 더하려고 하면 R은 위에서 보듯 너무나 많은 에러를 쏟아낸다. 모양이 다른 두 텐서를 더하기 위해서는 모양을 같게 맞춰줘야 한다. A의 모양을 B의 모양과 같이 바꿔보도록 하자. 모양을 바꿀때는 view() 함수를 사용하고, 안에 모양의 형태를 벡터 형식으로 짚어 넣는다는 것을 기억하자. A &lt;- A$view(c(2, 3)) A #&gt; torch_tensor #&gt; 1 2 3 #&gt; 4 5 6 #&gt; [ CPUDoubleType{2,3} ] 한가지 짚고 넘어가야하는 기능이 있는데, R에서 행렬을 정의할 때, 주어진 원소벡터를 넣고, 가로행과 세로열 중 하나만 입력을 해도 잘 정의가 되는 것을 기억할 것이다. view 함수 역시 비슷한 기능이 있는데, 바로 -1을 이용해서 모양을 변환시키는 방법이다. 앞선 예제에서 2행 3열이 텐서를 1행의 가로 텐서로 변환 시키려면 다음과 같이 view() 함수의 입력값을 조정할 수 있다. A$view(c(1, -1)) #&gt; torch_tensor #&gt; 1 2 3 4 5 6 #&gt; [ CPUDoubleType{1,6} ] 2.2.3 덧셈과 뺄셈 앞에서 형(type)과 모양(shape)까지 맞춰놨으니, 텐서끼리의 덧셈과 뺄셈을 할 수 있다. A + B #&gt; torch_tensor #&gt; 1.5134 2.7426 3.7159 #&gt; 4.5705 5.1653 6.0443 #&gt; [ CPUDoubleType{2,3} ] A - B #&gt; torch_tensor #&gt; 0.4866 1.2574 2.2841 #&gt; 3.4295 4.8347 5.9557 #&gt; [ CPUDoubleType{2,3} ] 사실, 텐서끼리의 연산은 모양만 맞으면 가능하다. 즉, 다음의 연산이 성립한다. A_ &lt;- A$to(dtype = torch_long()) A_ + B #&gt; torch_tensor #&gt; 1.5134 2.7426 3.7159 #&gt; 4.5705 5.1653 6.0443 #&gt; [ CPUFloatType{2,3} ] 결과에서 알 수 있듯, 정수를 담을 수 있는 텐서와 실수를 담을 수 있는 텐서를 더하면, 결과는 실수를 담을 수 있는 텐서로 반환이 된다. 하지만, 필자는 이러한 코딩은 피해야 한다고 생각한다. 즉, 모든 연산을 할 경우, 명시적으로 형변환을 한 후 연산을 할 것을 권한다. 왜냐하면, 언제나 우리는 코드를 다른 사람이 보았을 때, 이해하기 쉽도록 짜는 것을 추구해야 한다. (코드는 하나의 자신의 생각을 적은 글이다.) 2.2.4 상수와의 연산 R에서와 마찬가지로, 텐서와 상수와의 사칙연산은 각 원소에 적용되는 것을 확인하자. A + 2 #&gt; torch_tensor #&gt; 3 4 5 #&gt; 6 7 8 #&gt; [ CPUDoubleType{2,3} ] B^2 #&gt; torch_tensor #&gt; 0.2636 0.5514 0.5125 #&gt; 0.3254 0.0273 0.0020 #&gt; [ CPUFloatType{2,3} ] A %/% 3 #&gt; torch_tensor #&gt; 0 0 1 #&gt; 1 1 2 #&gt; [ CPUDoubleType{2,3} ] A %% 3 #&gt; torch_tensor #&gt; 1 2 0 #&gt; 1 2 0 #&gt; [ CPUDoubleType{2,3} ] 2.2.5 제곱근과 로그 제곱근(square root)나 로그(log) 함수 역시 각 원소별 적용이 가능하다. A #&gt; torch_tensor #&gt; 1 2 3 #&gt; 4 5 6 #&gt; [ CPUDoubleType{2,3} ] torch_sqrt(A) #&gt; torch_tensor #&gt; 1.0000 1.4142 1.7321 #&gt; 2.0000 2.2361 2.4495 #&gt; [ CPUDoubleType{2,3} ] 위의 연산이 에러가 나는 이유는 A가 정수를 담는 텐서였는데, 연산을 수행한 후에 실수가 담겨져서 나오는 에러이다. R과는 사뭇다른 예민한 아이 torch를 위해 형을 바꿔준 후에 연산을 실행하도록 하자. torch_sqrt(A$to(dtype = torch_double())) #&gt; torch_tensor #&gt; 1.0000 1.4142 1.7321 #&gt; 2.0000 2.2361 2.4495 #&gt; [ CPUDoubleType{2,3} ] torch_log(B) #&gt; torch_tensor #&gt; -0.6667 -0.2977 -0.3342 #&gt; -0.5613 -1.8002 -3.1166 #&gt; [ CPUFloatType{2,3} ] 2.2.6 텐서의 곱셈 텐서의 곱셈 역시 모양이 맞아야 하므로, 3행 2열이 두개가 붙어있는 C에서 앞에 한장을 떼어내도록 하자. B #&gt; torch_tensor #&gt; 0.5134 0.7426 0.7159 #&gt; 0.5705 0.1653 0.0443 #&gt; [ CPUFloatType{2,3} ] D &lt;- C[1,,] D #&gt; torch_tensor #&gt; 0.9628 0.2943 #&gt; 0.0992 0.8096 #&gt; 0.0169 0.8222 #&gt; [ CPUFloatType{3,2} ] 텐서의 곱셈은 torch_matmul() 함수를 사용한다. # 파이프 사용해도 무방하다. # B %&gt;% torch_matmul(D) torch_matmul(B, D) #&gt; torch_tensor #&gt; 0.5800 1.3409 #&gt; 0.5664 0.3381 #&gt; [ CPUFloatType{2,2} ] 토치의 텐서 곱셈은 다음과 같은 방법들도 있으니 알아두자. torch_mm(B, D) #&gt; torch_tensor #&gt; 0.5800 1.3409 #&gt; 0.5664 0.3381 #&gt; [ CPUFloatType{2,2} ] B$mm(D) #&gt; torch_tensor #&gt; 0.5800 1.3409 #&gt; 0.5664 0.3381 #&gt; [ CPUFloatType{2,2} ] B$matmul(D) #&gt; torch_tensor #&gt; 0.5800 1.3409 #&gt; 0.5664 0.3381 #&gt; [ CPUFloatType{2,2} ] 2.2.7 텐서의 전치(transpose) 전치(transpose)는 주어진 텐서를 뒤집는 것인데, 다음의 문법 구조를 가지고 있다. torch_transpose(input, dim0, dim1) dim0, dim1는 바꿀 차원을 의미한다. ‘바꿀 차원은 두 개 밖에 없지 않나?’ 라고 생각할 수 있다. 2 차원 텐서의 경우에는 그렇다. 우리가 행렬을 전치하는 경우에는 transpose를 취하는 대상이 2차원이므로 지정해주는 차원이 정해져있다. 하지만, 텐서의 차원이 3차원 이상이 되면 전치를 해주는 차원을 지정해줘야한다. A #&gt; torch_tensor #&gt; 1 2 3 #&gt; 4 5 6 #&gt; [ CPUDoubleType{2,3} ] 위의 텐서 A의 차원은 행과 열, 즉, 2개이다. 다음의 코드들은 A 텐서의 첫번째 차원과 두번째 차원을 뒤집는 효과를 가져온다. 즉, 전치 텐서가 된다. torch_transpose(A, 1, 2) #&gt; torch_tensor #&gt; 1 4 #&gt; 2 5 #&gt; 3 6 #&gt; [ CPUDoubleType{3,2} ] A$transpose(1, 2) #&gt; torch_tensor #&gt; 1 4 #&gt; 2 5 #&gt; 3 6 #&gt; [ CPUDoubleType{3,2} ] A %&gt;% torch_transpose(1, 2) #&gt; torch_tensor #&gt; 1 4 #&gt; 2 5 #&gt; 3 6 #&gt; [ CPUDoubleType{3,2} ] 3차원의 텐서를 살펴보자. C #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 0.9628 0.2943 #&gt; 0.0992 0.8096 #&gt; 0.0169 0.8222 #&gt; #&gt; (2,.,.) = #&gt; 0.1242 0.7489 #&gt; 0.3608 0.5131 #&gt; 0.2959 0.7834 #&gt; [ CPUFloatType{2,3,2} ] 텐서 C는 위와 같이 2차원 텐서가 두 개 포개져 있다고 생각하면 된다. 텐서의 결과물을 잘 살펴보면, 제일 앞에 위치한 1, 2가 나타내는 것이 우리가 흔히 생각하는 2차원 텐서들의 색인(index) 역할을 한다는 것을 알 수 있다. 앞으로는 편의를 위해서 3차원 텐서의 색인 역할을 하는 차원을 깊이(depth)라고 부르도록 하자. 앞에서 주어진 텐서 C 안의 포개져있는 2차원 텐서들을 전치하기 위해서는 이들을 관할(?)하는 두번째와 세번째 차원을 바꿔줘야 한다. torch_transpose(C, 2, 3) #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 0.9628 0.0992 0.0169 #&gt; 0.2943 0.8096 0.8222 #&gt; #&gt; (2,.,.) = #&gt; 0.1242 0.3608 0.2959 #&gt; 0.7489 0.5131 0.7834 #&gt; [ CPUFloatType{2,2,3} ] 결과를 살펴보면, 잘 바뀌어 있음을 알 수 있다. 2.2.8 R에서의 3차원 배열 앞에서 다룬 torch에서의 3차원 텐서 부분은 R에서 기본적으로 제공하는 array의 문법과 차이가 난다. 다음의 코드를 살펴보자. 먼저 R에서 2행 3열의 행렬을 두 개 포개어 놓은 3차원 배열을 만드는 코드이다. array(1:12, c(2, 3, 2)) #&gt; , , 1 #&gt; #&gt; [,1] [,2] [,3] #&gt; [1,] 1 3 5 #&gt; [2,] 2 4 6 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] [,3] #&gt; [1,] 7 9 11 #&gt; [2,] 8 10 12 필자는 참고로 matrix()를 만들때에도 byrow 옵션을 써서 만드는 것을 좋아하는데, array()에서 byrow 옵션 효과를 적용하려면 aperm() 함수를 사용해야 한다. 따라서, 좀 더 직관적으로 쓰기위해서 다음의 함수를 사용하자. array_3d_byrow &lt;- function(num_vec, nrow, ncol, ndeath){ aperm(array(num_vec, c(ncol, nrow, ndeath)), c(2, 1, 3)) } E &lt;- array_3d_byrow(1:12, 2, 3, 2) E #&gt; , , 1 #&gt; #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] [,3] #&gt; [1,] 7 8 9 #&gt; [2,] 10 11 12 이러한 코드를 앞서 배웠던 torch_tensor() 함수에 넣어보자. E %&gt;% torch_tensor() #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 1 7 #&gt; 2 8 #&gt; 3 9 #&gt; #&gt; (2,.,.) = #&gt; 4 10 #&gt; 5 11 #&gt; 6 12 #&gt; [ CPULongType{2,3,2} ] 결과를 살펴보면, 우리가 예상했던 2행 3열의 텐서가 두개 겹쳐있는 텐서의 모양이 나오지 않는다는 것을 알 수 있다. 이유는 torch에서 정의된 3차원 텐서의 경우, 첫번째 차원이 텐서가 얼마나 겹쳐있는지를 나타내는 깊이(depth)를 나타내기 때문이다. 문제를 해결하기 위해서는 aperm() 사용해서 차원을 바꿔주면 된다. E %&gt;% aperm(c(3, 1, 2)) %&gt;% # 3 번째 차원을 맨 앞으로, 나머지는 그대로 torch_tensor() #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 1 2 3 #&gt; 4 5 6 #&gt; #&gt; (2,.,.) = #&gt; 7 8 9 #&gt; 10 11 12 #&gt; [ CPULongType{2,2,3} ] 위의 경우를 좀더 직관적인 함수명으로 바꿔서 사용하도록 하자. array_to_torch &lt;- function(mat, n_dim = 3){ torch_tensor(aperm(mat, c(n_dim:3, 1, 2))) } E &lt;- array_to_torch(E) E #&gt; torch_tensor #&gt; (1,.,.) = #&gt; 1 2 3 #&gt; 4 5 6 #&gt; #&gt; (2,.,.) = #&gt; 7 8 9 #&gt; 10 11 12 #&gt; [ CPULongType{2,2,3} ] 2.2.9 다차원 텐서와 1차원 벡터 텐서의 연산 R에서 우리가 아주 애용하는 기능 중 하나가 바로 recycling 개념이다. 즉, 길이 혹은 모양이 맞지 않는 개체(object)들을 연산할 때, 자동으로 길이와 모양을 맞춰서 연산을 해주는 기능인데, torch에서도 이러한 기능을 제공한다. 다음의 코드를 살펴보자. A #&gt; torch_tensor #&gt; 1 2 3 #&gt; 4 5 6 #&gt; [ CPUDoubleType{2,3} ] A + torch_tensor(1:3) #&gt; torch_tensor #&gt; 2 4 6 #&gt; 5 7 9 #&gt; [ CPUDoubleType{2,3} ] A #&gt; torch_tensor #&gt; 1 2 3 #&gt; 4 5 6 #&gt; [ CPUDoubleType{2,3} ] A + torch_tensor(matrix(2:3, ncol = 1)) #&gt; torch_tensor #&gt; 3 4 5 #&gt; 7 8 9 #&gt; [ CPUDoubleType{2,3} ] 2.2.10 1차원 텐서 끼리의 연산, 내적과 외적 1차원 텐서끼리의 연산도 2차원 텐서끼리의 연산과 마찬가지라고 생각하면 된다. 내적과 외적 역시 그냥 모양을 맞춰서 곱하면 된다. A_1 &lt;- A$view(c(1, -1)) A_1 #&gt; torch_tensor #&gt; 1 2 3 4 5 6 #&gt; [ CPUDoubleType{1,6} ] A_2 &lt;- A$view(c(-1, 1)) A_2 #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; 5 #&gt; 6 #&gt; [ CPUDoubleType{6,1} ] A_1$mm(A_2) #&gt; torch_tensor #&gt; 91 #&gt; [ CPUDoubleType{1,1} ] A_2$mm(A_1) #&gt; torch_tensor #&gt; 1 2 3 4 5 6 #&gt; 2 4 6 8 10 12 #&gt; 3 6 9 12 15 18 #&gt; 4 8 12 16 20 24 #&gt; 5 10 15 20 25 30 #&gt; 6 12 18 24 30 36 #&gt; [ CPUDoubleType{6,6} ] 한가지 주의할 점은 1차원 텐서끼리의 연산이더라도 꼭 차원을 선언해줘서 열벡터와 행벡터를 분명히 해줘야 한다는 점이다. A_3 &lt;- torch_tensor(1:6) A_1$mm(A_3) #&gt; Error in (function (self, mat2) : mat2 must be a matrix #&gt; Exception raised from mm_cpu at ../aten/src/ATen/native/LinearAlgebra.cpp:399 (most recent call first): #&gt; frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x69 (0x7f692199db89 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libc10.so) #&gt; frame #1: at::native::mm_cpu(at::Tensor const&amp;, at::Tensor const&amp;) + 0x334 (0x7f69117ec194 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #2: &lt;unknown function&gt; + 0x133236d (0x7f6911d0c36d in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #3: &lt;unknown function&gt; + 0xaf1c34 (0x7f69114cbc34 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #4: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;) const + 0x1ce (0x7f6911eb424e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #5: at::mm(at::Tensor const&amp;, at::Tensor const&amp;) + 0xb7 (0x7f6911d9a947 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #6: &lt;unknown function&gt; + 0x2a5db24 (0x7f6913437b24 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #7: &lt;unknown function&gt; + 0xaf1c34 (0x7f69114cbc34 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #8: at::Tensor c10::Dispatcher::callWithDispatchKey&lt;at::Tensor, at::Tensor const&amp;, at::Tensor const&amp;&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;)&gt; const&amp;, c10::DispatchKey, at::Tensor const&amp;, at::Tensor const&amp;) const + 0x1ce (0x7f6911eb424e in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #9: at::Tensor::mm(at::Tensor const&amp;) const + 0xb7 (0x7f691201dd67 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/./libtorch_cpu.so) #&gt; frame #10: _lantern_Tensor_mm_tensor_tensor + 0x4c (0x7f6921cdb79c in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/deps/liblantern.so) #&gt; frame #11: cpp_torch_method_mm_self_Tensor_mat2_Tensor(Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;, Rcpp::XPtr&lt;XPtrTorchTensor, Rcpp::PreserveStorage, &amp;(void Rcpp::standard_delete_finalizer&lt;XPtrTorchTensor&gt;(XPtrTorchTensor*)), false&gt;) + 0x2c (0x7f692260d4fc in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) #&gt; frame #12: _torch_cpp_torch_method_mm_self_Tensor_mat2_Tensor + 0x82 (0x7f69223b2f22 in /home/issac/R/x86_64-pc-linux-gnu-library/4.0/torch/libs/torchpkg.so) #&gt; frame #13: &lt;unknown function&gt; + 0xf932c (0x7f693801832c in /usr/lib/R/lib/libR.so) #&gt; frame #14: &lt;unknown function&gt; + 0xf9826 (0x7f6938018826 in /usr/lib/R/lib/libR.so) #&gt; frame #15: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #16: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #17: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #18: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #19: Rf_eval + 0x353 (0x7f69380628c3 in /usr/lib/R/lib/libR.so) #&gt; frame #20: &lt;unknown function&gt; + 0xc650d (0x7f6937fe550d in /usr/lib/R/lib/libR.so) #&gt; frame #21: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #22: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #23: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #24: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #25: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #26: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #27: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #28: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #29: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #30: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #31: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #32: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #33: Rf_eval + 0x353 (0x7f69380628c3 in /usr/lib/R/lib/libR.so) #&gt; frame #34: &lt;unknown function&gt; + 0x1470a2 (0x7f69380660a2 in /usr/lib/R/lib/libR.so) #&gt; frame #35: Rf_eval + 0x572 (0x7f6938062ae2 in /usr/lib/R/lib/libR.so) #&gt; frame #36: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #37: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #38: Rf_eval + 0x353 (0x7f69380628c3 in /usr/lib/R/lib/libR.so) #&gt; frame #39: &lt;unknown function&gt; + 0x149782 (0x7f6938068782 in /usr/lib/R/lib/libR.so) #&gt; frame #40: &lt;unknown function&gt; + 0x137106 (0x7f6938056106 in /usr/lib/R/lib/libR.so) #&gt; frame #41: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #42: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #43: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #44: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #45: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #46: &lt;unknown function&gt; + 0x1440ac (0x7f69380630ac in /usr/lib/R/lib/libR.so) #&gt; frame #47: Rf_eval + 0x454 (0x7f69380629c4 in /usr/lib/R/lib/libR.so) #&gt; frame #48: &lt;unknown function&gt; + 0x14a22c (0x7f693806922c in /usr/lib/R/lib/libR.so) #&gt; frame #49: &lt;unknown function&gt; + 0x1871fd (0x7f69380a61fd in /usr/lib/R/lib/libR.so) #&gt; frame #50: &lt;unknown function&gt; + 0x1353c4 (0x7f69380543c4 in /usr/lib/R/lib/libR.so) #&gt; frame #51: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #52: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #53: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #54: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #55: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #56: &lt;unknown function&gt; + 0x1440ac (0x7f69380630ac in /usr/lib/R/lib/libR.so) #&gt; frame #57: &lt;unknown function&gt; + 0x1444e4 (0x7f69380634e4 in /usr/lib/R/lib/libR.so) #&gt; frame #58: &lt;unknown function&gt; + 0x1377d4 (0x7f69380567d4 in /usr/lib/R/lib/libR.so) #&gt; frame #59: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) #&gt; frame #60: &lt;unknown function&gt; + 0x14550f (0x7f693806450f in /usr/lib/R/lib/libR.so) #&gt; frame #61: Rf_applyClosure + 0x1c7 (0x7f69380652d7 in /usr/lib/R/lib/libR.so) #&gt; frame #62: &lt;unknown function&gt; + 0x13a989 (0x7f6938059989 in /usr/lib/R/lib/libR.so) #&gt; frame #63: Rf_eval + 0x180 (0x7f69380626f0 in /usr/lib/R/lib/libR.so) 위의 코드는 연산 에러가 나는데, 이유는 A_3의 모양이 A_1의 모양과 맞지 않기 때문이다. A_1$size() #&gt; [1] 1 6 A_3$size() #&gt; [1] 6 "],["텐서의-이동-cpu-leftrightarrow-gpu.html", "Chapter 3 텐서의 이동; CPU \\(\\leftrightarrow\\) GPU 3.1 GPU 사용 가능 체크 3.2 CPU to GPU 3.3 GPU to CPU", " Chapter 3 텐서의 이동; CPU \\(\\leftrightarrow\\) GPU 딥러닝(deep learning)에서는 네트워크의 구조가 조금만 복잡해져도, 필요한 계산량이 엄청나게 늘어나기 때문에 GPU는 사실 필수적이다. torch 패키지에서는 텐서를 다룰때에 현재 다루는 텐서가 어디에 저장되어있는가에 대한 일종의 태그를 달아놓는다. 다음의 코드를 살펴보자. a &lt;- torch_tensor(1:4) a #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CPULongType{4} ] a는 3이라는 상수가 담겨있는 텐서이다. 이 a를 콘솔에서 돌렸을때에 나오는 결과 [ CPUFloatType{1} ]를 통해서 우리는 a가 현재 CPU의 메모리를 이용하고 있으며, 모양은 {1}인 실수을 담은 텐서라는 것을 알 수 있다. 3.1 GPU 사용 가능 체크 앞서 정의한 텐서 a를 GPU의 메모리로 옮기기 위해서는, 너무나 당연하게 GPU가 현재 시스템에서 접근 가능한지에 대하여 알아보아야한다. GPU 접근성은 cuda_is_available()을 사용한다. cuda_is_available() #&gt; [1] TRUE 3.2 CPU to GPU 이미 정의된 텐서 a를 GPU로 옮기려면 다음과 같이 cuda() 함수를 이용하면 된다. a #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CPULongType{4} ] a$cuda() #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CUDALongType{4} ] gpu &lt;- torch_device(&quot;cuda&quot;) a$to(device = gpu) #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CUDALongType{4} ] 옮길 때에 dtype을 사용하여 다음과 같이 자료형을 바꿔줄 수도 있다. a$to(device = gpu, dtype = torch_double()) #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CUDADoubleType{4} ] 3.3 GPU to CPU GPU 상에 직접 텐서를 만드는 방법은 다음과 같다. b &lt;- torch_tensor(1:4, device=gpu) b #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CUDALongType{4} ] 이전 섹션에서 CPU에서 GPU로 옮기는 방법과 비슷하게 다음의 코드가 작동한다. b$cpu() #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CPULongType{4} ] # to 함수 이용 cpu &lt;- torch_device(&quot;cpu&quot;) a$to(device = cpu) #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; 3 #&gt; 4 #&gt; [ CPULongType{4} ] "],["r6.html", "Chapter 4 R6와 텐서 4.1 시작하기 4.2 클래스(Class)와 멤버함수(Method), 그리고 필드(Field) 4.3 상속(Inheritance) - 클래스 물려받기 4.4 공개(Public)정보와 비공개(Private) 정보의 필요성 4.5 텐서와 R6의 관계 4.6 R6 관련자료", " Chapter 4 R6와 텐서 torch의 코드를 살펴보면 우리가 늘상 사용하던 R의 패키지들과는 어딘가 다른점이 있다고 느껴질 것이다. 이것의 근본적인 이유는 바로 torch 패키지가 객체지향언어 (Object Oriented Programming; OOP)를 할 수 있도록 해주는 R6 패키지를 기반으로 하고있기 때문이다. 좀 더 직접적으로 말하면, torch의 텐서와 신경망들이 R6 패키지의 클래스들로 정의되어 있기 때문에, 일반적인 R 패키지들보다 $을 통한 함수(OOP에서는 method 라고 부른다.) 접근이 가능하다. 어떤 이야기인지 한번 좀 더 깊게 들어가보자. 4.1 시작하기 여느 패키지와 다를바가 없다. R6 패키지를 설치하도록 하자. # install.packages(&quot;R6&quot;) library(R6) 4.2 클래스(Class)와 멤버함수(Method), 그리고 필드(Field) R6 패키지에는 딱 하나의 함수가 존재한다. 바로 R6Class() 함수이다. 이 함수의 입력값은 두가지 인데, 첫번째는 클래스 이름 clasename이고, 두번째는 공개될 정보들을 담을 public이라는 입력값이다. public에는 우리가 만들 클래스에서 사용이 가능한 멤버함수들(methods)과 변수(fields)들을 몽땅 다 떼려넣은 리스트(list) 형태가 들어간다. ExampleClass &lt;- R6Class(classname = &quot;Example&quot;, public = list( # 변수(fields) 정의 # 멤버함수(methods) 정의 )) ExampleClass #&gt; &lt;Example&gt; object generator #&gt; Public: #&gt; clone: function (deep = FALSE) #&gt; Parent env: &lt;environment: R_GlobalEnv&gt; #&gt; Locked objects: TRUE #&gt; Locked class: FALSE #&gt; Portable: TRUE 한가지 꼭 짚고 넘어가야하는 것이 있는데, 바로 이름을 정하는 방식이다. 클래스의 이름은 UpperCamelCase 형식으로 짓는다. 즉, 클래스의 이름을 선언할 때 띄어쓰기를 하지않고, 대신 대문자를 사용한다. 두번째 리스트에 들어가는 요소들의 이름은 snake_case를 사용한다. 즉, 모두 소문자를 유지하고, 띄어쓰기 대신에 밑줄을 사용하여 선언한다. 이렇게 규칙을 따라서 작성하게 되면, 나중에 다른 사람이 짜놓은 코드를 보게 되더라도, 선언된 이름의 구조를 보고, 이게 클래스인지, 클래스 안에 정의된 함수 혹은 변수인지를 구분 할 수 있어서 좋다. 4.2.1 클래스는 왜 필요할까? 필자도 클래스의 개념을 처음 들었을때 대체 이게 무슨 소리인지.. 했던 기억이 있다. 심지어 필자의 경우 R밖에 모르던 터여서, OOP가 필요가 있는지에 대한 의문까지 들 정도였으니, (사실 지금도 생각이 많이 바뀌지 않았다.) 머리에 아예 들어오지를 않았다. 그런 필자를 클래스 개념에 대하여 한방에 이해시킨 예제가 바로 학생 클래스이다. 자고로 모든 개념은 예를 들어 설명을 하는 것이 아주 효과적이라고 필자는 믿고있다. &gt; 목표: OOP의 개념와 왜 사용을 하는지에 대하여 이해한다. 4.2.2 학생자료 입력 예제 다음의 코드를 생각해보자. student &lt;- function(){ list() } issac &lt;- student() bomi &lt;- student() issac #&gt; list() bomi #&gt; list() student라는 함수는 빈 리스트를 반환을 하는데, 우리가 이 함수를 사용하여 issac과 bomi라는 학생의 정보를 담는 리스트를 만들 수 있다. 만약 우리가 다음과 같은 추가 정보를 저장하려고 한다고 가정해보자. issac last name: Lee first name: Issac email: issac-lee@gmail.com midterm: 70 final: 50 bomi last name: Kim first name: Bomi email: bomi-kim@gmail.com midterm: 65 final: 80 위의 정보를 저장하기 위해서는 다음과 같이 $ 기호를 통하여 저장할 수 있다. issac$first &lt;- &quot;Issac&quot; issac$last &lt;- &quot;Lee&quot; issac$email &lt;- &quot;issac-lee@gmail.com&quot; issac$midterm &lt;- 70 issac$final &lt;- 50 bomi$first &lt;- &quot;Bomi&quot; bomi$last &lt;- &quot;Kim&quot; bomi$email &lt;- &quot;bomi-kim@gmail.com&quot; bomi$midterm &lt;- 65 bomi$final &lt;- 80 issac #&gt; $first #&gt; [1] &quot;Issac&quot; #&gt; #&gt; $last #&gt; [1] &quot;Lee&quot; #&gt; #&gt; $email #&gt; [1] &quot;issac-lee@gmail.com&quot; #&gt; #&gt; $midterm #&gt; [1] 70 #&gt; #&gt; $final #&gt; [1] 50 bomi #&gt; $first #&gt; [1] &quot;Bomi&quot; #&gt; #&gt; $last #&gt; [1] &quot;Kim&quot; #&gt; #&gt; $email #&gt; [1] &quot;bomi-kim@gmail.com&quot; #&gt; #&gt; $midterm #&gt; [1] 65 #&gt; #&gt; $final #&gt; [1] 80 위의 코드는 OOP관점에서 상당히 중복 코드가 많은 비효율적인 코드이다. 이러한 코드를 우리가 배운 R6Class()를 사용하여 어떻게 줄일 수 있는지 알아보자. 4.2.3 클래스(Class) 정의하기 앞에서 우리는 issac과 bomi라는 변수를 생성했는데, 둘의 공통점은 학생이라는 점이었다. 사실 앞선 코드를 작성을 한다는 것은 issac과 bomi 뿐 아니라 엄청 많은 수의 학생들에 대한 데이터를 다루고 있는 상황일 수도 있다. 우리들이 써놓은 코드를 잘 뜯어보니, 학생 데이터로 입력되는 각 개인들은 성과 이름, 이메일, 그리고, 중간, 기말고사 점수의 정보들을 가지고 있다. 즉, 학생, Student, 라는 클래스는 항상 성(last)과 이름(first), 중간(midterm), 기말고사(final) 성적이 저장되어 있고, 이메일의 경우 이름과 성을 이용해서 작성을 하되, 모두 소문자로 입력된 자료 형태를 가지고 있는 구조를 갖는 어떤 추상적인 개념이라는 것을 알 수 있다. 이러한 정보를 사용하여 우리는 다음과 같이 Student 클래스를 선언 할 수 있다. Student &lt;- R6Class(&quot;Student&quot;, list( # 필요한 변수 (field) 선언 first = NULL, last = NULL, email = NULL, midterm = NA, final = NA, # 클래스 안의 객체를 만들때 사용되는 initialize initialize = function(first, last, midterm, final){ self$first = first self$last = last self$email = glue::glue(&quot;{tolower(first)}-{tolower(last)}@gmail.com&quot;) self$midterm = midterm self$final = final } )) Student #&gt; &lt;Student&gt; object generator #&gt; Public: #&gt; first: NULL #&gt; last: NULL #&gt; email: NULL #&gt; midterm: NA #&gt; final: NA #&gt; initialize: function (first, last, midterm, final) #&gt; clone: function (deep = FALSE) #&gt; Parent env: &lt;environment: R_GlobalEnv&gt; #&gt; Locked objects: TRUE #&gt; Locked class: FALSE #&gt; Portable: TRUE 결과값을 유심히 살펴보면, &lt;Student&gt; object generator 라는 부분이 있는데, Student 라는 클래스는 객체(object)들을 만들어내는 생성자(generator)라는 것을 알 수 있다. 우리가 만들 Student 생성자를 통해서 도장을 찍듯, new() 함수를 사용하여 issac과 bomi를 다음과 같이 만들 수 있다. issac &lt;- Student$new(&quot;Issac&quot;, &quot;Lee&quot;, 70, 50) bomi &lt;- Student$new(&quot;Bomi&quot;, &quot;Kim&quot;, 65, 80) issac #&gt; &lt;Student&gt; #&gt; Public: #&gt; clone: function (deep = FALSE) #&gt; email: issac-lee@gmail.com #&gt; final: 50 #&gt; first: Issac #&gt; initialize: function (first, last, midterm, final) #&gt; last: Lee #&gt; midterm: 70 bomi #&gt; &lt;Student&gt; #&gt; Public: #&gt; clone: function (deep = FALSE) #&gt; email: bomi-kim@gmail.com #&gt; final: 80 #&gt; first: Bomi #&gt; initialize: function (first, last, midterm, final) #&gt; last: Kim #&gt; midterm: 65 즉, OOP의 장점은 공을 들여 한번 클래스를 잘 만들어놓으면, 한번 작성된 함수나 변수들의 재 사용율이 엄청 좋아지는 것이다. 4.2.4 print()를 사용한 결과물 정리 정의된 클래스는 기본적으로 동작하는 함수들을 덮어서 쓸 수 있다. 예를들어 print()를 함수로 정의해버리면, base에 있는 print() 동작을 덮어서 쓸 수 있다. 즉, 기본 함수들 print(), plot() 같은 함수들을 우리가 정의한 클래스에서 나온 객체들에 적용했을때의 작동을 정해줄 수 있다는 것이다. Student &lt;- R6Class(&quot;Student&quot;, list( # 필요한 변수 (field) 선언 first = NULL, last = NULL, email = NULL, midterm = NA, final = NA, # 클래스 안의 객체를 만들때 사용되는 initialize initialize = function(first, last, midterm, final){ self$first = first self$last = last self$email = glue::glue(&quot;{tolower(first)}-{tolower(last)}@gmail.com&quot;) self$midterm = midterm self$final = final }, print = function(...){ cat(&quot;Student: \\n&quot;) cat(glue::glue(&quot; Name : {self$first} {self$last} E-mail: {self$email} Midterm Score : {self$midterm} Final Score: {self$final} &quot;)) invisible(self) } )) soony &lt;- Student$new(&quot;Soony&quot;, &quot;Kim&quot;, 70, 20) soony #&gt; Student: #&gt; Name : Soony Kim #&gt; E-mail: soony-kim@gmail.com #&gt; Midterm Score : 70 #&gt; Final Score: 20 print() 멤버 함수를 추가한 후에 만들어진 soony의 정보는 클래스안에 정의된 print()를 통해서 보여진다는 것을 확인할 수 있다. 한가지 주의할 점은 print()가 클래스 안에 정의되어 있지 않은 채로 생성된 issac과 bomi의 경우는 print()가 작동하지 않는다는 것이다. 즉, 클래스에 정의된 함수들은 객체가 클래스로부터 생성될 때, 따라와서 붙는다. issac$print() #&gt; Error in eval(expr, envir, enclos): attempt to apply non-function soony$print() #&gt; Student: #&gt; Name : Soony Kim #&gt; E-mail: soony-kim@gmail.com #&gt; Midterm Score : 70 #&gt; Final Score: 20 4.2.5 set을 이용한 클래스 조정 앞에서 우리는 print() 함수를 추가하기 위하여 전체 클래스를 다시 정의하였다. 하지만, 이렇게 클래스안에 함수를 추가하기 위해서 전체 클래스를 다시 정의하기보단, set()을 이용해서 변수나 함수를 추가할 수 있다. Student$set(&quot;public&quot;, &quot;total&quot;, NA) Student$set(&quot;public&quot;, &quot;calculate_total&quot;, function(){ self$total &lt;- self$midterm + self$final invisible(self) }) invisible() 함수는 결과를 반환하되, 결과물을 보여주지 않는 것인데, 클래스에서 함수를 정의할 때에 반드시 invisible(self)를 반환해줘야만 한다. 따라서 함수이지만, 함수와는 다른 이 클래스 안의 함수들을 멤버함수 method()라고하여 일반 함수와 구분을 지어서 부른다. jelly &lt;- Student$new(&quot;Jelly&quot;, &quot;Lee&quot;, 35, 23) jelly #&gt; Student: #&gt; Name : Jelly Lee #&gt; E-mail: jelly-lee@gmail.com #&gt; Midterm Score : 35 #&gt; Final Score: 23 jelly$total #&gt; [1] NA jelly$calculate_total() jelly$total #&gt; [1] 58 4.3 상속(Inheritance) - 클래스 물려받기 OOP가 코드의 중복을 되도록 피할 수 있도록 설계되어 있다는 것을 어렴풋이나마 앞의 예제를 통하여 알 수 있을 것이다. 이러한 OOP의 코드 재사용 관점에서 상속(Inheritance)의 개념은 꽃 중에 꽃이라 불릴 만하다. 단 한 줄의 코드로 미리 작성해놓은 함수들에 접근이 가능하기 때문이다. 상속(Inheritance)이라고 하면 뭔가 거창할 것 같지만, 그냥 미리 정의해둔 클래스의 정보(멤버함수과 필드)를 다른 클래스를 정의할 때 받아올 수 있다는 말이다. 예를 들어보자. 이제까지 사용해 온 학생 개념, Student 클래스를 좀 더 세분화를 한다면 학교별로 나눌 수 있을 것이다. Student 클래스를 상속받는 슬통대학교(University of Statistics Playbook; USP) 학생들을 위한 서브 클래스(sub class)는 다음과 같이 생성할 수 있다. UspStudent &lt;- R6Class(&quot;UspStudent&quot;, inherit = Student, public = list( university_name = &quot;University of Statistics Playbook&quot;, class_year = NA, average = NA, calculate_average = function(){ self$average &lt;- mean(c(self$midterm, self$final)) invisible(self) }, calculate_total = function(){ cat(&quot;The total score of midterm and final exam is calculated. \\n&quot;) super$calculate_total() } ) ) sanghoon &lt;- UspStudent$new(&quot;Sanghoon&quot;, &quot;Park&quot;, 80, 56) sanghoon #&gt; Student: #&gt; Name : Sanghoon Park #&gt; E-mail: sanghoon-park@gmail.com #&gt; Midterm Score : 80 #&gt; Final Score: 56 새로 정의된 UspStudent 클래스는 상위 클래스인 Student 클래스의 멤버함수들과 변수들을 그대로 물려받는다. 여기서 코드의 재사용성이 증가한다. 또한 상위 클래스가 가지고 있던 calculate_total() 멤버함수에 접근하여, 새롭게 고쳐서 사용하는 것도 가능하다. 다음은 정의된 멤버함수들을 사용하여 변수들에 계산을 해서 넣는 과정을 보여준다. sanghoon$university_name #&gt; [1] &quot;University of Statistics Playbook&quot; sanghoon$calculate_average() sanghoon$average #&gt; [1] 68 sanghoon$calculate_total() #&gt; The total score of midterm and final exam is calculated. sanghoon$total #&gt; [1] 136 4.4 공개(Public)정보와 비공개(Private) 정보의 필요성 앞에서 살펴본 R6Class() 함수의 두 가지 입력값은 클래스 이름(classname)과 공개정보(public) 였다. 클래스를 만들고 사용하다보면, 때로는 클래스 안의 함수들을 사용하기 위해서 만들어야하는 변수나 함수들이 있는데, 이러한 정보들은 굳이 클래스를 사용하는 사용자들에게 보여줄 필요가 없다. 우리네 인생도 그러하다. 우리는 때로는 너무 많은 정보 제공에 피로감과 불편을 겪는 경우가 많다. 따라서, 클래스에 대한 정보의 접근을 적절하게 조절할 필요가 있는데, 클래스의 정보들을 공개될 정보(public)와 비공개 정보(private)들로 분류함으로써 조절할 수 있다. UspStudent &lt;- R6Class(&quot;UspStudent&quot;, inherit = Student, public = list( university_name = &quot;University of Statistics Playbook&quot;, class_year = NA, calculate_average = function(){ private$.average &lt;- mean(c(self$midterm, self$final)) cat(&quot;Average score is&quot;, private$.average) invisible(self) }, calculate_total = function(){ cat(&quot;The total score of midterm and final exam is calculated. \\n&quot;) super$calculate_total() } ), private = list( .average = NA ) ) taemo &lt;- UspStudent$new(&quot;Taemo&quot;, &quot;Bang&quot;, 80, 56) taemo$calculate_average() #&gt; Average score is 68 위의 UspStudent 클래스에는 비공개 정보가 하나들어있다. 바로 중간 기말고사 점수의 평균을 저장하는 average 변수인데, 클래스의 정의시 private()에 감싸져서 입력이 되었음에 주목하자. average 변수는 클래스 안에서의 멤버함수를 통해서 접근할 땐 private$name 형식으로 접근이 가능함에 반하여, 클래스를 사용하는 사용자 입장에서는 가려져서 보이지 않는 정보에 해당한다. taemo$.average #&gt; NULL 해들리 위캠의 말을 빌리면, 공개-비공개 정보의 구분은 큰 패키지나 클래스를 정의할 때 가장 중요한 단계가 된다. 왜냐하면 비공개 정보의 경우는 개발자의 입장에서 언제든지 수정할 수 있는 정보가 되지만, 공개된 멤버함수나 필드들에 대해서는 쉽게 바꿀 수가 없기 때문이다. &gt; 여기서 하나 짚고 넘어가면 좋은 것이 있는데, 바로 R에서의 이름 짓기 방식이다. R의 기본 함수들 중에서 .을 사용해서 지어진 경우가 있는데, 현재는 권장하지 않고 있다. 이유는 바로 비공개 정보를 갖는 변수나 함수들을 나타내는데에 .을 찍어서 나타내기 때문이다. `.average` 역시 변수의 이름에서 이 변수는 클래스 안에서만 접근이 가능하다는 것을 변수 이름만 보고도 알 수 있도록 만들어졌다. 4.4.1 활성 변수(active field)를 사용한 읽기 전용 변수 Advance R의 14장의 내용을 보면, R6의 접근성을 다루면서 active field의 개념이 나온다. 자세한 내용이 궁금한 독자들은 찾아보기 바란다. active field의 좋은 점은 이것을 사용해서 클래스 사용자들에게 읽기 전용 정보를 제공해줄수 있기 때문이다. 앞에서의 예를 들어보면 중간, 기말고사의 평균 정보는 클래스 사용자들에게 유요한 정보가 될 수 있다. 하지만, private으로 감싸버리면 사용자들은 이 정보에 접근을 할 수 없게 된다. 사용자는 평균 정보에 접근하고 싶어하지만, 개발자의 입장에서는 쉽게 공개정보로 바꾸기가 쉽지 않다. 왜냐하면 사용자들이 마음대로 평균 변수에 접근해서 정보를 변경시켜버리면 클래스에서 평균 정보를 가져다가 쓰는 멤버함수들이 잘 작동하지 않을 수 있기 때문이다. 이럴 경우 active field를 사용해서 average를 읽기전용으로만 접근 가능하도록 설계할 수 있다. UspStudent &lt;- R6Class(&quot;UspStudent&quot;, inherit = Student, ## active field active = list( average = function(value) { if (missing(value)) { private$.average } else { stop(&quot;`$average` is read only&quot;, call. = FALSE) } } ), public = list( university_name = &quot;University of Statistics Playbook&quot;, class_year = NA, calculate_average = function(){ private$.average &lt;- mean(c(self$midterm, self$final)) cat(&quot;Average score is&quot;, private$.average) invisible(self) }, calculate_total = function(){ cat(&quot;The total score of midterm and final exam is calculated. \\n&quot;) super$calculate_total() } ), private = list( .average = NA ) ) conie &lt;- UspStudent$new(&quot;Connie&quot;, &quot;&quot;, 78, 82) conie$calculate_average() #&gt; Average score is 80 conie$average #&gt; [1] 80 위에서 정의된 UspStudent 클래스에서는 사용자에게 평균값을 구하는 함수와 구한 평균값에 접근을 허용하지만, 사용자가 average값에 접근하여 바꾸려고 하면 에러를 뱉어내도록 설계가 되어있다. conie$average &lt;- 60 #&gt; Error: `$average` is read only 4.5 텐서와 R6의 관계 4.6 R6 관련자료 R6에 대한 더 깊은 내용은 Hadley Wickham의 Advanced R과 R6 패키지의 웹사이트를 참고하도록 하자. "],["forward.html", "Chapter 5 순전파 (Forward propagation) 5.1 신경망의 구조 5.2 순전파(Forward propagation)", " Chapter 5 순전파 (Forward propagation) 5.1 신경망의 구조 딥러닝의 시작점인 신경망(Neural network)을 공부하기 위해서, 앞으로 우리가 다룰 모델 중 가장 간단하면서, 딥러닝에서 어떤 일이 벌어지고 있는지 상상이 가능한 신경망을 먼저 학습하기로 하자. 우리가 오늘 예로 생각할 신경망은 다음과 같다. 그림 5.1: 세상에서 가장 간단하지만 있을 건 다있는 신경망 위의 그림과 같은 신경망을 2단 신경망이라고 부른다. 일반적으로 단수를 셀 때 제일 처음 입력하는 층은 단수에 포함하지 않는 것에 주의하자. 각 녹색, 회색, 그리고 빨간색의 노드(node)들은 신경망의 요소를 이루는데, 각각의 이름은 다음과 같다. 입력층(input layer) - 2개의 녹색 노드(node) 은닉층(hidden layer) - 3개의 회색 노드(node) 출력층(output layer) - 1개의 빨강색 노드(node) 자 이제부터, 녹색 노드에는 무엇이 들어가는지, 그리고, 어떤 과정을 거쳐서 빨강색의 값이 나오는지에 대하여 알아보자. 딥러닝에서 녹색이 입력값을 넣어서 빨간색의 결과값을 얻는 과정을 순전파(Forward propagation)라고 부른다. propagation의 뜻은 증식, 혹은 번식인데, 식물이나 동물이 자라나는 것을 의미하는데, 녹색의 입력값들이 어떠한 과정을 거쳐 빨간색으로 자라나는지 한번 알아보자. 5.2 순전파(Forward propagation) 우리가 사용할 데이터 역시 아주 간단하다. \\[ X =\\left(\\begin{array}{cc} 1 &amp; 2\\\\ 3 &amp; 4\\\\ 5 &amp; 6 \\end{array}\\right) \\] 가로 행이 하나의 표본을 의미하고, 세로 열 각각은 변수를 의미한다. 즉, 위의 자료 행렬은 2개의 변수 정보가 들어있는 세 개의 표본들이 있는 자료을 의미한다. 5.2.1 표본 1개, 경로 1개만 생각해보기 주의할 것은, 우리가 그려놓은 신경망의 입력층의 노드는 2개이고, 자료 행렬은 3행 2열이라는 것이다. 우리가 그려놓은 신경망으로 샘플 하나 하나가 입력층에 각각 입력되어 표본별 결과값 생성되는 것이다. 따라서 신경망을 잘 이해하기 위해서 딱 하나의 표본, 그리고 딱 하나의 경로만을 생각해보자. &gt; 목표: 첫번째 표본인 $(1, 2)$가 다음과 같은 경로를 타고 어떻게 자라나는지 생각해보자. 그림 5.2: 예시 경로 1 그림에서 \\(\\beta\\)는 노드와 노드 사이를 지나갈 때 부여되는 웨이트들을 의미하고, \\(\\sigma()\\)는 다음의 시그모이드(sigmoid) 함수를 의미한다. \\[ \\sigma(x) = \\frac{1}{1+e^{-x}} = \\frac{e^x}{e^x+1} \\] 자료 행렬을 위에 색칠된 경로로 보낸다는 의미는 다음과 같은 계산과정을 거친다는 것이다. set.seed(1234) # 데이터 매트릭스 # 3 by 2 X &lt;- torch_tensor(matrix(1:2, ncol = 2, byrow = T), dtype = torch_double()) X #&gt; torch_tensor #&gt; 1 2 #&gt; [ CPUDoubleType{1,2} ] # beta_1 벡터 # 2 by 1 # 1번째 레이어에 관한 웨이트 (베타) 중 # 다음 레이어의 1번째 노드에 대한 베타 벡터에 부여 # beta_1 = (beta_11, beta_12) beta_1 &lt;- torch_tensor(matrix(runif(2), ncol = 1), dtype = torch_double()) beta_1 #&gt; torch_tensor #&gt; 0.1137 #&gt; 0.6223 #&gt; [ CPUDoubleType{2,1} ] # 2번째 레이어 1번째 노드 # 3 by 1 z_21 &lt;- X$mm(beta_1) z_21 #&gt; torch_tensor #&gt; 1.3583 #&gt; [ CPUDoubleType{1,1} ] # 2번째 레이어 1번째 노드에서의 시그모이드 함수 통과 # 3 by 1 library(sigmoid) a_21 &lt;- sigmoid(z_21) a_21 #&gt; torch_tensor #&gt; 0.7955 #&gt; [ CPUDoubleType{1,1} ] # 2번째 레이어에 관한 웨이트 (감마) 중 # 다음 레이어의 1번째 노드에 대한 베타값에 임의의 값을 부여 # beta_1 상수 1 by 1 gamma_1 &lt;- runif(1) # 3번째 레이어 1번째 노드 # 3 by 1 z_31 &lt;- a_21 * gamma_1 z_31 #&gt; torch_tensor #&gt; 0.4847 #&gt; [ CPUDoubleType{1,1} ] # 마지막 레이어에서 시그모이드 함수 통과 # 3 by 1 y_hat &lt;- sigmoid(z_31) y_hat #&gt; torch_tensor #&gt; 0.6188 #&gt; [ CPUDoubleType{1,1} ] 즉, 우리가 생각하는 표본은 빨간색 노드에 도착하기 위해서 두번째 은닉층의 첫번째 노드를 통과하여 올 수 있다. 하지만 빨간색 노드에는 방금 우리가 생각한 경로 뿐만아니라 두 개의 선택지가 더 존재한다. 5.2.2 1개의 표본, 경로 한꺼번에 생각하기 세가지의 경로를 모두 생각해보면, 우리의 표본은 다음의 경로를 통해서 도착한다. &gt; 목표: 첫번째 표본인 $(1, 2)$가 다음과 같은 세가지 경로를 타고 어떻게 하나로 합쳐지는지 이해해보자. 그림 5.3: 3가지 경로 이 과정을 우리가 통계 시간에 배운 회귀분석에 연결지어 생각해보면, 다음의 해석이 가능하다. 두번째 은닉층의 각각의 노드들이 하나의 회귀분석 예측 모델들이라고 생각하면, 신경망은 세 개의 회귀분석을 한 대 모아놓은 거대한 회귀분석 집합체라고 생각할 수 있게 된다. 즉, 각 회귀분석 모델들이 예측한 표본에 대한 대응변수 예측값들을 은닉층에 저장한 후, 그 예측값들을 모두 모아 마지막 빨간색 노드에서 합치면서 좀 더 좋은 예측값을 만들어 내는 것이다. 이 때, \\(\\gamma\\) 벡터를 통해 가중치를 부여하는 것이라고 해석이 가능하다. 이 과정을 torch 텐서를 사용하여 깔끔하게 나타내보자. # 1개 표본 # 1 by 2 X &lt;- torch_tensor(matrix(1:2, ncol = 2, byrow = T), dtype = torch_double()) X #&gt; torch_tensor #&gt; 1 2 #&gt; [ CPUDoubleType{1,2} ] # 베타벡터가 세 개 존재함. # 2 by 3 beta_1 &lt;- torch_tensor(matrix(runif(2), ncol = 1), dtype = torch_double()) beta_2 &lt;- torch_tensor(matrix(runif(2), ncol = 1), dtype = torch_double()) beta_3 &lt;- torch_tensor(matrix(runif(2), ncol = 1), dtype = torch_double()) # 정의된 베타벡터를 cbind in torch beta &lt;- torch_cat(c(beta_1, beta_2, beta_3), 2) beta #&gt; torch_tensor #&gt; 0.6234 0.6403 0.2326 #&gt; 0.8609 0.0095 0.6661 #&gt; [ CPUDoubleType{2,3} ] # 2번째 레이어 z_2 # 1 by 3 z_2 &lt;- X$mm(beta) z_2 #&gt; torch_tensor #&gt; 2.3452 0.6593 1.5647 #&gt; [ CPUDoubleType{1,3} ] # 2번째 레이어 sigmoid 함수 통과 # 1 by 3 a_2 &lt;- sigmoid(z_2) # 2번째 레이어에 관한 웨이트 (감마) 벡터 # 다음 레이어의 1번째 노드에 대한 베타값에 임의의 값을 부여 # gamma vector 3 by 1 gamma_1 &lt;- runif(1) gamma_2 &lt;- runif(1) gamma_3 &lt;- runif(1) gamma &lt;- torch_tensor(matrix(c(gamma_1, gamma_2, gamma_3), ncol = 1), dtype = torch_double()) # 3번째 레이어 z_3 # 1 by 1 z_3 &lt;- a_2$mm(gamma) z_3 #&gt; torch_tensor #&gt; 1.3771 #&gt; [ CPUDoubleType{1,1} ] # 마지막 레이어에서 시그모이드 함수 통과 # 1 by 1 y_hat &lt;- sigmoid(z_3) y_hat #&gt; torch_tensor #&gt; 0.7985 #&gt; [ CPUDoubleType{1,1} ] R에서 우리가 즐겨쓰던 cbind()와 rbind()는 torch에서는 torch_cat() 하나의 함수으로 구현이 가능하다. 함수의 두번째 입력값은 숫자 1은 행방향(rbind)에, 2는 열방향(cbind)과 대응된다. 5.2.3 전체 표본, 경로 전체 생각해보기 이제 자료 행렬 전체를 한꺼번에 넣는 방법을 생각해보자. 입력값이 자료 행렬 전체이므로, 결과값은 이에 대응하도록 행의 갯수와 같은 벡터 형식이 될 것이라는 것을 예상하고 코드를 따라오도록 하자. &gt; 목표: 전체 표본이 신경망을 통해서 예측되는 구조를 이해하자. # 데이터 텐서 # 3 by 2 X &lt;- torch_tensor(matrix(1:6, ncol = 2, byrow = T), dtype = torch_double()) X #&gt; torch_tensor #&gt; 1 2 #&gt; 3 4 #&gt; 5 6 #&gt; [ CPUDoubleType{3,2} ] # 베타벡터가 세 개 존재함. # 2 by 3 beta &lt;- torch_tensor(matrix(runif(6), ncol = 3), dtype = torch_double()) beta #&gt; torch_tensor #&gt; 0.2827 0.2923 0.2862 #&gt; 0.9234 0.8373 0.2668 #&gt; [ CPUDoubleType{2,3} ] # 2번째 레이어 z_2 # 3 by 3 z_2 &lt;- X$mm(beta) z_2 #&gt; torch_tensor #&gt; 2.1296 1.9669 0.8199 #&gt; 4.5419 4.2261 1.9260 #&gt; 6.9543 6.4854 3.0320 #&gt; [ CPUDoubleType{3,3} ] # 2번째 레이어 sigmoid 함수 통과 # 3 by 3 a_2 &lt;- sigmoid(z_2) # 2번째 레이어에 관한 웨이트 (감마) 벡터 # 다음 레이어의 1번째 노드에 대한 베타값에 임의의 값을 부여 # gamma vector 3 by 1 gamma &lt;- torch_tensor(matrix(runif(3), ncol = 1), dtype = torch_double()) # 3번째 레이어 z_3 # 3 by 1 z_3 &lt;- a_2$mm(gamma) z_3 #&gt; torch_tensor #&gt; 0.5904 #&gt; 0.6900 #&gt; 0.7205 #&gt; [ CPUDoubleType{3,1} ] # 마지막 레이어에서 시그모이드 함수 통과 # 3 by 1 y_hat &lt;- sigmoid(z_3) y_hat #&gt; torch_tensor #&gt; 0.6435 #&gt; 0.6660 #&gt; 0.6727 #&gt; [ CPUDoubleType{3,1} ] "],["미분-자동추적-기능-autograd-에-대하여.html", "Chapter 6 미분 자동추적 기능 (Autograd) 에 대하여 6.1 예제 함수 6.2 데이터 생성 6.3 함수 만들기 및 오차 그래프 6.4 Autograd 기능 없이 기울기 구하기 6.5 자동미분(Autograd) 기능 6.6 자동 미분 관련 함수들 6.7 경사하강법", " Chapter 6 미분 자동추적 기능 (Autograd) 에 대하여 이번 장에서는 torch 및 다른 딥러닝 라이브러리의 근본을 이루는 기능인 미분 자동 추적 기능에 대하여 알아보도록 하자. 예를 들어 설명하는 것을 좋아하므로, 이번 챕터에 쓸 예제 함수를 먼저 정의하자. 6.1 예제 함수 \\(n\\)개의 데이터 \\(x_1, ..., x_n\\)이 주어졌다고 할 때, 우리는 다음의 함수 \\(f\\)를 정의 할 수 있다. \\[ f(\\mu) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\mu)^2 \\] 위의 함수는 다음과 같이 해석해 볼 수 있다. \\(x\\) 데이터에 담겨있는 정보를 단 하나의 지표 \\(\\mu\\)로 압축해서 나타낸다고 할 때, 함수 \\(f\\)는 각 관찰값에 대한 오차들, \\(x_i - \\mu\\),의 제곱의 평균을 나타낸다. 통계학에서는 나름 유명한 함수인데, 왜냐하면 위의 함수값을 최소화시키는 \\(\\mu\\)를 찾게되면 표본평균(\\(\\bar{x}\\)) 나오기 때문이다. 오늘은 이 함수를 통하여 torch의 자동 미분 기능에 대하여 알아보고자 한다. 6.2 데이터 생성 torch패키지를 불러 임의로 난수를 발생시킨 후, 텐서 x에 집어넣도록 하자. library(tidyverse) library(torch) # set seed in torch torch_manual_seed(2021) x_tensor &lt;- torch_rand(7) * 10 x_tensor #&gt; torch_tensor #&gt; 5.1339 #&gt; 7.4256 #&gt; 7.1589 #&gt; 5.7047 #&gt; 1.6527 #&gt; 0.4431 #&gt; 9.6277 #&gt; [ CPUFloatType{7} ] 위의 코드에서 쓰인 함수 두 개를 알아보자. torch_manual_seed(): base 패키지의 set.seed() 함수와 같다. 시뮬레이션 할 때 시드를 고정하는 역할을 한다. torch_rand(): base 패키지에서 runif() 함수와 같다. 균등분포(Uniform distribution) 분포에서 원하는 갯수만큼 표본을 뽑는다. 6.3 함수 만들기 및 오차 그래프 앞에서 살펴본 함수 \\(f\\)는 모수(\\(\\mu\\))를 입력값으로 하는 함수이므로, 다음과 같이 함수를 정의 할 수 있다. f &lt;- function(mu, x){ mean((x - mu)^2) } f(2, x_tensor) #&gt; torch_tensor #&gt; 20.0462 #&gt; [ CPUFloatType{} ] 위에서 알 수 있듯, \\(\\mu\\) 값이 2인 경우에 대한 오차들의 제곱의 평균값은 20.0462이다. 여러 \\(\\mu\\) 값에 대하여 f 함수의 값을 구해보자. mu_vec &lt;- seq(0, 10, by = 0.02) result &lt;- map_dbl(mu_vec, ~as.numeric(f(mu = .x, x = x_tensor))) head(result) #&gt; [1] 37.27285 37.06098 36.84991 36.63964 36.43018 36.22152 위의 두 정보를 이용해서 f의 모양이 어떻게 생겼는지 그려보면 다음과 같이 2차원 곡선을 띄고있다는 것을 알 수 있다. library(latex2exp) library(ggthemes) theme_set(theme_igray()) plot_data &lt;- tibble(x = mu_vec, y = result) p &lt;- ggplot(data = plot_data, aes(x = x, y = y)) + geom_line() + labs(x = TeX(&quot;$\\\\mu$&quot;), y = TeX(&quot;$f(\\\\mu;x)$&quot;)) p 그림 6.1: \\(\\mu\\) 값에 따른 myf 함수값의 변화 우리의 목표는 바로 저 곡선을 최소로 만드는 \\(\\mu\\) 값이 무엇인지 찾아내는 것이다. 이 최소값을 찾기위해서는 경사하강법 같은 방법을 사용해야 하는데, 이러한 알고리즘들의 핵심은 바로 주어진 \\(\\mu\\)값에 대응하는 기울기값을 구하는 것이다. 우리가 임의로 정한 시작점 \\(\\mu_i\\)에서 목표인 \\(\\mu_{*}\\)까지 찾아가기 위해서 경사하강법을 통하면 다음의 과정을 \\(\\mu\\)값이 수렴할 때까지 반복하면 된다. \\[ {\\displaystyle \\mathbf {\\mu} _{i+1}=\\mathbf {\\mu} _{i}-\\gamma _{i}\\nabla f(\\mathbf {\\mu} _{i})}, \\quad i \\in \\mathbb{N} \\tag{6.1} \\] 위의 수식에서 \\(\\gamma _{i}\\)은 탐색을 할 때 움직이는 거리 (step size)라고 부르고, 딥러닝 분야에서는 나중에 학습률(learning rate)의 개념이 된다. 또한, \\(\\nabla f(\\mathbf {\\mu} _{i})\\) 부분이 바로 기울기값을 나타내는 부분이다. 6.4 Autograd 기능 없이 기울기 구하기 먼저 torch의 자동기울기 기능를 사용해서 기울기값 계산을 하기에 앞서, 계산 결과를 구해보자. \\(y\\)를 \\(\\beta\\)에 대하여 미분하면 다음과 같다. \\[ \\begin{align*} f&#39;(\\beta) &amp; =\\frac{d}{d\\beta}\\left(\\frac{1}{n}\\sum_{i=1}^{n}\\left(x_{i}-\\beta\\right)^{2}\\right)\\\\ &amp; =\\frac{1}{n}\\sum_{i=1}^{n}\\frac{d}{d\\beta}\\left(x_{i}-\\beta\\right)^{2}\\\\ &amp; =-\\frac{1}{n}\\sum_{i=1}^{n}2\\left(x_{i}-\\beta\\right) \\end{align*} \\] 따라서 mu값이 2.5로 주어졌을때, 기울기 값은 다음과 같다. f_prime &lt;- function(mu, x){ -mean(2*(x - mu)) } f_prime(2.5, x_tensor) #&gt; torch_tensor #&gt; -5.61331 #&gt; [ CPUFloatType{} ] 이것이 실제로 그러한지 그림을 그려보자. mu &lt;- 2.5 my_slope &lt;- as.numeric(f_prime(mu, x_tensor)) my_intercept &lt;- as.numeric(f(mu, x_tensor) - f_prime(mu, x_tensor) * mu) p + geom_abline(slope = my_slope, intercept = my_intercept, col = &quot;red&quot;) 6.5 자동미분(Autograd) 기능 torch에는 우리가 계산한 기울기 구하는 과정들을 자동으로 해주는 기능이 있다. 바로 자동미분 (Auto gradient) 기능이다. 기울기값 계산을 위해서 해야할 일은 기울기 계산기능을 activate 해주는 옵션을 실행시켜주기만 하면 된다. 함수는 \\(\\mu\\)에 대한 함수이므로, 기울기값을 추적할 텐서 \\(\\mu\\)를 선언할 때 requires_grad = TRUE 옵션을 붙여줘서 선언하면 끝이다. 이 옵션이 활성화 되면 torch는 이 변수와 관련된 다른 변수들에 대하여 기울기값을 자동으로 추적한다. 추후 복잡한 신경망을 다루는 딥러닝 분야에서는 기울기를 구하는 것이 학습에 아주 핵심적인 기능이고, 이러한 기울기를 구하는 이러한 기울기를 계산하는 방법을 역전파 (backpropagation)라고 부른다. mu &lt;- torch_tensor(2.5, requires_grad=TRUE) mu #&gt; torch_tensor #&gt; 2.5000 #&gt; [ CPUFloatType{1} ] mu 텐서가 기울기 추적 옵션을 달고 있어서, 이와 관련되어 생성되는 모든 텐서에 기울기 추적 옵션 grad_fn 태그가 달려서 생성된다. 다음과 같이 y를 정의를 하면, y에도 역시 grad_fn이 붙어서 생성되는 것을 알 수 있다. y &lt;- mean((x_tensor - mu)^2) y$grad_fn #&gt; MeanBackward0 기울기 값 계산을 위해서 해야 할 일은 기울기 계산을 activate 해주는 함수를 실행시켜주기만 하면 된다. y에 대한 베타의 기울기 값을 구하는 것이므로, 다음과 같이 backward()를 이용하여 역전파(backward propagation)를 통하여 기울기 계산을 한다. y$backward() 자동 기울기 추적 기능을 사용한 auto grad가 구한 베타의 기울기값이 우리가 구한 값과 동일한지 확인해보자. f_prime(2.5, x_tensor) #&gt; torch_tensor #&gt; -5.61331 #&gt; [ CPUFloatType{} ] mu$grad #&gt; torch_tensor #&gt; -5.6133 #&gt; [ CPUFloatType{1} ] 앞에서 구한 f_prime(2.5)값이 동일하게 mu$grad에 담겨 있다는 것을 알 수 있다. 6.6 자동 미분 관련 함수들 기울기 자동 추적기능을 사용한다는 것은 그것을 돌리는 컴퓨터의 메모리를 많이 차지한다는 이야기이다. 따라서 우리가 생각하는 변수에 대한 것에만 추적 옵션을 붙여야 하고, 더 이상 필요가 없어지면 기능을 꺼주기도 해야 할 것이다. 이러한 자동 미분 추척 기능들을 자유자재로 다루기 위해서 알아두어야 할 함수들이 있다. 6.6.1 $detach() 현재 y는 기울기 자동추적 기능이 붙어있다. 우리가 다음과 같이 y를 사용해서 텐서 z를 생성하면 그 역시 옵션이 딸려 생성이 될 테지만, y 텐서 이후 부터는 추적 기능을 사용하고 싶지 않을때, $detach()를 사용해서 추적기를 떼어낼 수 있다. y$grad_fn #&gt; MeanBackward0 z &lt;- y^2 z$grad_fn #&gt; PowBackward0 z$detach_() #&gt; torch_tensor #&gt; 288.646 #&gt; [ CPUFloatType{} ] z$grad_fn #&gt; NULL 6.6.2 $requires_grad 변수와 $requires_grad_(TRUE) 이 함수는 이미 선언된 텐서에 미분 추적기능을 붙이고 싶을 때, $requires_grad_(TRUE)을 사용할 수 있다. 일반 텐서 a를 생성하도록 하자. a &lt;- torch_tensor(c(1, 2)) a #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; [ CPUFloatType{2} ] a$requires_grad #&gt; [1] FALSE a$requires_grad 값이 FALSE라는 말은 a에 대한 추적 옵션은 현재 꺼져있는 상태이다. 자동 추적 기능이 없이 생성된 텐서에 추적 기능을 붙일 때에는 a$requires_grad을 TRUE로 바꿔주면 된다. TRUE를 직접 할당해도 되고, $requires_grad_(TRUE)을 사용하여 바꿔줘도 된다. # a$requires_grad &lt;- TRUE a$requires_grad_(TRUE) #&gt; torch_tensor #&gt; 1 #&gt; 2 #&gt; [ CPUFloatType{2} ] 6.6.3 with_no_grad({}) 만약 특정 코드를 실행함에 있어서 추적 기능을 떼고 계산하고 싶은 경우, with_no_grad({})가 유용하다. y #&gt; torch_tensor #&gt; 16.9896 #&gt; [ CPUFloatType{} ] y$grad_fn #&gt; MeanBackward0 with_no_grad({ y y$grad_fn }) #&gt; MeanBackward0 6.7 경사하강법 이왕 자동 미분기능을 알았으니, 이 기능을 이용하여 식 (6.1)의 경사하강법으로 함수값을 최소로 만드는 \\(\\mu\\) 값을 찾아보도록 하자. learning_rate &lt;- 0.1 # 시작값 0.5 mu &lt;- torch_tensor(0.5, requires_grad=TRUE) result &lt;- rep(0, 100) result[1] &lt;- as.numeric(mu) for (i in 2:100) { result[i] &lt;- as.numeric(mu) y &lt;- mean((x_tensor - mu)^2) y$backward() with_no_grad({ mu$sub_(learning_rate * mu$grad) mu$grad$zero_() }) } tail(result) #&gt; [1] 5.306654 5.306654 5.306654 5.306654 5.306654 5.306654 mu$grad$zero_() 부분은 미분값을 초기화 해주는 부분이라고 이해하면 좋다. 그렇지 않을 경우, 이전의 값이 남아있어서 계속 누적되므로 주의하자. 6.7.1 시각화 mu_points &lt;- tibble(x = result, y = map_dbl(result, ~as.numeric(f(mu = .x, x = x_tensor)))) p + geom_point(data = mu_points, aes(x = x, y = y), col = &quot;blue&quot;) 이 챕터의 제일 첫부분에서 말했든 이론적인 정답은 데이터의 표본평균이 함수값을 최소로 만드는 값이다. 실제로 그렇게 나왔는지 확인해보면 두 값이 같다는 것을 알 수 있다. result[100] #&gt; [1] 5.306654 x_tensor$mean() #&gt; torch_tensor #&gt; 5.30665 #&gt; [ CPUFloatType{} ] 이것으로 자동 미분 기능에 대하여 알아보았다. 이 기능을 활용하면 훨씬 복잡한 구조의 함수(예를 들어 딥러닝에서의 신경망 같은)에 대한 미분값 역시도 쉽게 구할 수 있다. 응용 코드들은 신경망 예제에서 다루기로 하자. "],["torch-nn-모듈로-첫-신경망-정의하기.html", "Chapter 7 torch_nn 모듈로 첫 신경망 정의하기 7.1 신경망 정의 (Custom nn Modules) 7.2 nn_linear 클래스 7.3 순전파(Forward propagation) 정의", " Chapter 7 torch_nn 모듈로 첫 신경망 정의하기 이제까지 torch의 자동미분(auto grad) 기능과 순전파(forward propagation)에 대하여 알아보았다. 오늘은 드디어, torch 라이브러리에서 제공하는 함수들을 이용해서 챕터 5 에서 정의해본 신경망을 정의해 보도록 한다. 그림 7.1: 다시 두두등장! 세상 간단한 신경망 7.1 신경망 정의 (Custom nn Modules) 토치를 사용해서 신경망을 정의할 때 사용하는 함수가 있다. 바로 nn_module()이라는 함수인데, torch에서 신경망을 정의할 때, 이 함수를 사용해서 “클래스”를 만들어 정의한다! 왜 우리가 챕터 4에서 R6관련 클래스 내용을 그렇게도 공부했었는지에 대한 답을 바로 이 챕터에서 찾을 수 있을 것이다. 7.1.1 nn_module과 클래스 상속 nn_module이 어떤 역할을 하는지에 대하여 알아보기 위해 가장 간단한 신경망을 작성해보도록 하자. 바로 우리가 앞서 살펴본 2단 레이어 네트워크 예제에서 사용한 데이터를 만들어 보자. library(torch) X &lt;- torch_tensor(matrix(1:6, ncol = 2, byrow = T), dtype = torch_float()) X #&gt; torch_tensor #&gt; 1 2 #&gt; 3 4 #&gt; 5 6 #&gt; [ CPUFloatType{3,2} ] 먼저, TwoLayerNet이라는 이름의 신경망 클래스를 정의한다(기억하시나? 클래스의 이름은 카멜 형식이다!). nn_module() 함수는 클래스를 정의하는 함수인데, 이 함수를 사용해서 만들어진 클래스는 자동으로 신경망과 관련한 클래스인 basic-nn-module 클래스를 상속하게 만든다. 즉, nn_module안에는 신경망 관련 클래스들 속에는 신경망과 관련한 많은 함수가 정의되어 있을 것이고, 이것을 다 상속받아서 클래스가 만들어지는 것이다. 다음의 코드는 위의 신경망을 정의한 코드이다. TwoLayerNet &lt;- nn_module( classname = &quot;TowLayerNet&quot;, initialize = function(data_in, hidden, data_out){ cat(&quot;Initiation complete!&quot;) self$hidden_layer &lt;- nn_linear(data_in, hidden, bias=FALSE) self$output_layer &lt;- nn_linear(hidden, data_out, bias=FALSE) } ) myfirst_model &lt;- TwoLayerNet(2, 3, 1) #&gt; Initiation complete! myfirst_model #&gt; An `nn_module` containing 9 parameters. #&gt; #&gt; ── Modules ───────────────────────────────────────────────────────────────────── #&gt; ● hidden_layer: &lt;nn_linear&gt; #6 parameters #&gt; ● output_layer: &lt;nn_linear&gt; #3 parameters 결과를 살펴보면 TwoLayerNet 클래스에 의하여 만들어진 myfirst_model는 두 개의 층이 들어있는 것을 확인할 수 있다. 이 두개 층에 관련한 모수 갯수를 그림과 한번 연결 시켜보면 잘 정의가 되어있다는 것을 알 수 있다. hidden_layer: 그림에서 첫번째와 두번째 층을 연결하는 다리가 6개라는 것을 주목하자. 모수의 갯수는 그래서 6개! output_layer: 그림에서 두번째와 마지막 층을 연결하는 다리는 3개이므로, 모수의 갯수는 3개가 된다. 7.2 nn_linear 클래스 nn_linear의 입력값은 입력변수의 갯수, 출력변수의 갯수, 그리고 bias 항의 유무를 나타내는 옵션 이렇게 세개가 된다. 예제의 경우, 데이터 텐서 \\(X\\)의 features 갯수가 2개이므로, 히든 레이어의 입력값 갯수가 2개가 되어야 한다. 또한 히든 레이어의 노드 갯수가 3개이므로 결과 행력의 features 갯수가 3개가 되어야 한다. 7.2.1 bias 없는 경우 우리가 예전에 다루었던 예제에서는 bias 항이 없었으므로, bias=FALSE를 해주어야 함에 주의하자. mat_op &lt;- nn_linear(2, 3, bias = FALSE) mat_op$weight #&gt; torch_tensor #&gt; 0.01 * #&gt; -7.2235 -7.5713 #&gt; -22.4736 -16.3281 #&gt; -12.1568 -22.5592 #&gt; [ CPUFloatType{3,2} ] mat_op을 nn.Linear(2, 3) 클래스로 만들어진 클래스 생성자로 이해 할 수 있다. 그리고 이것의 수학적 의미는 행렬 연산으로 이해할 수 있겠다. mat_op가 생성될 때 임의의 weight 텐서, \\(W\\), 와 bias, \\(b\\),가 생성이 되고, 입력값으로 들어오는 X에 대하여 다음의 연산을 수행한 후 결괏값을 내보낸다. \\[ y = X\\beta = XW^T \\] 결과를 코드로 확인해보자. X$mm(mat_op$weight$t()) #&gt; torch_tensor #&gt; -0.2237 -0.5513 -0.5728 #&gt; -0.5196 -1.3273 -1.2671 #&gt; -0.8155 -2.1034 -1.9614 #&gt; [ CPUFloatType{3,3} ] mat_op(X) #&gt; torch_tensor #&gt; -0.2237 -0.5513 -0.5728 #&gt; -0.5196 -1.3273 -1.2671 #&gt; -0.8155 -2.1034 -1.9614 #&gt; [ CPUFloatType{3,3} ] 7.2.2 bias 있는 경우 bias=TRUE를 해주면 weight 텐서 \\(W\\)와 더불어 bias 텐서가 생성이 된다. mat_op2 &lt;- nn_linear(2, 3, bias = TRUE) mat_op2$weight #&gt; torch_tensor #&gt; 0.0837 -0.5985 #&gt; -0.6104 0.1347 #&gt; 0.0889 -0.2483 #&gt; [ CPUFloatType{3,2} ] mat_op2$bias #&gt; torch_tensor #&gt; 0.1729 #&gt; -0.2470 #&gt; -0.1615 #&gt; [ CPUFloatType{3} ] 따라서 정의된 신경망의 연산 역시 다음과 같이 바뀐다. \\[ y = X\\beta + b = XW^T + b \\] X$mm(mat_op2$weight$t()) + mat_op2$bias #&gt; torch_tensor #&gt; -0.9405 -0.5879 -0.5690 #&gt; -1.9702 -1.5393 -0.8877 #&gt; -2.9999 -2.4907 -1.2063 #&gt; [ CPUFloatType{3,3} ] mat_op2(X) #&gt; torch_tensor #&gt; -0.9405 -0.5879 -0.5690 #&gt; -1.9702 -1.5393 -0.8877 #&gt; -2.9999 -2.4907 -1.2063 #&gt; [ CPUFloatType{3,3} ] 7.3 순전파(Forward propagation) 정의 torch를 공부하면서 신기한 걸 많이 배우고 있다. 그 중 한가지가 바로 객체지향 프로그래밍을 사용해서 신경망을 정의한다는 것이다. 앞선 예제를 이어가보면, 우리는 신경망의 순전파를 구현해야 한다. 순전파의 경우 다음과 같이 forward 멤버 함수를 정의해서 구현할 수 있다. TwoLayerNet &lt;- nn_module( classname = &quot;TowLayerNet&quot;, initialize = function(data_in, hidden, data_out){ cat(&quot;Initiation complete!&quot;) self$hidden_layer &lt;- nn_linear(data_in, hidden, bias=FALSE) self$output_layer &lt;- nn_linear(hidden, data_out, bias=FALSE) self$sigmoid &lt;- nn_sigmoid() }, # 순전파 멤버함수 forward 정의 부분 forward = function(X) { z1 &lt;- self$hidden_layer(X) a1 &lt;- self$sigmoid(z1) z2 &lt;- self$output_layer(a1) y_hat &lt;- self$sigmoid(z2) return(y_hat) } ) library(zeallot) c(D_in, H, D_out) %&lt;-% c(2, 3, 1) my_net &lt;- TwoLayerNet(D_in, H, D_out) #&gt; Initiation complete! my_net(X) #&gt; torch_tensor #&gt; 0.4518 #&gt; 0.4524 #&gt; 0.4533 #&gt; [ CPUFloatType{3,1} ] 위의 코드를 한번 살펴보자. 먼저 zeallot 패키지는 %&lt;-%를 포함하는 패키지인데, 여러 개의 변수에 한꺼번에 값을 부여하는 연산자이기 때문에 알아두면 편한 패키지 이다. 새로 정의된 TwoLayerNet 클래스에는 7.1의 2단 신경망의 순전파(forward propagation)가 구현된 멤버함수 forward가 정의되어 있다. 이 함수는 입력 텐서 X가 신경망으로 들어오게 되면, 은닉층(hidden_layer) \\(\\rightarrow\\) 활성함수 (activation function; 여기서는 nn_sigmoid 함수) \\(\\rightarrow\\) 출력층(output_layer) \\(\\rightarrow\\) 활성함수 순으로 내보내게 된다. "],["나의-첫-신경망-학습.html", "Chapter 8 나의 첫 신경망 학습 8.1 학습 준비 - 데이터 만들기 8.2 신경망과 블랙박스(Black-box) 8.3 신경망 학습 8.4 과적합(overfitting)과의 싸움", " Chapter 8 나의 첫 신경망 학습 저번 시간 우리는 토치에서 신경망을 정의하는 방법에 대하여 알아보았다. 오늘은 정의한 신경망을 어떻게 학습하는가에 대하여 알아보도록 하자. 8.1 학습 준비 - 데이터 만들기 필자는 유튜브에 R을 사용한 통계관련 수업들을 올려놓았다. 이 수업에서 큰 축을 이루는 것 중 하나가 바로 회귀분석이다. 회귀분석은 주어진 데이터를 모델링할 때 신경망의 가장 큰 장점은 회귀직선과 같은 선형모형들이 가지는 한계를 넘어서, 비선형 모델링을 할 수 있게 해준다는 것이다. 이러한 장점들을 잘 확인해보기 위해서 비선형 모델에서 관찰값을 뽑아 모의 데이터로 만들어 보도록 하자. library(tidyverse) # 재현 가능을 위한 시드 고정 set.seed(2021) # x 자리 임의 생성 x &lt;- sort(sample(1:100, 100)) # 모델을 위한 f 함수 정의 f &lt;- function(x){ x + 30 * sin(0.1 * x) } # noise을 가미한 관찰값 생성 y &lt;- f(x) + 5 * rnorm(100) obs_data &lt;- tibble(x = x, y = y) head(obs_data) #&gt; # A tibble: 6 x 2 #&gt; x y #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 10.1 #&gt; 2 2 7.89 #&gt; 3 3 2.88 #&gt; 4 4 17.0 #&gt; 5 5 21.9 #&gt; 6 6 19.1 관찰값 \\(y\\)가 발생되는 코드를 살펴보면, \\(y\\)는 발생되는 실제 함수 \\(f\\)는 다음과 같이 비선형성을 가지고 있고, 거기에 잡음이 섞여서 관찰되는 형태를 띄고 있다. \\[ \\begin{equation} \\begin{aligned} f(x) &amp;= x + 30 sin(0.1 x), \\\\ y &amp; = f(x) + \\epsilon, \\quad \\epsilon \\sim \\mathbb{N}(0, 5^2) \\end{aligned} \\tag{8.1} \\end{equation} \\] 관찰값과 모델 함수 그려보도록 하자. 모델 함수의 경우 점선으로 표시했다. library(ggthemes) library(latex2exp) theme_set(theme_igray()) x_true &lt;- 1:100 model_data &lt;- tibble(x = x_true, y = f(x_true)) # 관찰값 시각화 p &lt;- obs_data %&gt;% ggplot(aes(x = x, y = y)) + geom_point(color = &quot;#E69F00&quot;) + labs(x = &quot;x&quot;, y = &quot;f(x)&quot;, caption = &quot;https://www.youtube.com/c/statisticsplaybook&quot;) p + geom_line(data = model_data, aes(x = x, y = y), linetype = &quot;dashed&quot;) # 모델 함수 그림 8.1: 샘플 데이터 시각화. 비선형성이 잘 드러나있다. 위에 주어진 관찰값을 사용해서 회귀직선을 구해보면 다음과 같이 회색의 직선을 구할 수 있다. 그림 8.2: 회귀직선(회색 직선)은 자료를 가장 잘 설명하는 선형모델로 볼 수 있다. 추후 신경망 모델과의 비교를 위해서 회귀직선과 관찰값 사이의 잔차들의 제곱의 평균을 구해놓자. model &lt;- lm(y ~ x, obs_data) # Mean Squared Error for train data mean((model$residuals)^2) #&gt; [1] 431.8235 8.2 신경망과 블랙박스(Black-box) Figure 8.2 을 보면 회귀 직선도 사실 자료의 x값에 따른 함수값의 변화를 아주 잘 잡아내는 것을 알 수 있다. 하지만, 우리가 자료를 발생시키는 함수의 구조가 비선형을 띈다는 것을 알고 있는 상태에서 보면(현실에서는 아무도 모른다.), 비선형성을 잡아내지 못하는 회귀 직선의 한계가 뚜렷하게 보인다. 따라서 통계학에서는 이러한 비선형성을 잡아내기 위해서 일반화선형모형(General Linear Model)이나 일반화 가법모형(Generalized Additive Model; GAM)1 등 여러가지 기법들이 발달했다. 신경망 역시 이것들의 연장선 상에 위치하는 모델이라고 생각해도 무방하다. 다만 모델의 해석적인 측면에서 일반화 선형모형에서는 모델을 만드는 사람들이 비선형성을 부여하는 툴들을 (예를 들어 link 함수를 자료를 보고 사용자가 선택한다.) 조절해서, 모델의 결과 해석력이 우수했다면, 일반화 가법모형과 신경망으로 갈 수록 사용자가 모델의 비선형성을 조절한다기모다 기법 자체가 비선형성을 잘 다루도록 설계가 되어있어서 해석력은 떨어지고 예측력은 증가했다. 신경망은 특히 모델 자체에 자유도를 높이고, 대량의 데이터를 사용하여 학습하면서 실제 함수를 찾아가는 방식이라서, 학습된 모델의 해석이 거의 불가능하게 되어버려서 블랙박스(Black box - 안이 어떻게 돌아가는지 모름) 모델이라는 별명이 생겼다. 모델러 입장에서는 ’뭐가 뭔지는 모르겠는데, 예측은 잘한다’라는 느낌이 드는 아이인데, 실제 성능적인 측면에서 기존 모델보다 월등하게 잘 예측을 하기 때문에, 신경망의 핫하게 된 이유가 되었다. 개인적으로 필자는 책의 뒷부분에 소개할 신경망의 여러 구조들이 결국에는 신경망의 모수 학습시(실제 함수를 찾아갈 때) 데이터를 넣었을 때 발산하지 않고 실제 함수로 잘 수렴하도록 잘 이끌어주는 신경망 구조를 만들어가는 것이라고 생각하고 있다. 즉, 대략적인 구조를 잡아주고, 그 안에서 데이터를 사용하여 tuning을 하는 방식이다. 어찌보면 이러한 과정은 통계에서 특정 조건을 만족하는 함수들의 집합을 정의하고 (회귀분석의 경우는 선형 함수들만을 생각하고), 그 안에서 최적 모델을 찾아가는 방식과 유사하다. 8.3 신경망 학습 앞에서 만들어낸 데이터를 사용하여, 신경망을 학습하도록 하자. 신경망을 학습한다는 이야기를 통계적으로 보면 주어진 혹은 설정한 손실 함수(loss function) 값을 최소화 시키는 신경망의 모수(weights)값을 찾는다는 이야기이다. 이런 최적 모수값 찾는 방법에는 여러가지가 있는데, torch에서는 이제까지 제안된 많은 방법들이 최적화 함수 (optimizer) 클래스 형식으로 제공이 된다. 당연한 것이겠지만 어떤 최적화 함수를 사용하느냐에 따라서 학습 결과가 달라진다. 앞에서 정의한 신경망 코드를 가져오자. library(torch) torch_manual_seed(2021) TwoLayerNet &lt;- nn_module( classname = &quot;TowLayerNet&quot;, initialize = function(data_in, hidden, data_out){ cat(&quot;Initiation complete!&quot;) self$hidden1 &lt;- nn_linear(data_in, hidden) self$hidden2 &lt;- nn_linear(hidden, hidden) self$hidden3 &lt;- nn_linear(hidden, hidden) self$output_layer &lt;- nn_linear(hidden, data_out) self$tanh &lt;- nn_tanh() }, # 순전파 멤버함수 forward 정의 부분 forward = function(X) { x &lt;- self$tanh(self$hidden1(X)) x &lt;- self$tanh(self$hidden2(x)) x &lt;- self$hidden3(x) y_hat &lt;- self$output_layer(x) return(y_hat) } ) library(zeallot) # GPU available cuda_is_available() #&gt; [1] TRUE gpu &lt;- torch_device(&quot;cuda&quot;) x_tensor &lt;- torch_tensor(scale(x), dtype = torch_float(), requires_grad = TRUE, device = gpu)$view(c(-1, 1)) y_tensor &lt;- torch_tensor(y, dtype = torch_float(), device = gpu)$view(c(-1, 1)) c(D_in, H, D_out) %&lt;-% c(1, 10, 1) my_net &lt;- TwoLayerNet(D_in, H, D_out) #&gt; Initiation complete! my_net$cuda() my_net #&gt; An `nn_module` containing 251 parameters. #&gt; #&gt; ── Modules ───────────────────────────────────────────────────────────────────── #&gt; ● hidden1: &lt;nn_linear&gt; #20 parameters #&gt; ● hidden2: &lt;nn_linear&gt; #110 parameters #&gt; ● hidden3: &lt;nn_linear&gt; #110 parameters #&gt; ● output_layer: &lt;nn_linear&gt; #11 parameters #&gt; ● tanh: &lt;nn_tanh&gt; #0 parameters 8.3.1 손실함수와 최적화 방법 선택 토치에서는 많은 손실함수 (loss function)와 최적화 함수 (optimizer) 를 모두 제공하는데, 그 중 가장 기본적인 손실함수인 MSE(Mean Squared Error)와 최적화 방법 SGD(Stochastic Gradient Desent) 방법을 사용하도록 하자. 둘은 다음과 같은 방법으로 선언한다. mse_loss &lt;- nn_mse_loss(reduction = &quot;mean&quot;) optimizer &lt;- optim_sgd(my_net$parameters, lr = 1e-5) # 손실함수와 최적화 방법에 대한 깊은 내용은 다른 챕터에서 다루도록 하고, 일단 간단하게 정리만 해보자. 지금은 신경망이 어떤 식의 구조를 가진 코드로 학습할 수 있는지 집중한다. nn_mse_loss() nn_mse_loss 함수의 경우, 다음의 두 가지 타입 손실함수를 제공한다. reduction 옵션을 sum 설정할 경우 손실함수는 다음과 같다. \\[ L(\\hat{\\boldsymbol{y}}, \\boldsymbol{y}) = \\sum_i^{n}(\\hat{y_i}-y_i)^2 \\] 혹은 reduction 옵션을 mean으로 설정할 경우 손실함수는 MES를 반환한다. \\[ L(\\hat{\\boldsymbol{y}}, \\boldsymbol{y}) = \\frac{1}{n}\\sum_i^{n}(\\hat{y_i}-y_i)^2 \\] 참고로 none으로 설정시 입력한 두 벡터의 차이의 제곱값들이 벡터 형식으로 나온다. 앞에 신경망 정의에서 보았듯 히든 레이어를 지날 때, activation 함수를 통과하므로, 로스값 역시 어떤 activation 함수를 사용하느냐에 따라서 달라질 수 있다는 것을 염두해두자. 주어진 데이터에 대한 손실 함수 값은 다음과 같이 구할 수 있다. y_hat &lt;- my_net(x_tensor) mse_loss(y_hat, y_tensor) #&gt; torch_tensor #&gt; 4268.52 #&gt; [ CUDAFloatType{} ] optim_sgd() 최적화 함수에 대하여는 나중에 따로 포스트로 다루겠다. 현재는 optim_sgd가 토치에서 제공하는 최적화 함수 중 하나이며, 입력값으로 신경망의 모수(weights)와 학습률(learning rate), lr,을 받는다는 것을 알아두자. 학습률(learning rate)은 자동 미분 챕터에서 다뤘던 경사하강도 알고리즘을 설명했던 부분에서도 다뤘는데, 신경망 학습 과정에서 중요한 역할을 차지한다. 이것에 따라서 학습이 잘 될 수도, 그렇지 않을 수도 있다. 보통 신경망이 복잡해 질 수록 학습률은 좀 더 세밀한 탐색을 위해 작게 잡아준다. 하지만, 학습률이 작은 경우에는 신경망을 학습하는 시간이 길어지게 된다. 최적은 학습률을 정하는 주제는 학문적으로도 아주 중요하고 방대한 주제이다. 한가지 예만 들면, 굳이 우리가 신경망을 학습시킬때 학습률을 동일하게 고정할 필요가 있을까? 어떻게 보면 너무나 중용하고, 실무적인(당장 신경망 학습에 막대한 영향을 미치므로), 연구 주제같다. 8.3.2 학습 구현 경사하강법에서 모수가 점점 업데이트 되면서 최적값으로 수렴하는 것을 보았다. 이렇게 업데이트 한번 진행이 되는 단계 단계를 딥러닝에서는 epoch라고 한다. 보통 데이터가 너무 많은 경우 전체 데이터를 한꺼번에 사용하는 것이 아니라 작은 단위로 잘라서 컴퓨터 메모리에 올리게 되는데, 이렇게 작게 잘린 데이터 단위를 배치(batch)라고 하며, 배치의 크기는 배치 안에 몇 개의 데이터가 들어가 있는가를 의미한다. 이와 관련한 내용은 추후에 데이터셋(Dataset) 클래스와 데이터 로더(Data loader) 클래스를 다룰 때 다시 자세하게 이야기하도록 한다. 다음의 코드는 mse_loss 값을 업데이트 단계마다 저장하고, 총 1000번의 모수 업데이트를 수행하여 신경망의 모수를 학습시키는 코드이다. store_loss &lt;- rep(0, 50000) for (epoch in 1:50000){ optimizer$zero_grad() output &lt;- my_net(x_tensor) loss &lt;- mse_loss(output, y_tensor) loss$backward() optimizer$step() store_loss[epoch] &lt;- as.numeric(loss$item()) if (epoch %% 5000 == 0){ cat(sprintf(&quot;Loss at epoch %d: %.2f\\n&quot;, epoch, store_loss[epoch])) } } #&gt; Loss at epoch 5000: 123.00 #&gt; Loss at epoch 10000: 94.12 #&gt; Loss at epoch 15000: 86.84 #&gt; Loss at epoch 20000: 81.58 #&gt; Loss at epoch 25000: 76.47 #&gt; Loss at epoch 30000: 70.47 #&gt; Loss at epoch 35000: 58.99 #&gt; Loss at epoch 40000: 41.10 #&gt; Loss at epoch 45000: 28.03 #&gt; Loss at epoch 50000: 23.86 8.3.3 시각화 이전 섹션에서 우리는 신경망의 학습이 진행되면서 손실함수(loss)값이 점점 줄어드는 것을 확인할 수 있었다. 최종적으로 학습된 신경망은 어떻게 생겼을까? . 그림 8.3: 학습된 신경망과 회귀직선 비교 학습된 신경망이 데이터가 발생되는 함수의 비선형성을 잘 반영하고 있는 것을 확인할 수 있다. 8.4 과적합(overfitting)과의 싸움 이렇게 학습한 신경망은 너무나도 완벽해 보이지만, 사실 중대한 문제점이 있다. 바로 학습에 사용된 데이터에 나타난 패턴을 너무나도 잘 반영하고 있는 것이 문제이다. 사실 뭐가 문제냐 싶지만, 우리가 흔히 말하는 “이론과 현실은 달라요.” 라는 말이 신경망 학습에서도 그대로 적용이 된다고 생각하면 된다. 즉, 학습 데이터를 너무나 잘 반영하는 것도 좋지만, 이렇게 학습된 신경망을 사용해서 예측을 할 때, 신경망에 입력 될 데이터는 대부분 학습 데이터와 비슷하기도 하겠지만, 비슷하지 않은 전혀 다른 입력값이 들어올 수 있다. 이런 상황에 잘 대비하기(?) 위해서 혹은 신경망이 성능을 잘 내기 위해서는 신경망을 학습을 할 때 성과측정을 신경망의 학습에 한번도 사용되지 않는 새로운 데이터로 평가를 해야만 한다. 이렇게 모델이 학습 데이터 패턴을 너무나 많이 반영하고 있는 현상을 과하게 적합이 되어 있다고 하여 모델 과적합(overfitting) 상태라고 부른다. 기계학습과 딥러닝에서는 일단 베이스라인 모델이 정해진 후에는 어떤 모수값(weights)이 최적의 모수인지를 찾아내야하는 과정을 거친다. 이 과정을 거치는 가장 큰 이유는 모델 과적합 방지에 있다. 어떻게 하면 학습 데이터의 패턴은 잘 반영하면서, 새로이 들어올 데이터에도 잘 반응할 수 있는 모델을 세울 수 있을지 앞으로의 학습을 통해서 차근차근 배워보자. 링크는 가톨릭대 문건웅 교수님이 쓴 일반화 가법모델에 대한 내용이다. R코드와 함께 친절하게 설명이 되어있다.↩︎ "],["dataset과-dataloader-클래스.html", "Chapter 9 Dataset과 Dataloader 클래스 9.1 예제 데이터 9.2 Dataset 클래스 9.3 데이터로더 (Dataloader) 클래스 9.4 모델 설정 - 로지스틱 회귀모형 9.5 학습 결과", " Chapter 9 Dataset과 Dataloader 클래스 이번 챕터에서는 실제 딥러닝을 사용하여 모델링을 할 때 사용될 데이터를 어떻게 torch에 넣을수 있는지에 대하여 알아보자. 이 과정에서 우리가 알아야하는 클래스가 두개가 있는데, 바로 Dataset 클래스와 Dataloader 클래스이다. 9.1 예제 데이터 언제나 그렇듯, 본 공략집은 예제를 통해서 설명하는 것을 선호한다. 이번 챕터에서는 가상의 학생들의 공부시간과 연습한 문제 갯수, 그리고 시험의 합격 여부에 대한 자료를 만들어보았다. library(torch) library(tidyverse) set.seed(2021) # 독립변수 발생 x1 &lt;- c(rnorm(300, 5, 2), rnorm(200, 10, 2)) x2 &lt;- as.integer(pmax(c(rnorm(300, 10, 2), rnorm(200, 13, 2)), 0)) # 종속변수 발생 y &lt;- rep(c(0, 1), c(300, 200)) # 데이터 프레임 만들기 study_data &lt;- tibble(study_time = x1, n_question = x2, pass_exam = y) # 뒤섞기 study_data &lt;- study_data[sample(500, 500),] knitr::kable(head(study_data), format=&quot;html&quot;, caption = &quot;`study_data` 구조&quot;) %&gt;% kableExtra::kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) 표 9.1: study_data 구조 study_time n_question pass_exam 4.376114 9 0 9.305141 15 1 3.790936 9 0 5.879647 7 0 1.166191 7 0 9.976015 11 1 9.1.1 데이터 나누기 이전 챕터에서 우리는 전체 데이터를 모두 사용하여 신경망을 학습했었다. 하지만, 이럴 경우 과적합의 문제가 발생하기 때문에 언제 학습을 할 때, 우리 모델이 새로운 데이터에 얼마나 잘 되어있는지, 혹시 학습이 과적합은 일어나고 있는게 아닌지 판단해야 한다. 이런 것들을 하기 위해서 주어진 데이터를 두 개로 쪼갠다; 하나는 학습용(train data set), 하나는 평가용(test data set)으로 나눈다. 다음의 코드는 주어진 study_data의 70%는 학습용, 30%는 평가용으로 나누는 코드이다. library(rsample) set.seed(2021) splited_data &lt;- initial_split(study_data, prop = 0.7) train_data &lt;- training(splited_data) test_data &lt;- testing(splited_data) train_data %&gt;% dim() #&gt; [1] 350 3 test_data %&gt;% dim() #&gt; [1] 150 3 9.1.2 시각화 학습용 데이터를 사용하여 데이터를 시각화보면 다음과 같다. 그림 9.1: study_data 학습용 데이터(train data) 시각화 9.2 Dataset 클래스 Dataset 클래스는 우리가 가지고 있는 데이터를 torch에서 접근할 때 어떻게 접근을 해야하는지 알려줄때 사용한다. 예를 들어, 예제 데이터와 같이 행과 열로 구성된 데이터에서 어떤 열이 독립변수(independant variables)를 의미하고 있는지, 어떤 열이 종속변수(dependant variable)를 의미하는지 알려줘야하고, 만약 모델에 넣기 전, 특정 전처리가 필요하다면, 그 과정 역시 넣어줄 수 있다. 다음은 dataset 함수를 사용하여 study_dataset 클래스 생성자를 정의하는 코드이다. 일단 study_dataset 생성자는 객체를 만들때, R6에서처럼 클래스 initialize가 실행된다. 이것을 통하여 prepare_data() 함수가 실행되고, 결과값이 클래스의 data로 저장된다. study_dataset &lt;- dataset( name = &quot;study_dataset&quot;, initialize = function() { self$data &lt;- self$prepare_data() }, .getitem = function(index) { # 독립변수 x, 종속변수 y x &lt;- self$data[index, 1:2] y &lt;- self$data[index, 3] list(x, y) }, .length = function() { self$data$size()[[1]] }, prepare_data = function() { # 난수고정 set.seed(2021) split_data &lt;- rsample::initial_split(study_data, prop = 0.7) train_data &lt;- training(split_data) torch_tensor(as.matrix(train_data)) } ) 위의 코드를 살펴보면 prepare_data() 함수는 앞에서 살펴본 R 코드를 응용하여 study_data 데이터셋 (R 환경에 정의되어 있는 데이터)을 가져다가 rsample 패키지의 initial_split() 함수를 사용해서 학습용 데이터셋을 분리한 후 torch_tensor()를 사용해서 torch로 넘겨준다는 것을 알 수 있다. 그리고, .getitem()과 .length()의 멤버함수를 통하여 데이터에 접근할 수 있도록 만들어져 있다. 정의된 study_dataset() 클래스 생성자를 통하여 데이터를 만들어보자. torch_data &lt;- study_dataset() torch_data #&gt; &lt;study_dataset&gt; #&gt; Inherits from: &lt;dataset&gt; #&gt; Public: #&gt; .getitem: function (index) #&gt; .length: function () #&gt; clone: function (deep = FALSE) #&gt; data: torch_tensor, R7 #&gt; initialize: function () #&gt; prepare_data: function () 결과를 살펴보면 앞에서 정의한 study_dataset() 클래스 생성자 안의 멤버 함수들이 리스트로 제공되는 것을 알 수 있다. .getitem() 멤버함수는 색인(index)을 입력 변수로 받는 함수인데, 입력된 색인 값에 대응되는 데이터를 반환한다. 다음의 코드를 통하여 train_data가 torch_data에 그대로 전달 잘 되었다는 것을 확인할 수 있다. torch_data$.getitem(1:6) #&gt; [[1]] #&gt; torch_tensor #&gt; 9.3051 15.0000 #&gt; 3.7909 9.0000 #&gt; 5.8796 7.0000 #&gt; 1.1662 7.0000 #&gt; 9.9760 11.0000 #&gt; 11.7531 9.0000 #&gt; [ CPUFloatType{6,2} ] #&gt; #&gt; [[2]] #&gt; torch_tensor #&gt; 1 #&gt; 0 #&gt; 0 #&gt; 0 #&gt; 1 #&gt; 1 #&gt; [ CPUFloatType{6} ] head(train_data) #&gt; # A tibble: 6 x 3 #&gt; study_time n_question pass_exam #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 9.31 15 1 #&gt; 2 3.79 9 0 #&gt; 3 5.88 7 0 #&gt; 4 1.17 7 0 #&gt; 5 9.98 11 1 #&gt; 6 11.8 9 1 9.3 데이터로더 (Dataloader) 클래스 study_dataset() 생성자를 통하여 데이터를 torch 상에서 접근하도록 만들었다. 앞선 신경망 학습 예제에서 신경망을 학습할 때, 주어진 데이터 전체를 사용하여 미분값(gradient)을 구했다. 하지만, 실제 많은 딥러닝 문제의 경우 데이터의 크기가 너무 커서 한꺼번에 모든 표본을 메모리에 올린 후 학습을 하지 않고, 잘게 쪼갠 여러 개의 배치(batch)를 만든 뒤에 학습을 진행한다. 다음 차례는 torch에서 신경망을 학습시킬때 데이터의 부분부분을 잘라서 접근 할 수 있도록 만들어 줘야하는데, 이 부분은 dataloader 클래스에서 담당하고 있다. 다음의 코드는 앞에서 정의한 torch_data를 학습할 때 한번에 불러오는 표본 갯수(batch_size)를 8개로 설정한다. study_dl &lt;- dataloader(torch_data, batch_size = 8) 8개를 기준으로 한 세트를 이루므로, 전체 350개의 표본은 총 44개의 batch로 이루어져 있다는 것을 확인 할 수 있다. 주의하기 마지막 배치의 경우는 8개가 아닌 6개의 표본들로 이루어져 있다는 것도 짐작할 수 있어야 한다. # 350/8 == 43.75 # 350 %% 8 == 6 study_dl$.length() #&gt; [1] 44 이렇게 study_dl 안에 들어있는 각각의 데이터 조각들에 접근을 하기 위해서는 enumerate() 함수를 사용한다. 이 함수에 study_dl을 넣어보면 전체 44개의 원소를 가진 리스트 안에 각각의 배치들이 들어가 있는 것을 확인 할 수 있다. enumerate(study_dl) %&gt;% length() #&gt; [1] 44 enumerate(study_dl)[1:2] #&gt; [[1]] #&gt; &lt;environment: 0x557103625548&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;enum_env&quot; #&gt; #&gt; [[2]] #&gt; &lt;environment: 0x5571036274a0&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;enum_env&quot; 9.4 모델 설정 - 로지스틱 회귀모형 자료를 torch에 보내고, 어떻게 접근하는지까지 알아보았다. 이번에는 분류 문제를 푸는 통계 모델 중에서 가장 유명한 모델인 로지스틱 회귀모형을 torch로 정의해보자. 로지스틱 회귀모형은 일반화 선형모형(GLM)의 한 종류이다. 이름에서도 느껴지겠지만, 이 모형은 선형모형의 연장선에 있다. 왜 연장선 상에 있다고 하는 것일까? 일반적인 회귀모형에서는 종속변수인 \\(Y\\)값이 정규분포를 따른다고 가정한다. 왜냐하면 데이터의 발생이 다음과 같은 가정에서 출발하기 때문이다. \\[ Y = X \\beta + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2I) \\] 이것을 \\(Y\\)의 입장에서 생각해보면, 결국 \\(Y\\)라는 확률변수는 정규분포를 따르고, \\(X\\)가 정해졌을때의 평균값은 \\(X\\beta\\)가 된다. \\[ Y \\sim \\mathcal{N}(X\\beta, \\sigma^2 I) \\] 따라서, 다음의 관계가 성립하게 된다. \\[ \\mathbb{E}[Y|X] = X\\beta = f(X\\beta) \\] 위의 등식에서 \\(f(x)\\)는 \\(f(x)=x\\)인 항등함수(identity function)를 나타낸다. 즉, 일반적인 회귀모형의 경우, 종속변수 \\(Y\\)를 정규분포를 따르는 확률변수로 생각하고 있고, 그 평균과 \\(X\\beta\\)를 항등함수로 이어놓은 형태인 것이다. 만약 우리가 종속변수를 다른 확률변수라고 생각하고, 그것의 평균을 이어주는 어떤 함수 \\(f\\)를 찾는다면 어떨까? 수리 통계학에서 가장 먼저 배우는 함수 중 하나가 바로 0과 1을 갖는 베르누이 확률변수인데, 베르누이 확률변수의 평균은 바로 1이 나오는 확률을 의미하는 \\(p\\)이다. \\(p\\)값이 그 의미상 0과 1사이에 위치해야 하므로, \\(X\\beta\\)에서 나오는 값들을 0과 1사이로 모아줘야 하는데 여기서 시그모이드(sigmoid) 함수, \\(\\sigma(x)\\),를 사용한다. \\[ f(x) := \\sigma(x) = \\frac{e^x}{1+e^x} \\] 따라서, 로지스틱 회귀모형에서 종속변수 \\(Y\\)는 다음과 같이 모수 \\(\\sigma(X\\beta)\\)인 베르누이 확률변수를 따른다고 생각하면 된다. \\[ Y \\sim Bernulli(\\sigma(X\\beta)) \\] 알아두기 로지스틱 회귀모형은 종속변수를 베르누이 확률변수로 가정하고, 그것의 평균인 \\(p\\)와 \\(X\\beta\\)를 시그모이드(sigmoid) 함수로 이어놓은 형태로 볼 수 있다. 문제는 왜 그럼 로지스틱 회귀모형인가 하는건데, 사실은 시그모이드(sigmoid) 함수가 바로 로지스틱 함수이기 때문이다. 좀 더 엄밀하게 말하면 우리가 알고 있는 시그모이드 함수의 정확한 명칭은 로지스틱 함수이고, 시그모이드 함수는 S 자 곡선 형태를 띄는 함수들을 통칭해서 부르는 말이다. 우리가 딥러닝에서 많이 쓰는 활성함수(activation function)중 하나인 Hyperbolic tangent 역시 시그모이드 함수이다. 주의하기 우리가 알고 있는 시그모이드(sigmoid) 함수의 정확한 명칭은 로지스틱(logistic) 함수이다. 9.4.1 torch 코드 구현 이제 torch로 특정 신경망 구조를 구현하는 코드는 익숙해졌으리라고 생각한다. 로지스틱 회귀모형은 단층 모형이고, 마지막 활성함수를 sigmoid() 함수로 감싸줘야하는 것이 특징이다. study_net &lt;- nn_module( &quot;StudyNet&quot;, initialize = function() { self$fc1 &lt;- nn_linear(2, 1) self$sigmoid &lt;- nn_sigmoid() }, forward = function(x) { x %&gt;% self$fc1() %&gt;% self$sigmoid() } ) logistic_reg &lt;- study_net() logistic_reg #&gt; An `nn_module` containing 3 parameters. #&gt; #&gt; ── Modules ───────────────────────────────────────────────────────────────────── #&gt; ● fc1: &lt;nn_linear&gt; #3 parameters #&gt; ● sigmoid: &lt;nn_sigmoid&gt; #0 parameters logistic_reg$parameters #&gt; $fc1.weight #&gt; torch_tensor #&gt; 0.01 * #&gt; 9.9717 -23.9173 #&gt; [ CPUFloatType{1,2} ] #&gt; #&gt; $fc1.bias #&gt; torch_tensor #&gt; 0.01 * #&gt; 4.8379 #&gt; [ CPUFloatType{1} ] 코드에서 볼 수 있다시피, 로지스틱 회귀모형은 입력값을 독립변수 갯수인 2개로 받고, 출력값은 하나로 나가는 모형이다. 마지막 층에 sigmoid() 함수는 마지막 출력값을 0과 1사이로 보내기 위하여 사용되었다. 최적화 알고리즘은 optim_sgd으로 설정하였다. optimizer &lt;- optim_sgd(logistic_reg$parameters, lr = 0.05) 9.4.2 손실함수 설정 로지스틱 회귀모형의 구현에서 핵심 파트는 손실함수(loss function)를 설정하는 부분이다. 앞에서 로지스틱 회귀모형이 종속변수 \\(Y\\)를 베르누이 확률변수(Bernoulli random variable)로 모델링을 한다는 것을 살펴보았다. 로지스틱 회귀분석의 계수를 구하기 위해서는 우도함수(Likelihood function)를 정의한 후, 그것을 최대로 만드는 최대우도 추정량(Maximum likelihood estimator; MLE) 값을 찾아야 한다. 확률변서 \\(Y\\)가 베르누이 확률변수를 따를 때, 확률질량함수(p.m.f)는 다음과 같다. \\[ f_Y(y; p) = p^{y}(1-p)^{1-y}, \\text{ for }y = 1, 0, \\text{ and } 0 \\le p \\le 1. \\] 따라서, 로지스틱 회귀모형의 가정을 위의 확률질량함수와 같이 생각해보면, 주어진 데이터에 대한 우도함수 \\(p\\)는 다음과 같다. \\[ \\begin{align} p\\left(\\beta|\\mathbf{X}, \\underline{y}\\right) &amp; =\\prod_{i=1}^{n}p\\left(\\beta|\\mathbf{x}_{i},y_{i}\\right)\\\\ &amp; =\\prod_{i=1}^{n}\\sigma\\left(\\mathbf{x}_{i}^{T}\\beta\\right)^{y_{i}}\\left(1-\\sigma\\left(\\mathbf{x}_{i}^{T}\\beta\\right)\\right)^{1-y_{i}}\\\\ &amp; =\\prod_{i=1}^{n}\\pi_{i}^{y_{i}}\\left(1-\\pi_{i}\\right)^{1-y_{i}} \\end{align} \\] 위의 수식에서 계산의 편의를 위하여 \\(\\pi_i\\)를 사용하여 다음의 항을 간단히 표현했음에 주의한다. \\[ \\pi_{i}:=\\sigma\\left(\\mathbf{x}_{i}^{T}\\beta\\right) \\] 보통의 최적화 알고리즘의 경우, 손실함수 값을 최소로 만드는 값을 찾는 알고리즘이다. 하지만 MLE의 경우 주어진 우도함수를 최대로 만드는 값이기 때문에 최적화 알고리즘에 사용할 수 있도록 음수값을 붙여주고, 함수를 좀 더 완만하게 만들기 위해서 로그값을 취해준, 음우도함수(negative log-likelihood function)을 사용한다. \\[ \\begin{align*} -\\ell\\left(\\beta\\right) &amp; =-log\\left(p\\left(\\underline{y}|\\mathbf{X},\\beta\\right)\\right)\\\\ &amp; =-\\sum_{i=1}^{n}\\left\\{ y_{i}log\\left(\\sigma\\left(\\mathbf{x}_{i}^{T}\\beta\\right)\\right)+\\left(1-y_{i}\\right)log\\left(1-\\sigma\\left(\\mathbf{x}_{i}^{T}\\beta\\right)\\right)\\right\\} \\\\ &amp; =-\\sum_{i=1}^{n}\\left\\{ y_{i}log\\left(\\pi_{i}\\right)+\\left(1-y_{i}\\right)log\\left(1-\\pi_{i}\\right)\\right\\} \\end{align*} \\] 위의 함수 \\(-\\ell(\\cdot)\\)은 torch에서 nnf_binary_cross_entropy() 함수에 정의되어 있다. 따라서 로지스틱 회귀모형의 계수는 다음과 같이 데이터 행렬(\\(X\\))과 레이블(\\(y\\))가 주어졌을때 \\(-\\ell(\\cdot)\\) 함수를 최소로 만드는 \\(\\beta\\)값으로 표현된다. \\[ \\hat{\\beta} \\overset{set}{=} \\underset{\\beta}{arg \\ min} \\ \\ -\\ell\\left(\\beta; X, y\\right) \\] 이 값을 찾기 위해서 경사하강법을 이용해 \\(\\hat{\\beta}\\)을 찾아나아가는 과정이 torch에서는 단 두 줄로 표현이 된다. loss &lt;- nnf_binary_cross_entropy(output, batch[[2]]) loss$backward() optimizer$step() 앞에서 정의한 study_dl 데이터로더를 사용하여 로지스틱 회귀모형을 학습시키는 코드는 다음과 같다. for (epoch in 1:1000) { loss_collect &lt;- c() for (batch in enumerate(study_dl)) { optimizer$zero_grad() output &lt;- logistic_reg(batch[[1]]) loss &lt;- nnf_binary_cross_entropy(output, batch[[2]]) loss$backward() optimizer$step() loss_collect &lt;- c(loss_collect, loss$item()) } if (epoch %% 100 == 0){ cat(sprintf(&quot;Loss at epoch %d: %3f\\n&quot;, epoch, mean(loss_collect))) } } #&gt; Loss at epoch 100: 0.256948 #&gt; Loss at epoch 200: 0.220478 #&gt; Loss at epoch 300: 0.209576 #&gt; Loss at epoch 400: 0.205040 #&gt; Loss at epoch 500: 0.202900 #&gt; Loss at epoch 600: 0.201856 #&gt; Loss at epoch 700: 0.201370 #&gt; Loss at epoch 800: 0.201186 #&gt; Loss at epoch 900: 0.201170 #&gt; Loss at epoch 1000: 0.201249 9.5 학습 결과 학습된 계수 값을 다음과 같다. logistic_reg$parameters #&gt; $fc1.weight #&gt; torch_tensor #&gt; 1.2512 0.6331 #&gt; [ CPUFloatType{1,2} ] #&gt; #&gt; $fc1.bias #&gt; torch_tensor #&gt; -17.0234 #&gt; [ CPUFloatType{1} ] 9.5.1 평가셋 예측 학습된 로지스틱 회귀모형의 계수값을 사용하여 평가셋의 반응 변수가 1일 확률, 즉, 시험에 통과할 확률을 예측 할 수 있다. test_data &lt;- testing(splited_data) test_data[,1:2] %&gt;% # R to torch as.matrix() %&gt;% torch_tensor() %&gt;% # prop. prediction logistic_reg() %&gt;% # torch to R as.array() %&gt;% as.numeric()-&gt; predict 예측한 확률값이 0.5가 넘을 경우, 학생이 시험에 통과를 할 수 있다고 예측을 하고, 그렇지 않을 경우 통과하지 못한다고 예측해보자. # make 0 and 1 using 0.5 threshold predict &lt;- floor(predict - 0.5) + 1 head(predict) #&gt; [1] 0 0 0 0 1 0 이렇게 예측한 값과 실제 평가셋에 들어있는 학생들의 시험 통과 여부값을 사용하여 결과 비교하여 표로 만들어보면 다음과 같다. 표 9.2: 평가셋을 통한 모델성능 비교 (p = 0.5) 예측 불합격 합격 총계 실제값 불합격 87 0 87 합격 7 56 63 총계 94 56 150 아래 그림에서처럼 로지스틱 함수는 입력값이 0일때 함수값이 0.5가 된다. 즉, 로지스틱 회귀에서 \\(X\\beta\\)값이 로지스틱 함수에 입력이 되므로, \\(X\\beta\\) 값이 0이 되는 값들을 경계로 모델의 합격 불합격 예측값이 갈리는 것이다. 그림 9.2: 로지스틱 함수는 x가 0일때 0.5를 지나게 된다. 이러한 선을 의사결정선(decision boundary)라고 부른다. \\[ \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 = 0 \\] 주어진 예제의 평가셋을 시각화 시키고, 학습한 계수를 바탕으로 의사결정선을 구해보면 다음과 같다. learned_beta &lt;- logistic_reg$parameters$fc1.weight %&gt;% as.numeric() learned_bias &lt;- logistic_reg$parameters$fc1.bias %&gt;% as.numeric() addline &lt;- function(beta, bias, ...){ my_slope &lt;- -beta[1] / beta[2] my_intercept &lt;- -bias / beta[2] geom_abline(slope = my_slope, intercept = my_intercept, ...) } p_data &lt;- ggplot(data = test_data) + geom_point(mapping = aes(x = study_time, y = n_question, color = factor(pass_exam))) + xlab(&quot;Study time&quot;) + ylab(&quot;Number of Question&quot;) + scale_colour_discrete(guide = guide_legend(reverse=TRUE), name=&quot;Exam&quot;, labels=c(&quot;Fail&quot;, &quot;Success&quot;)) p_data + addline(learned_beta, learned_bias, linetype = &quot;solid&quot;, col = &quot;blue&quot;) 그림에서 확인할 수 있다시피, 파란선을 기준으로 초록색과 빨간색 점이 완벽히 갈라져 있지 않다. 즉, 표에서도 확인 할 수 있었듯, 모델의 예측과 실제 데이터가 다른 경우가 있는 것이다. 일반적으로 딥러닝에서 사용되는 신경망 모델은 로지스틱 회귀모형보다 훨씬 예측력이 뛰어나다고 알려져있다. 다음 챕터에서는 분류문제에 신경망을 적용하여 로지스틱 회귀모형의 성능을 얼마나 향상 시킬 수 있는지 알아보도록 하자. "],["references.html", "References", " References Custom block icons made by Freepik and mavadee from www.flaticon.com "]]
